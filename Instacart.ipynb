{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading aisles...\n",
      "loading department...\n",
      "loading products...\n",
      "loading prior orders...\n",
      "loading train orders...\n",
      "loading orders...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from IPython.display import display\n",
    "import xgboost as xgb\n",
    "np.random.seed(999)\n",
    "print('loading aisles...')\n",
    "aisles = pd.read_csv('aisles.csv', dtype={\n",
    "        'aisle_id': np.uint16,\n",
    "        'aisle': 'category'})\n",
    "\n",
    "print('loading department...')\n",
    "department = pd.read_csv('departments.csv', dtype={\n",
    "            'department_id': np.uint8,\n",
    "            'department': 'category'})\n",
    "\n",
    "print('loading products...')\n",
    "products = pd.read_csv('products.csv', dtype={\n",
    "        'product_id': np.uint16,\n",
    "        'order_id': np.uint32,\n",
    "        'aisle_id': np.uint8,\n",
    "        'department_id': np.uint8})\n",
    "\n",
    "print('loading prior orders...')\n",
    "prior = pd.read_csv('order_products__prior.csv', dtype={\n",
    "        'order_id': np.uint32,\n",
    "        'product_id': np.uint16,\n",
    "        'add_to_cart_order': np.uint16,\n",
    "        'reordered': np.uint16})\n",
    "\n",
    "print('loading train orders...')\n",
    "train = pd.read_csv('order_products__train.csv', dtype={\n",
    "        'order_id': np.uint32,\n",
    "        'product_id': np.uint16,\n",
    "        'add_to_cart_order': np.uint16,\n",
    "        'reordered': np.uint8})\n",
    "\n",
    "print('loading orders...')\n",
    "order = pd.read_csv('orders.csv' , dtype={\n",
    "        'order_id': np.uint32,\n",
    "        'user_id': np.uint32,\n",
    "        'eval_set': 'category',\n",
    "        'order_number': np.uint16,\n",
    "        'order_dow': np.uint16,\n",
    "        'order_hour_of_day': np.uint16,\n",
    "        'days_since_prior_order': np.float32})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# best sellers\n",
    "best_seller_id = [24852, 13176, 21137, 21903, 47626, 47766, 47209, 16797, \\\n",
    "                 26209, 27966]\n",
    "most_often_reordered = [1729, 20940, 12193, 21038, 31764, 24852, 117, \\\n",
    "                       39180, 12384, 24024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_orders = order[order.eval_set == 'train']\n",
    "test_orders = order[order.eval_set == 'test']\n",
    "prior_orders = order[order.eval_set == 'prior']\n",
    "\n",
    "train.set_index(['order_id', 'product_id'], inplace=True, drop=False)\n",
    "\n",
    "order.set_index('order_id', inplace=True, drop=False)\n",
    "prior = prior.join(order, on='order_id', rsuffix='_')\n",
    "prior.drop('order_id_', inplace=True, axis=1)\n",
    "prior.set_index('order_id', inplace=True, drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Construct products information...\n"
     ]
    }
   ],
   "source": [
    "print('Construct products information...')\n",
    "prods = pd.DataFrame()\n",
    "prods['total_nb'] = prior.groupby(prior.product_id).size().astype(np.uint32)\n",
    "prods['nb_reorder'] = prior.groupby(prior.product_id)['reordered'].sum().astype(np.uint32)\n",
    "prods['reorder_rate'] = prods.nb_reorder / prods.total_nb.astype(np.float32)\n",
    "prods['nb_buyers'] = prior.groupby(prior.product_id)['user_id'].apply(lambda x: len(set(x))).astype(np.uint16) # unique buyers\n",
    "prods['avg_add_to_cart_order'] = prior.groupby(prior.product_id)['add_to_cart_order'].mean().astype(np.uint8)\n",
    "prods['min_add_to_cart_order'] = prior.groupby(prior.product_id)['add_to_cart_order'].min().astype(np.uint8)\n",
    "prods['max_add_to_cart_order'] = prior.groupby(prior.product_id)['add_to_cart_order'].max().astype(np.uint8)\n",
    "prods['nb_orders'] = prior.groupby(prior.product_id).size().astype(np.uint16)\n",
    "products = products.join(prods, on='product_id')\n",
    "products.set_index('product_id', drop=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3214874, 8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(ords_pri.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order related information...\n"
     ]
    }
   ],
   "source": [
    "print('Order related information...')\n",
    "ords_pri = pd.DataFrame()\n",
    "ords_pri['order_id'] = prior.groupby(prior.order_id)['order_id'].apply(lambda x: x.iloc[0])\n",
    "ords_pri['user_id'] = prior.groupby(prior.order_id)['user_id'].apply(lambda x: x.iloc[0])\n",
    "ords_pri['unique_product_id'] = prior.groupby(prior.order_id)['product_id'].apply(set)\n",
    "ords_pri.set_index('order_id', drop=False, inplace=True)\n",
    "ords_pri['nb_items'] = prior.groupby(prior.order_id)['product_id'].size().astype(np.uint8)\n",
    "ords_pri['first_item_id'] = prior.groupby(prior.order_id)['product_id'].apply(lambda x: x.iloc[0])\n",
    "ords_pri['first_item_reorder'] = prior.groupby(prior.order_id)['reordered'].apply(lambda x: x.iloc[0])\n",
    "ords_pri['nb_reorder'] = prior.groupby(prior.order_id)['reordered'].sum()\n",
    "ords_pri['reorder_ratio'] = (ords_pri['nb_reorder'] / ords_pri['nb_items']).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min and max basket size for each user...\n",
      "10000 orders...\n",
      "20000 orders...\n",
      "30000 orders...\n",
      "40000 orders...\n",
      "50000 orders...\n",
      "60000 orders...\n",
      "70000 orders...\n",
      "80000 orders...\n",
      "90000 orders...\n",
      "100000 orders...\n",
      "110000 orders...\n",
      "120000 orders...\n",
      "130000 orders...\n",
      "140000 orders...\n",
      "150000 orders...\n",
      "160000 orders...\n",
      "170000 orders...\n",
      "180000 orders...\n",
      "190000 orders...\n",
      "200000 orders...\n"
     ]
    }
   ],
   "source": [
    "print(\"min and max basket size for each user...\")\n",
    "min_basket_list = []\n",
    "max_basket_list = []\n",
    "nb_reorder_items_list = []\n",
    "avg_reorder_per_basket_list = []\n",
    "reorder_order_vs_order_ratio_list = []\n",
    "nb_all_items_list = []\n",
    "nb_reorder_items_vs_nb_all_items_ratio_list = []\n",
    "min_reorder_items_list = []\n",
    "max_reorder_items_list = []\n",
    "user_order_list = prior_orders.groupby('user_id')['order_id'].apply(list)\n",
    "len(user_order_list)\n",
    "for ord_i, order_list in enumerate(user_order_list):\n",
    "    if not (ord_i + 1) % 10000:\n",
    "        print(\"%d orders...\" % (ord_i+1))\n",
    "    min_basket=999\n",
    "    max_basket=0\n",
    "    min_reorder_items = 999\n",
    "    max_reorder_items = 0\n",
    "    nb_reorder = 0\n",
    "    nb_reorder_orders = 0\n",
    "    nb_all_items = 0\n",
    "    nb_order = len(order_list)\n",
    "    for order_id in order_list:\n",
    "        nb_item_s = ords_pri.loc[order_id, 'nb_items']\n",
    "        nb_all_items += nb_item_s\n",
    "        nb_reorder_s = ords_pri.loc[order_id, 'nb_reorder']\n",
    "        nb_reorder += nb_reorder_s\n",
    "        nb_reorder_orders += (ords_pri.loc[order_id, 'nb_reorder'] > 0).astype(np.uint8)\n",
    "        min_basket = min(min_basket, nb_item_s)\n",
    "        max_basket = max(max_basket, nb_item_s)\n",
    "        min_reorder_items = min(min_reorder_items, nb_reorder_s)\n",
    "        max_reorder_items = max(max_reorder_items, nb_reorder_s)\n",
    "    min_basket_list.append(min_basket)\n",
    "    max_basket_list.append(max_basket)\n",
    "    nb_reorder_items_list.append(nb_reorder)\n",
    "    avg_reorder_per_basket_list.append((nb_reorder / nb_order).astype(np.float32))\n",
    "    reorder_order_vs_order_ratio_list.append((nb_reorder_orders / nb_order).astype(np.float32)) \n",
    "    nb_all_items_list.append(nb_all_items)\n",
    "    nb_reorder_items_vs_nb_all_items_ratio_list.append((nb_reorder / nb_all_items).astype(np.float32))\n",
    "    min_reorder_items_list.append(min_reorder_items)\n",
    "    max_reorder_items_list.append(max_reorder_items)\n",
    "#     print(\"order id: %d, min_basket: %d, max_basket: %d\" %(order_id, min_basket, max_basket))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User related information\n",
      "users best seller 1\n",
      "users best reorder 1\n"
     ]
    }
   ],
   "source": [
    "print('User related information')\n",
    "users = pd.DataFrame()\n",
    "users['user_id'] = prior.groupby('user_id')['user_id'].apply(lambda x: x.iloc[0])\n",
    "users['nb_order'] = prior_orders.groupby('user_id').size().astype(np.uint16)\n",
    "users['orders'] = prior_orders.groupby('user_id')['order_id'].apply(list) \n",
    "users['min_basket'] = min_basket_list\n",
    "users['max_basket'] = max_basket_list\n",
    "users['nb_reorder_items'] = nb_reorder_items_list\n",
    "users['avg_reorder_per_basket'] = avg_reorder_per_basket_list\n",
    "users['reorder_order_vs_order_ratio'] = reorder_order_vs_order_ratio_list\n",
    "users['nb_all_items'] = nb_all_items_list\n",
    "users['nb_reorder_items_vs_nb_all_items_ratio'] = nb_reorder_items_vs_nb_all_items_ratio_list\n",
    "users['min_reorder_items'] = min_reorder_items_list\n",
    "users['max_reorder_items'] = max_reorder_items_list\n",
    "\n",
    "#     print(\"order id: %d, min_basket: %d, max_basket: %d\" %(order_id, min_basket, max_basket))\n",
    "users['avg_days_between_order'] = prior.groupby('user_id')['days_since_prior_order'].mean().astype(np.float32)\n",
    "users['avg_hour_of_day'] = prior.groupby('user_id')['order_hour_of_day'].mean().astype(np.float32)\n",
    "users['nb_total_items'] = prior.groupby('user_id').size().astype(np.uint16)\n",
    "users['unique_products'] = prior.groupby('user_id')['product_id'].apply(set) # apply 对每个行或者列调用一次函数\n",
    "users['all_products'] = prior.groupby('user_id')['product_id'].apply(list)\n",
    "users['nb_distinct_items'] = (users['unique_products'].map(len)).astype(np.uint16) #map 对每个元素(element-wise)调用一次函数\n",
    "users['average_basket'] = (users.nb_total_items / users.nb_order).astype(np.float32)\n",
    "users['min_days_of_week'] = prior.groupby(prior.user_id)['order_dow'].apply(min).astype(np.uint8)\n",
    "users['max_days_of_week'] = prior.groupby(prior.user_id)['order_dow'].apply(max).astype(np.uint8)\n",
    "print('users best seller 1')\n",
    "users['nb_2nd_seller'] = users.all_products.apply(lambda X: sum([best_seller_id[1]==x for x in X]))\n",
    "print('users best reorder 1')\n",
    "users['nb_1st_reorder'] = users.all_products.apply(lambda X: sum([most_often_reordered[0] == x for x in X]))\n",
    "\n",
    "# Query data from ords\n",
    "users['last_order_id'] = prior_orders.groupby(prior_orders.user_id)['user_id'].apply(lambda x: x.iloc[-1])\n",
    "users['lo_nb_products'] = users.last_order_id.map(ords_pri.nb_items)\n",
    "users['lo_first_item_id'] = users.last_order_id.map(ords_pri.first_item_id)\n",
    "users['lo_first_item_reorder'] = users.last_order_id.map(ords_pri.first_item_reorder)\n",
    "users['lo_nb_reorder'] = users.last_order_id.map(ords_pri.nb_reorder)\n",
    "users['lo_reorder_ratio'] = users.last_order_id.map(ords_pri.reorder_ratio)\n",
    "\n",
    "users['last_2_order_id'] = prior_orders.groupby(prior_orders.user_id)['user_id'].apply(lambda x: x.iloc[-2])\n",
    "users['lo2_nb_products'] = users.last_2_order_id.map(ords_pri.nb_items)\n",
    "users['lo2_first_item_id'] = users.last_2_order_id.map(ords_pri.first_item_id)\n",
    "users['lo2_first_item_reorder'] = users.last_2_order_id.map(ords_pri.first_item_reorder)\n",
    "users['lo2_nb_reorder'] = users.last_2_order_id.map(ords_pri.nb_reorder)\n",
    "users['lo2_reorder_ratio'] = users.last_2_order_id.map(ords_pri.reorder_ratio)\n",
    "\n",
    "users['last_3_order_id'] = prior_orders.groupby(prior_orders.user_id)['user_id'].apply(lambda x: x.iloc[-3])\n",
    "users['lo3_nb_products'] = users.last_3_order_id.map(ords_pri.nb_items)\n",
    "users['lo3_first_item_id'] = users.last_3_order_id.map(ords_pri.first_item_id)\n",
    "users['lo3_first_item_reorder'] = users.last_3_order_id.map(ords_pri.first_item_reorder)\n",
    "users['lo3_nb_reorder'] = users.last_3_order_id.map(ords_pri.nb_reorder)\n",
    "users['lo3_reorder_ratio'] = users.last_3_order_id.map(ords_pri.reorder_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Construct products information...\n",
      "Order related information...\n",
      "User related information\n",
      "users best seller 1\n",
      "users best seller 2\n",
      "users best seller 3\n",
      "users best seller 4\n",
      "users best seller 5\n",
      "users best seller 6\n",
      "users best seller 7\n",
      "users best seller 8\n",
      "users best seller 9\n",
      "users best seller 10\n",
      "users best reorder 1\n",
      "users best reorder 2\n",
      "users best reorder 3\n",
      "users best reorder 4\n",
      "users best reorder 5\n",
      "users best reorder 6\n",
      "users best reorder 7\n",
      "users best reorder 8\n",
      "users best reorder 9\n",
      "users best reorder 10\n",
      "UserXproduct_id information...\n"
     ]
    }
   ],
   "source": [
    "print('UserXproduct_id information...')\n",
    "prior['user_product_index'] = (prior.user_id.astype(np.uint64) * 100000\\\n",
    "                               + prior.product_id).astype(np.uint64)\n",
    "d = dict()\n",
    "for row in prior.itertuples():\n",
    "    k = row.user_product_index\n",
    "    if k not in d:\n",
    "        d[k] = (1, \\\n",
    "                row.add_to_cart_order, \\\n",
    "                row.reordered, \\\n",
    "                (row.order_number, row.order_id),\\\n",
    "                row.order_dow, \\\n",
    "                row.order_hour_of_day, \\\n",
    "                row.add_to_cart_order, \\\n",
    "                row.add_to_cart_order)\n",
    "    else:\n",
    "        d[k] = (d[k][0]+1, d[k][1]+row.add_to_cart_order, \\\n",
    "                d[k][2]+row.reordered, \\\n",
    "                # find last order with that product\n",
    "                max(d[k][3], (row.order_number, row.order_id)), \\\n",
    "                d[k][4]+row.order_dow, \\\n",
    "                d[k][5]+row.order_hour_of_day, \\\n",
    "                min(d[k][6], row.add_to_cart_order), \\\n",
    "                max(d[k][7], row.add_to_cart_order))\n",
    "UserProduct = pd.DataFrame.from_dict(d, orient='index')\n",
    "del d\n",
    "UserProduct.columns = ['nb_orders', 'sum_add_to_cart_order', 'nb_reordered', \\\n",
    "                      'last_order_id', 'sum_order_dow', 'sum_order_hour_of_day', \\\n",
    "                      'min_add_to_cart_order', 'max_add_to_cart_order']\n",
    "UserProduct['nb_orders'] = UserProduct.nb_orders.astype(np.uint16) \n",
    "UserProduct['sum_add_to_cart_order'] = UserProduct.sum_add_to_cart_order.astype(np.uint16)\n",
    "UserProduct['nb_reordered'] = UserProduct.nb_reordered.astype(np.uint16)\n",
    "UserProduct['last_order_id'] = UserProduct.last_order_id.map(lambda x: x[1]).astype(np.uint32)\n",
    "UserProduct['sum_order_dow'] = UserProduct.sum_order_dow.astype(np.uint16)\n",
    "UserProduct['sum_order_hour_of_day'] = UserProduct.sum_order_hour_of_day.astype(np.uint32)\n",
    "UserProduct['min_add_to_cart_order'] = UserProduct.min_add_to_cart_order.astype(np.uint8)\n",
    "UserProduct['max_add_to_cart_order'] = UserProduct.max_add_to_cart_order.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_features(orders, labels_out=False):\n",
    "    print('generate features and labels(optional) from selected orders')\n",
    "    count=0\n",
    "    product_list = []\n",
    "    order_list = []\n",
    "    labels = []\n",
    "    for row in orders.itertuples():\n",
    "        count+=1\n",
    "        order_id = row.order_id\n",
    "        user_id = row.user_id\n",
    "        user_products = users.unique_products[user_id]\n",
    "        product_list += user_products\n",
    "        order_list += [order_id] * len(user_products)\n",
    "        if labels_out:\n",
    "            labels += [(order_id, product) in train.index for product in user_products]            \n",
    "        if count%10000 == 0:\n",
    "            print('order row', count)\n",
    "            \n",
    "    df = pd.DataFrame({'order_id': order_list, 'product_id': product_list}, dtype=np.int32)\n",
    "    labels = np.array(labels, dtype=np.int8)\n",
    "    del order_list\n",
    "    del product_list\n",
    "    \n",
    "    print(\"user related features<prior>\")\n",
    "    df['user_id'] = df.order_id.map(order.user_id)\n",
    "    df['user_total_orders'] = df.user_id.map(users.nb_order)\n",
    "    df['user_total_items'] = df.user_id.map(users.nb_total_items)\n",
    "    df['user_distinct_items'] = df.user_id.map(users.nb_distinct_items)\n",
    "    df['user_avg_days_between_orders'] = df.user_id.map(users.avg_days_between_order)\n",
    "    df['user_avg_basket'] = df.user_id.map(users.average_basket)\n",
    "    df['user_min_days_of_week'] = df.user_id.map(users.min_days_of_week)\n",
    "    df['user_max_days_of_week'] = df.user_id.map(users.max_days_of_week)\n",
    "    \n",
    "    df['user_nb_1st_seller'] = df.user_id.map(users.nb_1st_seller)\n",
    "\n",
    "    df['user_nb_1st_reorder'] = df.user_id.map(users.nb_1st_reorder)\n",
    "    \n",
    "    df['user_last_order_id'] = df.user_id.map(users.last_order_id)\n",
    "    df['user_lo_dow'] = df.user_last_order_id.map(order.order_dow)\n",
    "    df['user_lo_hour_of_day'] = df.user_last_order_id.map(order.order_hour_of_day)\n",
    "    df['user_lo_day_since_prior'] = df.user_last_order_id.map(order.days_since_prior_order)\n",
    "    df['user_lo_nb_products'] = df.user_id.map(users.lo_nb_products)\n",
    "    df['user_lo_first_item_id'] = df.user_id.map(users.lo_first_item_id)\n",
    "    df['user_lo_first_item_reorder'] = df.user_id.map(users.lo_first_item_reorder)\n",
    "    df['user_lo_nb_reorder'] = df.user_id.map(users.lo_nb_reorder)\n",
    "    df['user_lo_reorder_ratio'] = df.user_id.map(users.lo_reorder_ratio)\n",
    "    \n",
    "    df['user_last2_order_id'] = df.user_id.map(users.last_2_order_id)\n",
    "    df['user_lo2_dow'] = df.user_last2_order_id.map(order.order_dow)\n",
    "    df['user_lo2_hour_of_day'] = df.user_last2_order_id.map(order.order_hour_of_day)\n",
    "    df['user_lo2_day_since_prior'] = df.user_last2_order_id.map(order.days_since_prior_order)\n",
    "    df['user_lo2_nb_products'] = df.user_id.map(users.lo2_nb_products)\n",
    "    df['user_lo2_first_item_id'] = df.user_id.map(users.lo2_first_item_id)\n",
    "    df['user_lo2_first_item_reorder'] = df.user_id.map(users.lo2_first_item_reorder)\n",
    "    df['user_lo2_nb_reorder'] = df.user_id.map(users.lo2_nb_reorder)\n",
    "    df['user_lo2_reorder_ratio'] = df.user_id.map(users.lo2_reorder_ratio)\n",
    "    \n",
    "    df['user_last3_order_id'] = df.user_id.map(users.last_3_order_id)\n",
    "    df['user_lo3_dow'] = df.user_last3_order_id.map(order.order_dow)\n",
    "    df['user_lo3_hour_of_day'] = df.user_last3_order_id.map(order.order_hour_of_day)\n",
    "    df['user_lo3_day_since_prior'] = df.user_last3_order_id.map(order.days_since_prior_order)\n",
    "    df['user_lo3_nb_products'] = df.user_id.map(users.lo3_nb_products)\n",
    "    df['user_lo3_first_item_id'] = df.user_id.map(users.lo3_first_item_id)\n",
    "    df['user_lo3_first_item_reorder'] = df.user_id.map(users.lo3_first_item_reorder)\n",
    "    df['user_lo3_nb_reorder'] = df.user_id.map(users.lo3_nb_reorder)\n",
    "    df['user_lo3_reorder_ratio'] = df.user_id.map(users.lo3_reorder_ratio)\n",
    "    \n",
    "    df['users_min_basket'] = df.user_id.map(users.min_basket)\n",
    "    df['users_max_basket'] = df.user_id.map(users.max_basket)\n",
    "    df['users_nb_reorder_items'] = df.user_id.map(users.nb_reorder_items)\n",
    "    df['users_avg_reorder_per_basket'] = df.user_id.map(users.avg_reorder_per_basket)\n",
    "    df['users_reorder_order_vs_order_ratio'] = df.user_id.map(users.reorder_order_vs_order_ratio)\n",
    "    df['users_nb_all_items'] = df.user_id.map(users.nb_all_items)\n",
    "    df['users_nb_reorder_items_vs_nb_all_items_ratio'] = df.user_id.map(users.nb_reorder_items_vs_nb_all_items_ratio)\n",
    "    df['users_min_reorder_items'] = df.user_id.map(users.min_reorder_items)\n",
    "    df['users_max_reorder_items'] = df.user_id.map(users.max_reorder_items)\n",
    "    \n",
    "    print(\"product related features<prior>\")\n",
    "    df['product_aisle_id'] = df.product_id.map(products.aisle_id)\n",
    "    df['product_department_id'] = df.product_id.map(products.department_id)\n",
    "    df['product_orders'] = df.product_id.map(products.total_nb)\n",
    "    df['product_reorders'] = df.product_id.map(products.nb_reorder)\n",
    "    df['product_reorder_rate'] = df.product_id.map(products.reorder_rate)\n",
    "    df['product_nb_buyers'] = df.product_id.map(products.nb_buyers)\n",
    "    df['product_avg_add_to_cart_order'] = df.product_id.map(products.avg_add_to_cart_order)\n",
    "    df['product_nb_orders'] = df.product_id.map(products.nb_orders)\n",
    "    df['product_min_add_to_cart_order'] = df.product_id.map(products.min_add_to_cart_order)\n",
    "    df['product_max_add_to_cart_order'] = df.product_id.map(products.max_add_to_cart_order)\n",
    "    \n",
    "    print(\"order related features<train>\")\n",
    "    df['order_hour_of_day'] = df.order_id.map(order.order_hour_of_day)\n",
    "    df['order_days_since_prior_order'] = df.order_id.map(order.days_since_prior_order)\n",
    "    df['order_day_of_week'] = df.order_id.map(order.order_dow)\n",
    "    df['order_number'] = df.order_id.map(order.order_number)\n",
    "    \n",
    "    print(\"userXproduct related features<prior>\")\n",
    "    # 1.nb_orders, 2.sum_add_to_cart_order, 3.nb_reordered, \\\n",
    "    # 4.last_order_id, 5.sum_order_dow, 6.sum_order_hour_of_day\n",
    "    df['UP'] = df.product_id+df.user_id.astype(np.uint64)*100000\n",
    "    df['UP_nb_orders'] = df.UP.map(UserProduct.nb_orders)\n",
    "    df['UP_avg_add_to_cart_order'] = df.UP.map(UserProduct.sum_add_to_cart_order)\\\n",
    "                                    / df.UP_nb_orders\n",
    "    df['UP_nb_reordered'] = df.UP.map(UserProduct.nb_reordered)\n",
    "    df['UP_reorder_ratio'] = (df.UP_nb_reordered / df.UP_nb_orders).astype(np.float32)\n",
    "    df['UP_last_order_id'] = df.UP.map(UserProduct.last_order_id)\n",
    "    df['UP_avg_order_dow'] = (df.UP.map(UserProduct.sum_order_dow)\\\n",
    "                              / df.UP_nb_orders).astype(np.float32)\n",
    "    df['UP_avg_order_hour_of_day'] = (df.UP.map(UserProduct.sum_order_hour_of_day) / \\\n",
    "                                    df.UP_nb_orders).astype(np.float32)\n",
    "    df['UP_order_ratio'] = (df.UP_nb_orders / df.user_total_orders).astype(np.float32)\n",
    "    df['UP_order_since_last'] = df.user_total_orders - \\\n",
    "                                df.UP_last_order_id.map(order.order_number)\n",
    "    #最后一次买该产品和该订单-相同产品相隔的时间(没有算日期。。。)\n",
    "    df['UP_delta_hour_vs_last'] = abs(df.order_hour_of_day - df.UP_last_order_id.map(\\\n",
    "                                       order.order_hour_of_day)).map(lambda x: min(x, 24-x)).astype(np.int8)\n",
    "    df['UP_min_add_to_cart_order'] = df.UP.map(UserProduct.min_add_to_cart_order)\n",
    "    df['UP_max_add_to_cart_order'] = df.UP.map(UserProduct.max_add_to_cart_order)\n",
    "    df.drop('UP', axis=1, inplace=True)\n",
    "    \n",
    "#     print(df.dtypes)\n",
    "#     print(df.memory_usage())\n",
    "    return(df, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train order size:  (131209, 7)\n",
      "generate features and labels(optional) from selected orders\n",
      "order row 10000\n",
      "order row 20000\n",
      "order row 30000\n",
      "order row 40000\n",
      "order row 50000\n",
      "order row 60000\n",
      "order row 70000\n",
      "order row 80000\n",
      "order row 90000\n",
      "order row 100000\n",
      "order row 110000\n",
      "order row 120000\n",
      "order row 130000\n",
      "user related features<prior>\n",
      "product related features<prior>\n",
      "order related features<train>\n",
      "userXproduct related features<prior>\n",
      "test order size:  (75000, 7)\n",
      "generate features and labels(optional) from selected orders\n",
      "order row 10000\n",
      "order row 20000\n",
      "order row 30000\n",
      "order row 40000\n",
      "order row 50000\n",
      "order row 60000\n",
      "order row 70000\n",
      "user related features<prior>\n",
      "product related features<prior>\n",
      "order related features<train>\n",
      "userXproduct related features<prior>\n"
     ]
    }
   ],
   "source": [
    "print('train order size: ', train_orders.shape)\n",
    "df_train, labels = gen_features(train_orders, labels_out=True)\n",
    "printf('feature size: ', df.train.shape[0])\n",
    "df_train['label'] = pd.Series(labels, dtype=np.int8)\n",
    "print('test order size: ', test_orders.shape)\n",
    "df_test, _ = gen_features(test_orders)\n",
    "\n",
    "df_train['label'] = pd.Series(labels, dtype=np.int8)\n",
    "user_id_list=users.index.tolist()\n",
    "np.random.shuffle(user_id_list)\n",
    "nb_user = len(user_id_list)\n",
    "val_nb_user = nb_user // 10\n",
    "# del users\n",
    "# del order\n",
    "# del UserProduct\n",
    "# del products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing Cross 0 Validation\n",
      "validation start: 0, end: 20620\n",
      "Split train and valid data/label by user_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "for nb in range(1):\n",
    "    print(\"Doing Cross %d Validation\"% nb)\n",
    "    val_start = nb*val_nb_user\n",
    "    val_end = (nb+1)*val_nb_user\n",
    "    if nb==9:\n",
    "        val_end = nb_user\n",
    "    print(\"validation start: %d, end: %d\" % (val_start, val_end))\n",
    "    train_user_ids = np.concatenate((user_id_list[:val_start],\\\n",
    "                                    user_id_list[val_end:]))\n",
    "    val_user_ids = user_id_list[val_start:val_end]\n",
    "    print(\"Split train and valid data/label by user_id\")\n",
    "    sub_df_val = df_train[df_train.user_id.isin(val_user_ids)]\n",
    "    sub_df_train = df_train[df_train.user_id.isin(train_user_ids)]\n",
    "    sub_train_label = np.array(sub_df_train['label'])\n",
    "    sub_val_label = np.array(sub_df_val['label'])\n",
    "    sub_df_train.drop('label', axis=1, inplace=True)\n",
    "    sub_df_val.drop('label', axis=1, inplace=True)\n",
    "    params={\n",
    "    'booster':'gbtree',\n",
    "    'objective': 'binary:logistic', \n",
    "    'eval_metric': 'logloss',\n",
    "    'gamma':0.7,  # 用于控制是否后剪枝的参数,越大越保守，一般0.1、0.2这样子。\n",
    "    'max_depth':10, # 构建树的深度，越大越容易过拟合\n",
    "    'lambda':10,  # 控制模型复杂度的权重值的L2正则化项参数，参数越大，模型越不容易过拟合。\n",
    "    'subsample':0.76, # 随机采样训练样本\n",
    "    'colsample_bytree':0.95, # 生成树时进行的列采样\n",
    "    'min_child_weight':10,  \n",
    "    'silent':0 ,#设置成1则没有运行信息输出，最好是设置为0.\n",
    "    'eta': 0.1, # 如同学习率\n",
    "    'seed':77,\n",
    "    'nthread':8,# cpu 线程数\n",
    "    }\n",
    "    train = np.array(sub_df_train)\n",
    "    valid = np.array(sub_df_val)\n",
    "    n = 150\n",
    "    plst = list(params.items())\n",
    "    xgtrain = xgb.DMatrix(train, label=sub_train_label)\n",
    "    xgval = xgb.DMatrix(valid, label=sub_val_label)\n",
    "    watchlist = [(xgtrain, 'train'), (xgval, 'val')]\n",
    "    model = xgb.train(plst, xgtrain, n, watchlist, early_stopping_rounds=100)\n",
    "    model.save_model('CV_0725_'+str(nb)+'.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test_array = np.array(df_test)\n",
    "xgtest = xgb.DMatrix(df_test_array)\n",
    "xgbst = xgb.Booster()\n",
    "for i in range(1):\n",
    "    print('xgboost predict from model',str(i))\n",
    "    xgbst.load_model('./CV_0725_'+str(i)+'.model')\n",
    "    if i == 0:\n",
    "        preds = xgbst.predict(xgtest)\n",
    "    else:\n",
    "        preds += xgbst.predict(xgtest)\n",
    "preds = preds / 10.\n",
    "df_test['pred'] = preds\n",
    "THRESHOLD=0.2\n",
    "d = dict()\n",
    "for row in df_test.itertuples():\n",
    "    if row.pred > THRESHOLD:\n",
    "        try:\n",
    "            d[row.order_id] += ' ' + str(row.product_id)\n",
    "        except:\n",
    "            d[row.order_id] = str(row.product_id)\n",
    "for order in test_orders.order_id:\n",
    "    if order not in d:\n",
    "        d[order] = 'None'\n",
    "\n",
    "tst = pd.DataFrame.from_dict(d, orient='index')\n",
    "tst.reset_index(inplace=True)\n",
    "tst.columns = ['order_id', 'products']\n",
    "tst.to_csv('submission_70_features_THRESHOLD_0.2_10_fold_CV_0725.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
