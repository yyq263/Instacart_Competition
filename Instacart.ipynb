{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading aisles...\n",
      "loading department...\n",
      "loading products...\n",
      "loading prior orders...\n",
      "loading train orders...\n",
      "loading orders...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from IPython.display import display\n",
    "import xgboost as xgb\n",
    "\n",
    "print('loading aisles...')\n",
    "aisles = pd.read_csv('aisles.csv', dtype={\n",
    "        'aisle_id': np.uint16,\n",
    "        'aisle': 'category'})\n",
    "\n",
    "print('loading department...')\n",
    "department = pd.read_csv('departments.csv', dtype={\n",
    "            'department_id': np.uint8,\n",
    "            'department': 'category'})\n",
    "\n",
    "print('loading products...')\n",
    "products = pd.read_csv('products.csv', dtype={\n",
    "        'product_id': np.uint16,\n",
    "        'order_id': np.uint32,\n",
    "        'aisle_id': np.uint8,\n",
    "        'department_id': np.uint8})\n",
    "\n",
    "print('loading prior orders...')\n",
    "prior = pd.read_csv('order_products__prior.csv', dtype={\n",
    "        'order_id': np.uint32,\n",
    "        'product_id': np.uint16,\n",
    "        'add_to_cart_order': np.uint16,\n",
    "        'reordered': np.uint16})\n",
    "\n",
    "print('loading train orders...')\n",
    "train = pd.read_csv('order_products__train.csv', dtype={\n",
    "        'order_id': np.uint32,\n",
    "        'product_id': np.uint16,\n",
    "        'add_to_cart_order': np.uint16,\n",
    "        'reordered': np.uint8})\n",
    "\n",
    "print('loading orders...')\n",
    "order = pd.read_csv('orders.csv' , dtype={\n",
    "        'order_id': np.uint32,\n",
    "        'user_id': np.uint32,\n",
    "        'eval_set': 'category',\n",
    "        'order_number': np.uint16,\n",
    "        'order_dow': np.uint16,\n",
    "        'order_hour_of_day': np.uint16,\n",
    "        'days_since_prior_order': np.float32})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# best sellers\n",
    "best_seller_id = [24852, 13176, 21137, 21903, 47626, 47766, 47209, 16797, \\\n",
    "                 26209, 27966]\n",
    "most_often_reordered = [1729, 20940, 12193, 21038, 31764, 24852, 117, \\\n",
    "                       39180, 12384, 24024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Construct products information...\n",
      "Order related information...\n",
      "User related information\n"
     ]
    }
   ],
   "source": [
    "train_orders = order[order.eval_set == 'train']\n",
    "test_orders = order[order.eval_set == 'test']\n",
    "prior_orders = order[order.eval_set == 'prior']\n",
    "\n",
    "train.set_index(['order_id', 'product_id'], inplace=True, drop=False)\n",
    "# add train to prior\n",
    "prior = pd.concat([prior, train], ignore_index=True)\n",
    "order.set_index('order_id', inplace=True, drop=False)\n",
    "prior = prior.join(order, on='order_id', rsuffix='_')\n",
    "prior.drop('order_id_', inplace=True, axis=1)\n",
    "prior.set_index('order_id', inplace=True, drop=False)\n",
    "\n",
    "print('Construct products information...')\n",
    "prods = pd.DataFrame()\n",
    "prods['total_nb'] = prior.groupby(prior.product_id).size().astype(np.uint32)\n",
    "prods['nb_reorder'] = prior.groupby(prior.product_id)['reordered'].sum().astype(np.uint32)\n",
    "prods['reorder_rate'] = prods.nb_reorder / prods.total_nb.astype(np.float32)\n",
    "prods['nb_buyers'] = prior.groupby(prior.product_id)['user_id'].apply(lambda x: len(set(x))).astype(np.uint16) # unique buyers\n",
    "prods['avg_add_to_cart_order'] = prior.groupby(prior.product_id)['add_to_cart_order'].mean().astype(np.uint8)\n",
    "prods['nb_orders'] = prior.groupby(prior.product_id).size().astype(np.uint16)\n",
    "products = products.join(prods, on='product_id')\n",
    "products.set_index('product_id', drop=False, inplace=True)\n",
    "del prods\n",
    "print('Order related information...')\n",
    "ords_pri = pd.DataFrame()\n",
    "ords_pri['order_id'] = prior.groupby(prior.order_id)['order_id'].apply(lambda x: x.iloc[0])\n",
    "ords_pri.set_index('order_id', drop=False, inplace=True)\n",
    "ords_pri['nb_items'] = prior.groupby(prior.order_id)['product_id'].size().astype(np.uint8)\n",
    "ords_pri['first_item_id'] = prior.groupby(prior.order_id)['product_id'].apply(lambda x: x.iloc[0])\n",
    "ords_pri['first_item_reorder'] = prior.groupby(prior.order_id)['reordered'].apply(lambda x: x.iloc[0])\n",
    "ords_pri['nb_reorder'] = prior.groupby(prior.order_id)['reordered'].sum()\n",
    "ords_pri['reorder_ratio'] = (ords_pri['nb_reorder'] / ords_pri['nb_items']).astype(np.float32)\n",
    "print('User related information')\n",
    "users = pd.DataFrame()\n",
    "users['user_id'] = prior.groupby('user_id')['user_id'].apply(lambda x: x.iloc[0])\n",
    "users['nb_order'] = order[order.eval_set == 'prior'].groupby('user_id').size().astype(np.uint16)\n",
    "users['avg_days_between_order'] = prior.groupby('user_id')['days_since_prior_order'].mean().astype(np.float32)\n",
    "users['avg_hour_of_day'] = prior.groupby('user_id')['order_hour_of_day'].mean().astype(np.float32)\n",
    "users['nb_total_items'] = prior.groupby('user_id').size().astype(np.uint16)\n",
    "users['unique_products'] = prior.groupby('user_id')['product_id'].apply(set) # apply 对每个行或者列调用一次函数\n",
    "users['all_products'] = prior.groupby('user_id')['product_id'].apply(list)\n",
    "users['nb_distinct_items'] = (users['unique_products'].map(len)).astype(np.uint16) #map 对每个元素(element-wise)调用一次函数\n",
    "users['average_basket'] = (users.nb_total_items / users.nb_order).astype(np.float32)\n",
    "users['min_days_of_week'] = prior.groupby(prior.user_id)['order_dow'].apply(min).astype(np.uint8)\n",
    "users['max_days_of_week'] = prior.groupby(prior.user_id)['order_dow'].apply(max).astype(np.uint8)\n",
    "users['nb_1st_seller'] = users.all_products.apply(lambda X: sum([best_seller_id[0]==x for x in X]))\n",
    "users['nb_2nd_seller'] = users.all_products.apply(lambda X: sum([best_seller_id[1]==x for x in X]))\n",
    "users['nb_3rd_seller'] = users.all_products.apply(lambda X: sum([best_seller_id[2]==x for x in X]))\n",
    "users['nb_4th_seller'] = users.all_products.apply(lambda X: sum([best_seller_id[3]==x for x in X]))\n",
    "users['nb_5th_seller'] = users.all_products.apply(lambda X: sum([best_seller_id[4]==x for x in X]))\n",
    "users['nb_6th_seller'] = users.all_products.apply(lambda X: sum([best_seller_id[5]==x for x in X]))\n",
    "users['nb_7th_seller'] = users.all_products.apply(lambda X: sum([best_seller_id[6]==x for x in X]))\n",
    "users['nb_8th_seller'] = users.all_products.apply(lambda X: sum([best_seller_id[7]==x for x in X]))\n",
    "users['nb_9th_seller'] = users.all_products.apply(lambda X: sum([best_seller_id[8]==x for x in X]))\n",
    "users['nb_10th_seller'] = users.all_products.apply(lambda X: sum([best_seller_id[9]==x for x in X]))\n",
    "users['nb_1st_reorder'] = users.all_products.apply(lambda X: sum([most_often_reordered[0] == x for x in X]))\n",
    "users['nb_2nd_reorder'] = users.all_products.apply(lambda X: sum([most_often_reordered[1] == x for x in X]))\n",
    "users['nb_3rd_reorder'] = users.all_products.apply(lambda X: sum([most_often_reordered[2] == x for x in X]))\n",
    "users['nb_4th_reorder'] = users.all_products.apply(lambda X: sum([most_often_reordered[3] == x for x in X]))\n",
    "users['nb_5th_reorder'] = users.all_products.apply(lambda X: sum([most_often_reordered[4] == x for x in X]))\n",
    "users['nb_6th_reorder'] = users.all_products.apply(lambda X: sum([most_often_reordered[5] == x for x in X]))\n",
    "users['nb_7th_reorder'] = users.all_products.apply(lambda X: sum([most_often_reordered[6] == x for x in X]))\n",
    "users['nb_8th_reorder'] = users.all_products.apply(lambda X: sum([most_often_reordered[7] == x for x in X]))\n",
    "users['nb_9th_reorder'] = users.all_products.apply(lambda X: sum([most_often_reordered[8] == x for x in X]))\n",
    "users['nb_10th_reorder'] = users.all_products.apply(lambda X: sum([most_often_reordered[9] == x for x in X]))\n",
    "\n",
    "\n",
    "# Query data from ords\n",
    "users['last_order_id'] = prior_orders.groupby(prior_orders.user_id)['user_id'].apply(lambda x: x.iloc[-1])\n",
    "users['lo_nb_products'] = users.last_order_id.map(ords_pri.nb_items)\n",
    "users['lo_first_item_id'] = users.last_order_id.map(ords_pri.first_item_id)\n",
    "users['lo_first_item_reorder'] = users.last_order_id.map(ords_pri.first_item_reorder)\n",
    "users['lo_nb_reorder'] = users.last_order_id.map(ords_pri.nb_reorder)\n",
    "users['lo_reorder_ratio'] = users.last_order_id.map(ords_pri.reorder_ratio)\n",
    "\n",
    "users['last_2_order_id'] = prior_orders.groupby(prior_orders.user_id)['user_id'].apply(lambda x: x.iloc[-2])\n",
    "users['lo2_nb_products'] = users.last_2_order_id.map(ords_pri.nb_items)\n",
    "users['lo2_first_item_id'] = users.last_2_order_id.map(ords_pri.first_item_id)\n",
    "users['lo2_first_item_reorder'] = users.last_2_order_id.map(ords_pri.first_item_reorder)\n",
    "users['lo2_nb_reorder'] = users.last_2_order_id.map(ords_pri.nb_reorder)\n",
    "users['lo2_reorder_ratio'] = users.last_2_order_id.map(ords_pri.reorder_ratio)\n",
    "\n",
    "users['last_3_order_id'] = prior_orders.groupby(prior_orders.user_id)['user_id'].apply(lambda x: x.iloc[-3])\n",
    "users['lo3_nb_products'] = users.last_3_order_id.map(ords_pri.nb_items)\n",
    "users['lo3_first_item_id'] = users.last_3_order_id.map(ords_pri.first_item_id)\n",
    "users['lo3_first_item_reorder'] = users.last_3_order_id.map(ords_pri.first_item_reorder)\n",
    "users['lo3_nb_reorder'] = users.last_3_order_id.map(ords_pri.nb_reorder)\n",
    "users['lo3_reorder_ratio'] = users.last_3_order_id.map(ords_pri.reorder_ratio)\n",
    "\n",
    "del ords_pri\n",
    "print('UserXproduct_id information...')\n",
    "prior['user_product_index'] = (prior.user_id.astype(np.uint64) * 100000\\\n",
    "                               + prior.product_id).astype(np.uint64)\n",
    "d = dict()\n",
    "for row in prior.itertuples():\n",
    "    k = row.user_product_index\n",
    "    if k not in d:\n",
    "        d[k] = (1, \\\n",
    "                row.add_to_cart_order, \\\n",
    "                row.reordered, \\\n",
    "                (row.order_number, row.order_id),\\\n",
    "                row.order_dow, \\\n",
    "                row.order_hour_of_day, \\\n",
    "                row.add_to_cart_order, \\\n",
    "                row.add_to_cart_order)\n",
    "    else:\n",
    "        d[k] = (d[k][0]+1, d[k][1]+row.add_to_cart_order, \\\n",
    "                d[k][2]+row.reordered, \\\n",
    "                # find last order with that product\n",
    "                max(d[k][3], (row.order_number, row.order_id)), \\\n",
    "                d[k][4]+row.order_dow, \\\n",
    "                d[k][5]+row.order_hour_of_day, \\\n",
    "                min(d[k][6], row.add_to_cart_order), \\\n",
    "                max(d[k][7], row.add_to_cart_order))\n",
    "UserProduct = pd.DataFrame.from_dict(d, orient='index')\n",
    "del d\n",
    "UserProduct.columns = ['nb_orders', 'sum_add_to_cart_order', 'nb_reordered', \\\n",
    "                      'last_order_id', 'sum_order_dow', 'sum_order_hour_of_day', \\\n",
    "                      'min_add_to_cart_order', 'max_add_to_cart_order']\n",
    "UserProduct['nb_orders'] = UserProduct.nb_orders.astype(np.uint16) \n",
    "UserProduct['sum_add_to_cart_order'] = UserProduct.sum_add_to_cart_order.astype(np.uint16)\n",
    "UserProduct['nb_reordered'] = UserProduct.nb_reordered.astype(np.uint16)\n",
    "UserProduct['last_order_id'] = UserProduct.last_order_id.map(lambda x: x[1]).astype(np.uint32)\n",
    "UserProduct['sum_order_dow'] = UserProduct.sum_order_dow.astype(np.uint16)\n",
    "UserProduct['sum_order_hour_of_day'] = UserProduct.sum_order_hour_of_day.astype(np.uint32)\n",
    "UserProduct['min_add_to_cart_order'] = UserProduct.min_add_to_cart_order.astype(np.uint8)\n",
    "UserProduct['max_add_to_cart_order'] = UserProduct.max_add_to_cart_order.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_features(orders, labels_out=False):\n",
    "    print('generate features and labels(optional) from selected orders')\n",
    "    count=0\n",
    "    product_list = []\n",
    "    order_list = []\n",
    "    labels = []\n",
    "    for row in orders.itertuples():\n",
    "        count+=1\n",
    "        order_id = row.order_id\n",
    "        user_id = row.user_id\n",
    "        user_products = users.all_products[user_id]\n",
    "        product_list += user_products\n",
    "        order_list += [order_id] * len(user_products)\n",
    "        if labels_out:\n",
    "            labels += [(order_id, product) in train.index for product in user_products]\n",
    "        if count%10000 == 0:\n",
    "            print('order row', count)\n",
    "            \n",
    "    df = pd.DataFrame({'order_id': order_list, 'product_id': product_list}, dtype=np.int32)\n",
    "    labels = np.array(labels, dtype=np.int8)\n",
    "    del order_list\n",
    "    del product_list\n",
    "    \n",
    "    print(\"user related features<prior>\")\n",
    "    df['user_id'] = df.order_id.map(order.user_id)\n",
    "    df['user_total_orders'] = df.user_id.map(users.nb_order)\n",
    "    df['user_total_items'] = df.user_id.map(users.nb_total_items)\n",
    "    df['user_distinct_items'] = df.user_id.map(users.nb_distinct_items)\n",
    "    df['user_avg_days_between_orders'] = df.user_id.map(users.avg_days_between_order)\n",
    "    df['user_avg_basket'] = df.user_id.map(users.average_basket)\n",
    "    df['user_min_days_of_week'] = df.user_id.map(users.min_days_of_week)\n",
    "    df['user_max_days_of_week'] = df.user_id.map(users.max_days_of_week)\n",
    "    \n",
    "    df['user_nb_1st_seller'] = df.user_id.map(users.nb_1st_seller)\n",
    "    df['user_nb_2nd_seller'] = df.user_id.map(users.nb_2nd_seller)\n",
    "    df['user_nb_3rd_seller'] = df.user_id.map(users.nb_3rd_seller)\n",
    "    df['user_nb_4th_seller'] = df.user_id.map(users.nb_4th_seller)\n",
    "    df['user_nb_5th_seller'] = df.user_id.map(users.nb_5th_seller)\n",
    "    df['user_nb_6th_seller'] = df.user_id.map(users.nb_6th_seller)\n",
    "    df['user_nb_7th_seller'] = df.user_id.map(users.nb_7th_seller)\n",
    "    df['user_nb_8th_seller'] = df.user_id.map(users.nb_8th_seller)\n",
    "    df['user_nb_9th_seller'] = df.user_id.map(users.nb_9th_seller)\n",
    "    df['user_nb_10th_seller'] = df.user_id.map(users.nb_10th_seller)\n",
    "    df['user_nb_1st_reorder'] = df.user_id.map(users.nb_1st_reorder)\n",
    "    df['user_nb_2nd_reorder'] = df.user_id.map(users.nb_2nd_reorder)\n",
    "    df['user_nb_3rd_reorder'] = df.user_id.map(users.nb_3rd_reorder)\n",
    "    df['user_nb_4th_reorder'] = df.user_id.map(users.nb_4th_reorder)\n",
    "    df['user_nb_5th_reorder'] = df.user_id.map(users.nb_5th_reorder)\n",
    "    df['user_nb_6th_reorder'] = df.user_id.map(users.nb_6th_reorder)\n",
    "    df['user_nb_7th_reorder'] = df.user_id.map(users.nb_7th_reorder)\n",
    "    df['user_nb_8th_reorder'] = df.user_id.map(users.nb_8th_reorder)\n",
    "    df['user_nb_9th_reorder'] = df.user_id.map(users.nb_9th_reorder)\n",
    "    df['user_nb_10th_reorder'] = df.user_id.map(users.nb_10th_reorder)   \n",
    "    \n",
    "    df['user_last_order_id'] = df.user_id.map(users.last_order_id)\n",
    "    df['user_lo_dow'] = df.user_last_order_id.map(order.order_dow)\n",
    "    df['user_lo_hour_of_day'] = df.user_last_order_id.map(order.order_hour_of_day)\n",
    "    df['user_lo_day_since_prior'] = df.user_last_order_id.map(order.days_since_prior_order)\n",
    "    df['user_lo_nb_products'] = df.user_id.map(users.lo_nb_products)\n",
    "    df['user_lo_first_item_id'] = df.user_id.map(users.lo_first_item_id)\n",
    "    df['user_lo_first_item_reorder'] = df.user_id.map(users.lo_first_item_reorder)\n",
    "    df['user_lo_nb_reorder'] = df.user_id.map(users.lo_nb_reorder)\n",
    "    df['user_lo_reorder_ratio'] = df.user_id.map(users.lo_reorder_ratio)\n",
    "    \n",
    "    df['user_last2_order_id'] = df.user_id.map(users.last_2_order_id)\n",
    "    df['user_lo2_dow'] = df.user_last2_order_id.map(order.order_dow)\n",
    "    df['user_lo2_hour_of_day'] = df.user_last2_order_id.map(order.order_hour_of_day)\n",
    "    df['user_lo2_day_since_prior'] = df.user_last2_order_id.map(order.days_since_prior_order)\n",
    "    df['user_lo2_nb_products'] = df.user_id.map(users.lo2_nb_products)\n",
    "    df['user_lo2_first_item_id'] = df.user_id.map(users.lo2_first_item_id)\n",
    "    df['user_lo2_first_item_reorder'] = df.user_id.map(users.lo2_first_item_reorder)\n",
    "    df['user_lo2_nb_reorder'] = df.user_id.map(users.lo2_nb_reorder)\n",
    "    df['user_lo2_reorder_ratio'] = df.user_id.map(users.lo2_reorder_ratio)\n",
    "    \n",
    "    df['user_last3_order_id'] = df.user_id.map(users.last_3_order_id)\n",
    "    df['user_lo3_dow'] = df.user_last3_order_id.map(order.order_dow)\n",
    "    df['user_lo3_hour_of_day'] = df.user_last3_order_id.map(order.order_hour_of_day)\n",
    "    df['user_lo3_day_since_prior'] = df.user_last3_order_id.map(order.days_since_prior_order)\n",
    "    df['user_lo3_nb_products'] = df.user_id.map(users.lo3_nb_products)\n",
    "    df['user_lo3_first_item_id'] = df.user_id.map(users.lo3_first_item_id)\n",
    "    df['user_lo3_first_item_reorder'] = df.user_id.map(users.lo3_first_item_reorder)\n",
    "    df['user_lo3_nb_reorder'] = df.user_id.map(users.lo3_nb_reorder)\n",
    "    df['user_lo3_reorder_ratio'] = df.user_id.map(users.lo3_reorder_ratio)\n",
    "    \n",
    "    print(\"product related features<prior>\")\n",
    "    df['product_aisle_id'] = df.product_id.map(products.aisle_id)\n",
    "    df['product_department_id'] = df.product_id.map(products.department_id)\n",
    "    df['product_orders'] = df.product_id.map(products.total_nb)\n",
    "    df['product_reorders'] = df.product_id.map(products.nb_reorder)\n",
    "    df['product_reorder_rate'] = df.product_id.map(products.reorder_rate)\n",
    "    df['product_nb_buyers'] = df.product_id.map(products.nb_buyers)\n",
    "    df['product_avg_add_to_cart_order'] = df.product_id.map(products.avg_add_to_cart_order)\n",
    "    df['nb_orders'] = df.product_id.map(products.nb_orders)\n",
    "    \n",
    "    print(\"order related features<train>\")\n",
    "    df['order_hour_of_day'] = df.order_id.map(order.order_hour_of_day)\n",
    "    df['order_days_since_prior_order'] = df.order_id.map(order.days_since_prior_order)\n",
    "    df['order_day_of_week'] = df.order_id.map(order.order_dow)\n",
    "    df['order_number'] = df.order_id.map(order.order_number)\n",
    "    \n",
    "    print(\"userXproduct related features<prior>\")\n",
    "    # 1.nb_orders, 2.sum_add_to_cart_order, 3.nb_reordered, \\\n",
    "    # 4.last_order_id, 5.sum_order_dow, 6.sum_order_hour_of_day\n",
    "    df['UP'] = df.product_id+df.user_id.astype(np.uint64)*100000\n",
    "    df['UP_nb_orders'] = df.UP.map(UserProduct.nb_orders)\n",
    "    df['UP_avg_add_to_cart_order'] = df.UP.map(UserProduct.sum_add_to_cart_order)\\\n",
    "                                    / df.UP_nb_orders\n",
    "    df['UP_nb_reordered'] = df.UP.map(UserProduct.nb_reordered)\n",
    "    df['UP_reorder_ratio'] = (df.UP_nb_reordered / df.UP_nb_orders).astype(np.float32)\n",
    "    df['UP_last_order_id'] = df.UP.map(UserProduct.last_order_id)\n",
    "    df['UP_avg_order_dow'] = (df.UP.map(UserProduct.sum_order_dow)\\\n",
    "                              / df.UP_nb_orders).astype(np.float32)\n",
    "    df['UP_avg_order_hour_of_day'] = (df.UP.map(UserProduct.sum_order_hour_of_day) / \\\n",
    "                                    df.UP_nb_orders).astype(np.float32)\n",
    "    df['UP_order_ratio'] = (df.UP_nb_orders / df.user_total_orders).astype(np.float32)\n",
    "    df['UP_order_since_last'] = df.user_total_orders - \\\n",
    "                                df.UP_last_order_id.map(order.order_number)\n",
    "    #最后一次买该产品和该订单-相同产品相隔的时间(没有算日期。。。)\n",
    "    df['UP_delta_hour_vs_last'] = abs(df.order_hour_of_day - df.UP_last_order_id.map(\\\n",
    "                                       order.order_hour_of_day)).map(lambda x: min(x, 24-x)).astype(np.int8)\n",
    "    df['UP_min_add_to_cart_order'] = df.UP.map(UserProduct.min_add_to_cart_order)\n",
    "    df['UP_max_add_to_cart_order'] = df.UP.map(UserProduct.max_add_to_cart_order)\n",
    "    df.drop('UP', axis=1, inplace=True)\n",
    "    \n",
    "#     print(df.dtypes)\n",
    "#     print(df.memory_usage())\n",
    "    return(df, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('train order size: ', train_orders.shape)\n",
    "df_train, labels = gen_features(train_orders, labels_out=True)\n",
    "df_train['label'] = pd.Series(labels, dtype=np.int8)\n",
    "print('test order size: ', test_orders.shape)\n",
    "df_test, _ = gen_features(test_orders)\n",
    "del order\n",
    "del UserProduct\n",
    "del products\n",
    "del users\n",
    "df_train['label'] = pd.Series(labels, dtype=np.int8)\n",
    "del labels\n",
    "user_id_list=users.index.tolist()\n",
    "nb_user = len(user_id_list)\n",
    "val_nb_user = nb_user // 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for nb in range(10):\n",
    "    print(\"Doing Cross %d Validation\"% nb)\n",
    "    val_start = nb*val_nb_user\n",
    "    val_end = (nb+1)*val_nb_user\n",
    "    if nb==9:\n",
    "        val_end = nb_user\n",
    "    print(\"validation start: %d, end: %d\" % (val_start, val_end))\n",
    "    train_user_ids = np.concatenate((user_id_list[:val_start],\\\n",
    "                                    user_id_list[val_end:]))\n",
    "    val_user_ids = user_id_list[val_start:val_end]\n",
    "    print(\"Split train and valid data/label by user_id\")\n",
    "    sub_df_val = df_train[df_train.user_id.isin(val_user_ids)]\n",
    "    sub_df_train = df_train[df_train.user_id.isin(train_user_ids)]\n",
    "    sub_train_label = np.array(sub_df_train['label'])\n",
    "    sub_val_label = np.array(sub_df_val['label'])\n",
    "    sub_df_train.drop('label', axis=1, inplace=True)\n",
    "    sub_df_val.drop('label', axis=1, inplace=True)\n",
    "    params={\n",
    "    'booster':'gbtree',\n",
    "    'objective': 'binary:logistic', \n",
    "    'eval_metric': 'logloss',\n",
    "    'gamma':0.7,  # 用于控制是否后剪枝的参数,越大越保守，一般0.1、0.2这样子。\n",
    "    'max_depth':10, # 构建树的深度，越大越容易过拟合\n",
    "    'lambda':10,  # 控制模型复杂度的权重值的L2正则化项参数，参数越大，模型越不容易过拟合。\n",
    "    'subsample':0.76, # 随机采样训练样本\n",
    "    'colsample_bytree':0.95, # 生成树时进行的列采样\n",
    "    'min_child_weight':10,  \n",
    "    'silent':0 ,#设置成1则没有运行信息输出，最好是设置为0.\n",
    "    'eta': 0.1, # 如同学习率\n",
    "    'seed':77,\n",
    "    'nthread':8,# cpu 线程数\n",
    "    }\n",
    "    train = np.array(sub_df_train)\n",
    "    valid = np.array(sub_df_val)\n",
    "    n = 150\n",
    "    plst = list(params.items())\n",
    "    xgtrain = xgb.DMatrix(train, label=sub_train_label)\n",
    "    xgval = xgb.DMatrix(valid, label=sub_val_label)\n",
    "    watchlist = [(xgtrain, 'train'), (xgval, 'val')]\n",
    "    model = xgb.train(plst, xgtrain, n, watchlist, early_stopping_rounds=100)\n",
    "    model.save_model('CV_0725_'+str(nb)+'.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c1c8229ab21a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_test_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mxgtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mxgbst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBooster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'xgboost predict from model'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_test' is not defined"
     ]
    }
   ],
   "source": [
    "df_test_array = np.array(df_test)\n",
    "xgtest = xgb.DMatrix(df_test_array)\n",
    "xgbst = xgb.Booster()\n",
    "for i in range(10):\n",
    "    print('xgboost predict from model',str(i))\n",
    "    xgbst.load_model('./CV_0724_'+str(i)+'.model')\n",
    "    if i == 0:\n",
    "        preds = xgbst.predict(xgtest)\n",
    "    else:\n",
    "        preds += xgbst.predict(xgtest)\n",
    "preds = preds / 10.\n",
    "df_test['pred'] = preds\n",
    "THRESHOLD=0.2\n",
    "d = dict()\n",
    "for row in df_test.itertuples():\n",
    "    if row.pred > THRESHOLD:\n",
    "        try:\n",
    "            d[row.order_id] += ' ' + str(row.product_id)\n",
    "        except:\n",
    "            d[row.order_id] = str(row.product_id)\n",
    "for order in test_orders.order_id:\n",
    "    if order not in d:\n",
    "        d[order] = 'None'\n",
    "\n",
    "tst = pd.DataFrame.from_dict(d, orient='index')\n",
    "tst.reset_index(inplace=True)\n",
    "tst.columns = ['order_id', 'products']\n",
    "tst.to_csv('submission_80_features_THRESHOLD_0.2_10_fold_CV_0725.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
