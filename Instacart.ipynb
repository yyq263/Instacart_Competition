{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading aisles...\n",
      "loading department...\n",
      "loading products...\n",
      "loading prior orders...\n",
      "loading train orders...\n",
      "loading orders...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from IPython.display import display\n",
    "import xgboost as xgb\n",
    "\n",
    "print('loading aisles...')\n",
    "aisles = pd.read_csv('aisles.csv', dtype={\n",
    "        'aisle_id': np.uint16,\n",
    "        'aisle': 'category'})\n",
    "\n",
    "print('loading department...')\n",
    "department = pd.read_csv('departments.csv', dtype={\n",
    "            'department_id': np.uint8,\n",
    "            'department': 'category'})\n",
    "\n",
    "print('loading products...')\n",
    "products = pd.read_csv('products.csv', dtype={\n",
    "        'product_id': np.uint16,\n",
    "        'order_id': np.uint32,\n",
    "        'aisle_id': np.uint8,\n",
    "        'department_id': np.uint8})\n",
    "\n",
    "print('loading prior orders...')\n",
    "prior = pd.read_csv('order_products__prior.csv', dtype={\n",
    "        'order_id': np.uint32,\n",
    "        'product_id': np.uint16,\n",
    "        'add_to_cart_order': np.uint16,\n",
    "        'reordered': np.uint16})\n",
    "\n",
    "print('loading train orders...')\n",
    "train = pd.read_csv('order_products__train.csv', dtype={\n",
    "        'order_id': np.uint32,\n",
    "        'product_id': np.uint16,\n",
    "        'add_to_cart_order': np.uint16,\n",
    "        'reordered': np.uint8})\n",
    "\n",
    "print('loading orders...')\n",
    "order = pd.read_csv('orders.csv' , dtype={\n",
    "        'order_id': np.uint32,\n",
    "        'user_id': np.uint32,\n",
    "        'eval_set': 'category',\n",
    "        'order_number': np.uint16,\n",
    "        'order_dow': np.uint16,\n",
    "        'order_hour_of_day': np.uint16,\n",
    "        'days_since_prior_order': np.float32})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Construct products information...\n"
     ]
    }
   ],
   "source": [
    "train_orders = order[order.eval_set == 'train']\n",
    "test_orders = order[order.eval_set == 'test']\n",
    "prior_orders = order[order.eval_set == 'prior']\n",
    "\n",
    "train.set_index(['order_id', 'product_id'], inplace=True, drop=False)\n",
    "\n",
    "order.set_index('order_id', inplace=True, drop=False)\n",
    "prior = prior.join(order, on='order_id', rsuffix='_')\n",
    "prior.drop('order_id_', inplace=True, axis=1)\n",
    "prior.set_index('order_id', inplace=True, drop=False)\n",
    "\n",
    "print('Construct products information...')\n",
    "prods = pd.DataFrame()\n",
    "prods['total_nb'] = prior.groupby(prior.product_id).size().astype(np.uint32)\n",
    "prods['nb_reorder'] = prior.groupby(prior.product_id)['reordered'].sum().astype(np.uint32)\n",
    "prods['reorder_rate'] = prods.nb_reorder / prods.total_nb.astype(np.float32)\n",
    "prods['nb_buyers'] = prior.groupby(prior.product_id)['user_id'].apply(lambda x: len(set(x))).astype(np.uint16) # unique buyers\n",
    "prods['avg_add_to_cart_order'] = prior.groupby(prior.product_id)['add_to_cart_order'].mean().astype(np.uint8)\n",
    "prods['nb_orders'] = prior.groupby(prior.product_id).size().astype(np.uint16)\n",
    "products = products.join(prods, on='product_id')\n",
    "products.set_index('product_id', drop=False, inplace=True)\n",
    "del prods\n",
    "ords_pri = pd.DataFrame()\n",
    "ords_pri['order_id'] = prior.groupby(prior.order_id)['order_id'].apply(lambda x: x.iloc[0])\n",
    "ords_pri.set_index('order_id', drop=False, inplace=True)\n",
    "ords_pri['nb_items'] = prior.groupby(prior.order_id)['product_id'].size().astype(np.uint8)\n",
    "ords_pri['first_item_id'] = prior.groupby(prior.order_id)['product_id'].apply(lambda x: x.iloc[0])\n",
    "ords_pri['first_item_reorder'] = prior.groupby(prior.order_id)['reordered'].apply(lambda x: x.iloc[0])\n",
    "ords_pri['nb_reorder'] = prior.groupby(prior.order_id)['reordered'].sum()\n",
    "ords_pri['reorder_ratio'] = (ords_pri['nb_reorder'] / ords_pri['nb_items']).astype(np.float32)\n",
    "users = pd.DataFrame()\n",
    "users['user_id'] = prior.groupby('user_id')['user_id'].apply(lambda x: x.iloc[0])\n",
    "users['nb_order'] = order[order.eval_set == 'prior'].groupby('user_id').size().astype(np.uint16)\n",
    "users['avg_days_between_order'] = prior.groupby('user_id')['days_since_prior_order'].mean().astype(np.float32)\n",
    "users['avg_hour_of_day'] = prior.groupby('user_id')['order_hour_of_day'].mean().astype(np.float32)\n",
    "users['nb_total_items'] = prior.groupby('user_id').size().astype(np.uint16)\n",
    "users['all_products'] = prior.groupby('user_id')['product_id'].apply(set) # apply 对每个行或者列调用一次函数\n",
    "users['nb_distinct_items'] = (users['all_products'].map(len)).astype(np.uint16) #map 对每个元素(element-wise)调用一次函数\n",
    "users['average_basket'] = (users.nb_total_items / users.nb_order).astype(np.float32)\n",
    "users['min_days_of_week'] = prior.groupby(prior.user_id)['order_dow'].apply(min).astype(np.uint8)\n",
    "users['max_days_of_week'] = prior.groupby(prior.user_id)['order_dow'].apply(max).astype(np.uint8)\n",
    "# Query data from ords\n",
    "users['last_order_id'] = prior_orders.groupby(prior_orders.user_id)['user_id'].apply(lambda x: x.iloc[-1])\n",
    "users['lo_nb_products'] = users.last_order_id.map(ords_pri.nb_items)\n",
    "users['lo_first_item_id'] = users.last_order_id.map(ords_pri.first_item_id)\n",
    "users['lo_first_item_reorder'] = users.last_order_id.map(ords_pri.first_item_reorder)\n",
    "users['lo_nb_reorder'] = users.last_order_id.map(ords_pri.nb_reorder)\n",
    "users['lo_reorder_ratio'] = users.last_order_id.map(ords_pri.reorder_ratio)\n",
    "\n",
    "users['last_2_order_id'] = prior_orders.groupby(prior_orders.user_id)['user_id'].apply(lambda x: x.iloc[-2])\n",
    "users['lo2_nb_products'] = users.last_2_order_id.map(ords_pri.nb_items)\n",
    "users['lo2_first_item_id'] = users.last_2_order_id.map(ords_pri.first_item_id)\n",
    "users['lo2_first_item_reorder'] = users.last_2_order_id.map(ords_pri.first_item_reorder)\n",
    "users['lo2_nb_reorder'] = users.last_2_order_id.map(ords_pri.nb_reorder)\n",
    "users['lo2_reorder_ratio'] = users.last_2_order_id.map(ords_pri.reorder_ratio)\n",
    "\n",
    "users['last_3_order_id'] = prior_orders.groupby(prior_orders.user_id)['user_id'].apply(lambda x: x.iloc[-3])\n",
    "users['lo3_nb_products'] = users.last_3_order_id.map(ords_pri.nb_items)\n",
    "users['lo3_first_item_id'] = users.last_3_order_id.map(ords_pri.first_item_id)\n",
    "users['lo3_first_item_reorder'] = users.last_3_order_id.map(ords_pri.first_item_reorder)\n",
    "users['lo3_nb_reorder'] = users.last_3_order_id.map(ords_pri.nb_reorder)\n",
    "users['lo3_reorder_ratio'] = users.last_3_order_id.map(ords_pri.reorder_ratio)\n",
    "\n",
    "del ords_pri\n",
    "\n",
    "prior['user_product_index'] = (prior.user_id.astype(np.uint64) * 100000\\\n",
    "                               + prior.product_id).astype(np.uint64)\n",
    "d = dict()\n",
    "for row in prior.itertuples():\n",
    "    k = row.user_product_index\n",
    "    if k not in d:\n",
    "        d[k] = (1, \\\n",
    "                row.add_to_cart_order, \\\n",
    "                row.reordered, \\\n",
    "                (row.order_number, row.order_id),\\\n",
    "                row.order_dow, \\\n",
    "                row.order_hour_of_day, \\\n",
    "                row.add_to_cart_order, \\\n",
    "                row.add_to_cart_order)\n",
    "    else:\n",
    "        d[k] = (d[k][0]+1, d[k][1]+row.add_to_cart_order, \\\n",
    "                d[k][2]+row.reordered, \\\n",
    "                # find last order with that product\n",
    "                max(d[k][3], (row.order_number, row.order_id)), \\\n",
    "                d[k][4]+row.order_dow, \\\n",
    "                d[k][5]+row.order_hour_of_day, \\\n",
    "                min(d[k][6], row.add_to_cart_order), \\\n",
    "                max(d[k][7], row.add_to_cart_order))\n",
    "UserProduct = pd.DataFrame.from_dict(d, orient='index')\n",
    "del d\n",
    "UserProduct.columns = ['nb_orders', 'sum_add_to_cart_order', 'nb_reordered', \\\n",
    "                      'last_order_id', 'sum_order_dow', 'sum_order_hour_of_day', \\\n",
    "                      'min_add_to_cart_order', 'max_add_to_cart_order']\n",
    "UserProduct['nb_orders'] = UserProduct.nb_orders.astype(np.uint16) \n",
    "UserProduct['sum_add_to_cart_order'] = UserProduct.sum_add_to_cart_order.astype(np.uint16)\n",
    "UserProduct['nb_reordered'] = UserProduct.nb_reordered.astype(np.uint16)\n",
    "UserProduct['last_order_id'] = UserProduct.last_order_id.map(lambda x: x[1]).astype(np.uint32)\n",
    "UserProduct['sum_order_dow'] = UserProduct.sum_order_dow.astype(np.uint16)\n",
    "UserProduct['sum_order_hour_of_day'] = UserProduct.sum_order_hour_of_day.astype(np.uint32)\n",
    "UserProduct['min_add_to_cart_order'] = UserProduct.min_add_to_cart_order.astype(np.uint8)\n",
    "UserProduct['max_add_to_cart_order'] = UserProduct.max_add_to_cart_order.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_features(orders, labels_out=False):\n",
    "    print('generate features and labels(optional) from selected orders')\n",
    "    count=0\n",
    "    product_list = []\n",
    "    order_list = []\n",
    "    labels = []\n",
    "    for row in orders.itertuples():\n",
    "        count+=1\n",
    "        order_id = row.order_id\n",
    "        user_id = row.user_id\n",
    "        user_products = users.all_products[user_id]\n",
    "        product_list += user_products\n",
    "        order_list += [order_id] * len(user_products)\n",
    "        if labels_out:\n",
    "            labels += [(order_id, product) in train.index for product in user_products]\n",
    "        if count%10000 == 0:\n",
    "            print('order row', count)\n",
    "            \n",
    "    df = pd.DataFrame({'order_id': order_list, 'product_id': product_list}, dtype=np.int32)\n",
    "    labels = np.array(labels, dtype=np.int8)\n",
    "    del order_list\n",
    "    del product_list\n",
    "    \n",
    "    print(\"user related features<prior>\")\n",
    "    df['user_id'] = df.order_id.map(order.user_id)\n",
    "    df['user_total_orders'] = df.user_id.map(users.nb_order)\n",
    "    df['user_total_items'] = df.user_id.map(users.nb_total_items)\n",
    "    df['user_distinct_items'] = df.user_id.map(users.nb_distinct_items)\n",
    "    df['user_avg_days_between_orders'] = df.user_id.map(users.avg_days_between_order)\n",
    "    df['user_avg_basket'] = df.user_id.map(users.average_basket)\n",
    "    df['user_min_days_of_week'] = df.user_id.map(users.min_days_of_week)\n",
    "    df['user_max_days_of_week'] = df.user_id.map(users.max_days_of_week)\n",
    "    \n",
    "    df['user_last_order_id'] = df.user_id.map(users.last_order_id)\n",
    "    df['user_lo_dow'] = df.user_last_order_id.map(order.order_dow)\n",
    "    df['user_lo_hour_of_day'] = df.user_last_order_id.map(order.order_hour_of_day)\n",
    "    df['user_lo_day_since_prior'] = df.user_last_order_id.map(order.days_since_prior_order)\n",
    "    df['user_lo_nb_products'] = df.user_id.map(users.lo_nb_products)\n",
    "    df['user_lo_first_item_id'] = df.user_id.map(users.lo_first_item_id)\n",
    "    df['user_lo_first_item_reorder'] = df.user_id.map(users.lo_first_item_reorder)\n",
    "    df['user_lo_nb_reorder'] = df.user_id.map(users.lo_nb_reorder)\n",
    "    df['user_lo_reorder_ratio'] = df.user_id.map(users.lo_reorder_ratio)\n",
    "    \n",
    "    df['user_last2_order_id'] = df.user_id.map(users.last_2_order_id)\n",
    "    df['user_lo2_dow'] = df.user_last2_order_id.map(order.order_dow)\n",
    "    df['user_lo2_hour_of_day'] = df.user_last2_order_id.map(order.order_hour_of_day)\n",
    "    df['user_lo2_day_since_prior'] = df.user_last2_order_id.map(order.days_since_prior_order)\n",
    "    df['user_lo2_nb_products'] = df.user_id.map(users.lo2_nb_products)\n",
    "    df['user_lo2_first_item_id'] = df.user_id.map(users.lo2_first_item_id)\n",
    "    df['user_lo2_first_item_reorder'] = df.user_id.map(users.lo2_first_item_reorder)\n",
    "    df['user_lo2_nb_reorder'] = df.user_id.map(users.lo2_nb_reorder)\n",
    "    df['user_lo2_reorder_ratio'] = df.user_id.map(users.lo2_reorder_ratio)\n",
    "    \n",
    "    df['user_last3_order_id'] = df.user_id.map(users.last_3_order_id)\n",
    "    df['user_lo3_dow'] = df.user_last3_order_id.map(order.order_dow)\n",
    "    df['user_lo3_hour_of_day'] = df.user_last3_order_id.map(order.order_hour_of_day)\n",
    "    df['user_lo3_day_since_prior'] = df.user_last3_order_id.map(order.days_since_prior_order)\n",
    "    df['user_lo3_nb_products'] = df.user_id.map(users.lo3_nb_products)\n",
    "    df['user_lo3_first_item_id'] = df.user_id.map(users.lo3_first_item_id)\n",
    "    df['user_lo3_first_item_reorder'] = df.user_id.map(users.lo3_first_item_reorder)\n",
    "    df['user_lo3_nb_reorder'] = df.user_id.map(users.lo3_nb_reorder)\n",
    "    df['user_lo3_reorder_ratio'] = df.user_id.map(users.lo3_reorder_ratio)\n",
    "    \n",
    "    print(\"product related features<prior>\")\n",
    "    df['product_aisle_id'] = df.product_id.map(products.aisle_id)\n",
    "    df['product_department_id'] = df.product_id.map(products.department_id)\n",
    "    df['product_orders'] = df.product_id.map(products.total_nb)\n",
    "    df['product_reorders'] = df.product_id.map(products.nb_reorder)\n",
    "    df['product_reorder_rate'] = df.product_id.map(products.reorder_rate)\n",
    "    df['product_nb_buyers'] = df.product_id.map(products.nb_buyers)\n",
    "    df['product_avg_add_to_cart_order'] = df.product_id.map(products.avg_add_to_cart_order)\n",
    "    df['nb_orders'] = df.product_id.map(products.nb_orders)\n",
    "    \n",
    "    print(\"order related features<train>\")\n",
    "    df['order_hour_of_day'] = df.order_id.map(order.order_hour_of_day)\n",
    "    df['order_days_since_prior_order'] = df.order_id.map(order.days_since_prior_order)\n",
    "    df['order_day_of_week'] = df.order_id.map(order.order_dow)\n",
    "    \n",
    "    print(\"userXproduct related features<prior>\")\n",
    "    # 1.nb_orders, 2.sum_add_to_cart_order, 3.nb_reordered, \\\n",
    "    # 4.last_order_id, 5.sum_order_dow, 6.sum_order_hour_of_day\n",
    "    df['UP'] = df.product_id+df.user_id.astype(np.uint64)*100000\n",
    "    df['UP_nb_orders'] = df.UP.map(UserProduct.nb_orders)\n",
    "    df['UP_avg_add_to_cart_order'] = df.UP.map(UserProduct.sum_add_to_cart_order)\\\n",
    "                                    / df.UP_nb_orders\n",
    "    df['UP_nb_reordered'] = df.UP.map(UserProduct.nb_reordered)\n",
    "    df['UP_reorder_ratio'] = (df.UP_nb_reordered / df.UP_nb_orders).astype(np.float32)\n",
    "    df['UP_last_order_id'] = df.UP.map(UserProduct.last_order_id)\n",
    "    df['UP_avg_order_dow'] = (df.UP.map(UserProduct.sum_order_dow)\\\n",
    "                              / df.UP_nb_orders).astype(np.float32)\n",
    "    df['UP_avg_order_hour_of_day'] = (df.UP.map(UserProduct.sum_order_hour_of_day) / \\\n",
    "                                    df.UP_nb_orders).astype(np.float32)\n",
    "    df['UP_order_ratio'] = (df.UP_nb_orders / df.user_total_orders).astype(np.float32)\n",
    "    df['UP_order_since_last'] = df.user_total_orders - \\\n",
    "                                df.UP_last_order_id.map(order.order_number)\n",
    "    #最后一次买该产品和该订单-相同产品相隔的时间(没有算日期。。。)\n",
    "    df['UP_delta_hour_vs_last'] = abs(df.order_hour_of_day - df.UP_last_order_id.map(\\\n",
    "                                       order.order_hour_of_day)).map(lambda x: min(x, 24-x)).astype(np.int8)\n",
    "    df['UP_min_add_to_cart_order'] = df.UP.map(UserProduct.min_add_to_cart_order)\n",
    "    df['UP_max_add_to_cart_order'] = df.UP.map(UserProduct.max_add_to_cart_order)\n",
    "    df.drop('UP', axis=1, inplace=True)\n",
    "    \n",
    "#     print(df.dtypes)\n",
    "#     print(df.memory_usage())\n",
    "    return(df, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train order size:  (131209, 7)\n",
      "generate features and labels(optional) from selected orders\n",
      "order row 10000\n",
      "order row 20000\n",
      "order row 30000\n",
      "order row 40000\n",
      "order row 50000\n",
      "order row 60000\n",
      "order row 70000\n",
      "order row 80000\n",
      "order row 90000\n",
      "order row 100000\n",
      "order row 110000\n",
      "order row 120000\n",
      "order row 130000\n",
      "user related features<prior>\n",
      "product related features<prior>\n",
      "order related features<train>\n",
      "userXproduct related features<prior>\n",
      "test order size:  (75000, 7)\n",
      "generate features and labels(optional) from selected orders\n",
      "order row 10000\n",
      "order row 20000\n",
      "order row 30000\n",
      "order row 40000\n",
      "order row 50000\n",
      "order row 60000\n",
      "order row 70000\n",
      "user related features<prior>\n",
      "product related features<prior>\n",
      "order related features<train>\n",
      "userXproduct related features<prior>\n"
     ]
    }
   ],
   "source": [
    "print('train order size: ', train_orders.shape)\n",
    "df_train, labels = gen_features(train_orders, labels_out=True)\n",
    "df_train['label'] = pd.Series(labels, dtype=np.int8)\n",
    "print('test order size: ', test_orders.shape)\n",
    "df_test, _ = gen_features(test_orders)\n",
    "del order\n",
    "del UserProduct\n",
    "del products\n",
    "df_train['label'] = pd.Series(labels, dtype=np.int8)\n",
    "\n",
    "user_id_list=users.index.tolist()\n",
    "nb_user = len(user_id_list)\n",
    "val_nb_user = nb_user // 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing Cross 0 Validation\n",
      "validation start: 0, end: 20620\n",
      "Split train and valid data/label by user_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/py3/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "//anaconda/envs/py3/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.625364\tval-logloss:0.625497\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[1]\ttrain-logloss:0.569941\tval-logloss:0.570179\n",
      "[2]\ttrain-logloss:0.523931\tval-logloss:0.52427\n",
      "[3]\ttrain-logloss:0.48533\tval-logloss:0.485775\n",
      "[4]\ttrain-logloss:0.452657\tval-logloss:0.453206\n",
      "[5]\ttrain-logloss:0.424819\tval-logloss:0.425455\n",
      "[6]\ttrain-logloss:0.400972\tval-logloss:0.401682\n",
      "[7]\ttrain-logloss:0.380464\tval-logloss:0.381236\n",
      "[8]\ttrain-logloss:0.362761\tval-logloss:0.363603\n",
      "[9]\ttrain-logloss:0.347494\tval-logloss:0.348398\n",
      "[10]\ttrain-logloss:0.334211\tval-logloss:0.335188\n",
      "[11]\ttrain-logloss:0.32269\tval-logloss:0.323743\n",
      "[12]\ttrain-logloss:0.312648\tval-logloss:0.313753\n",
      "[13]\ttrain-logloss:0.303907\tval-logloss:0.305076\n",
      "[14]\ttrain-logloss:0.296292\tval-logloss:0.297543\n",
      "[15]\ttrain-logloss:0.289642\tval-logloss:0.290947\n",
      "[16]\ttrain-logloss:0.283839\tval-logloss:0.285185\n",
      "[17]\ttrain-logloss:0.278779\tval-logloss:0.280181\n",
      "[18]\ttrain-logloss:0.274366\tval-logloss:0.27581\n",
      "[19]\ttrain-logloss:0.270508\tval-logloss:0.272018\n",
      "[20]\ttrain-logloss:0.267146\tval-logloss:0.268725\n",
      "[21]\ttrain-logloss:0.264211\tval-logloss:0.265843\n",
      "[22]\ttrain-logloss:0.261653\tval-logloss:0.263328\n",
      "[23]\ttrain-logloss:0.259414\tval-logloss:0.261133\n",
      "[24]\ttrain-logloss:0.257453\tval-logloss:0.259222\n",
      "[25]\ttrain-logloss:0.255741\tval-logloss:0.25756\n",
      "[26]\ttrain-logloss:0.254236\tval-logloss:0.256108\n",
      "[27]\ttrain-logloss:0.252937\tval-logloss:0.254861\n",
      "[28]\ttrain-logloss:0.251785\tval-logloss:0.253757\n",
      "[29]\ttrain-logloss:0.250774\tval-logloss:0.252794\n",
      "[30]\ttrain-logloss:0.249891\tval-logloss:0.251959\n",
      "[31]\ttrain-logloss:0.249124\tval-logloss:0.251252\n",
      "[32]\ttrain-logloss:0.248447\tval-logloss:0.250627\n",
      "[33]\ttrain-logloss:0.24785\tval-logloss:0.250078\n",
      "[34]\ttrain-logloss:0.247328\tval-logloss:0.249617\n",
      "[35]\ttrain-logloss:0.246863\tval-logloss:0.249205\n",
      "[36]\ttrain-logloss:0.246451\tval-logloss:0.248847\n",
      "[37]\ttrain-logloss:0.246087\tval-logloss:0.248544\n",
      "[38]\ttrain-logloss:0.245761\tval-logloss:0.248286\n",
      "[39]\ttrain-logloss:0.245473\tval-logloss:0.24805\n",
      "[40]\ttrain-logloss:0.245191\tval-logloss:0.247833\n",
      "[41]\ttrain-logloss:0.244944\tval-logloss:0.247657\n",
      "[42]\ttrain-logloss:0.244721\tval-logloss:0.247502\n",
      "[43]\ttrain-logloss:0.244492\tval-logloss:0.247353\n",
      "[44]\ttrain-logloss:0.244318\tval-logloss:0.24724\n",
      "[45]\ttrain-logloss:0.244142\tval-logloss:0.247125\n",
      "[46]\ttrain-logloss:0.243998\tval-logloss:0.24706\n",
      "[47]\ttrain-logloss:0.243828\tval-logloss:0.246948\n",
      "[48]\ttrain-logloss:0.243715\tval-logloss:0.246886\n",
      "[49]\ttrain-logloss:0.243592\tval-logloss:0.246828\n",
      "[50]\ttrain-logloss:0.243434\tval-logloss:0.246736\n",
      "[51]\ttrain-logloss:0.243291\tval-logloss:0.246687\n",
      "[52]\ttrain-logloss:0.243152\tval-logloss:0.246622\n",
      "[53]\ttrain-logloss:0.243059\tval-logloss:0.246579\n",
      "[54]\ttrain-logloss:0.242946\tval-logloss:0.246534\n",
      "[55]\ttrain-logloss:0.242832\tval-logloss:0.24649\n",
      "[56]\ttrain-logloss:0.242726\tval-logloss:0.246468\n",
      "[57]\ttrain-logloss:0.242619\tval-logloss:0.246434\n",
      "[58]\ttrain-logloss:0.242534\tval-logloss:0.246405\n",
      "[59]\ttrain-logloss:0.242448\tval-logloss:0.24637\n",
      "[60]\ttrain-logloss:0.242367\tval-logloss:0.246342\n",
      "[61]\ttrain-logloss:0.2423\tval-logloss:0.246319\n",
      "[62]\ttrain-logloss:0.242212\tval-logloss:0.246301\n",
      "[63]\ttrain-logloss:0.242137\tval-logloss:0.246288\n",
      "[64]\ttrain-logloss:0.242053\tval-logloss:0.246277\n",
      "[65]\ttrain-logloss:0.24196\tval-logloss:0.246262\n",
      "[66]\ttrain-logloss:0.241877\tval-logloss:0.246243\n",
      "[67]\ttrain-logloss:0.241785\tval-logloss:0.246238\n",
      "[68]\ttrain-logloss:0.241683\tval-logloss:0.246218\n",
      "[69]\ttrain-logloss:0.241578\tval-logloss:0.246218\n",
      "[70]\ttrain-logloss:0.241521\tval-logloss:0.246217\n",
      "[71]\ttrain-logloss:0.241421\tval-logloss:0.246203\n",
      "[72]\ttrain-logloss:0.241363\tval-logloss:0.246188\n",
      "[73]\ttrain-logloss:0.241283\tval-logloss:0.246177\n",
      "[74]\ttrain-logloss:0.241193\tval-logloss:0.24617\n",
      "[75]\ttrain-logloss:0.241146\tval-logloss:0.246169\n",
      "[76]\ttrain-logloss:0.241092\tval-logloss:0.246162\n",
      "[77]\ttrain-logloss:0.241009\tval-logloss:0.246155\n",
      "[78]\ttrain-logloss:0.240947\tval-logloss:0.24615\n",
      "[79]\ttrain-logloss:0.240845\tval-logloss:0.246139\n",
      "[80]\ttrain-logloss:0.240747\tval-logloss:0.24614\n",
      "[81]\ttrain-logloss:0.240698\tval-logloss:0.246137\n",
      "[82]\ttrain-logloss:0.240615\tval-logloss:0.246138\n",
      "[83]\ttrain-logloss:0.240562\tval-logloss:0.246126\n",
      "[84]\ttrain-logloss:0.240505\tval-logloss:0.246119\n",
      "[85]\ttrain-logloss:0.240445\tval-logloss:0.246109\n",
      "[86]\ttrain-logloss:0.240336\tval-logloss:0.246115\n",
      "[87]\ttrain-logloss:0.24026\tval-logloss:0.246105\n",
      "[88]\ttrain-logloss:0.240179\tval-logloss:0.246083\n",
      "[89]\ttrain-logloss:0.240079\tval-logloss:0.246055\n",
      "[90]\ttrain-logloss:0.240019\tval-logloss:0.246051\n",
      "[91]\ttrain-logloss:0.239978\tval-logloss:0.246049\n",
      "[92]\ttrain-logloss:0.2399\tval-logloss:0.246042\n",
      "[93]\ttrain-logloss:0.239825\tval-logloss:0.246039\n",
      "[94]\ttrain-logloss:0.239774\tval-logloss:0.246034\n",
      "[95]\ttrain-logloss:0.239708\tval-logloss:0.246036\n",
      "[96]\ttrain-logloss:0.239671\tval-logloss:0.246034\n",
      "[97]\ttrain-logloss:0.23961\tval-logloss:0.246035\n",
      "[98]\ttrain-logloss:0.239537\tval-logloss:0.246038\n",
      "[99]\ttrain-logloss:0.239475\tval-logloss:0.246038\n",
      "[100]\ttrain-logloss:0.239403\tval-logloss:0.246029\n",
      "[101]\ttrain-logloss:0.239349\tval-logloss:0.246026\n",
      "[102]\ttrain-logloss:0.239288\tval-logloss:0.246019\n",
      "[103]\ttrain-logloss:0.239217\tval-logloss:0.246005\n",
      "[104]\ttrain-logloss:0.239165\tval-logloss:0.246002\n",
      "[105]\ttrain-logloss:0.239107\tval-logloss:0.246009\n",
      "[106]\ttrain-logloss:0.23902\tval-logloss:0.246016\n",
      "[107]\ttrain-logloss:0.238972\tval-logloss:0.246009\n",
      "[108]\ttrain-logloss:0.238917\tval-logloss:0.246003\n",
      "[109]\ttrain-logloss:0.238863\tval-logloss:0.245995\n",
      "[110]\ttrain-logloss:0.238807\tval-logloss:0.246\n",
      "[111]\ttrain-logloss:0.238732\tval-logloss:0.246003\n",
      "[112]\ttrain-logloss:0.238642\tval-logloss:0.246016\n",
      "[113]\ttrain-logloss:0.238613\tval-logloss:0.246021\n",
      "[114]\ttrain-logloss:0.238529\tval-logloss:0.246012\n",
      "[115]\ttrain-logloss:0.23847\tval-logloss:0.246009\n",
      "[116]\ttrain-logloss:0.238416\tval-logloss:0.246009\n",
      "[117]\ttrain-logloss:0.238363\tval-logloss:0.246011\n",
      "[118]\ttrain-logloss:0.238261\tval-logloss:0.246013\n",
      "[119]\ttrain-logloss:0.238144\tval-logloss:0.246005\n",
      "[120]\ttrain-logloss:0.238095\tval-logloss:0.246009\n",
      "[121]\ttrain-logloss:0.238046\tval-logloss:0.246008\n",
      "[122]\ttrain-logloss:0.237994\tval-logloss:0.246003\n",
      "[123]\ttrain-logloss:0.237904\tval-logloss:0.245984\n",
      "[124]\ttrain-logloss:0.237848\tval-logloss:0.245974\n",
      "[125]\ttrain-logloss:0.237787\tval-logloss:0.245975\n",
      "[126]\ttrain-logloss:0.237743\tval-logloss:0.245968\n",
      "[127]\ttrain-logloss:0.237684\tval-logloss:0.245968\n",
      "[128]\ttrain-logloss:0.237636\tval-logloss:0.245975\n",
      "[129]\ttrain-logloss:0.237555\tval-logloss:0.245973\n",
      "[130]\ttrain-logloss:0.237494\tval-logloss:0.245982\n",
      "[131]\ttrain-logloss:0.237408\tval-logloss:0.245974\n",
      "[132]\ttrain-logloss:0.237339\tval-logloss:0.245964\n",
      "[133]\ttrain-logloss:0.237299\tval-logloss:0.245959\n",
      "[134]\ttrain-logloss:0.237254\tval-logloss:0.245968\n",
      "[135]\ttrain-logloss:0.237206\tval-logloss:0.245972\n",
      "[136]\ttrain-logloss:0.237172\tval-logloss:0.245979\n",
      "[137]\ttrain-logloss:0.237129\tval-logloss:0.245983\n",
      "[138]\ttrain-logloss:0.237051\tval-logloss:0.245983\n",
      "[139]\ttrain-logloss:0.236998\tval-logloss:0.245988\n",
      "[140]\ttrain-logloss:0.236938\tval-logloss:0.245993\n",
      "[141]\ttrain-logloss:0.236907\tval-logloss:0.245983\n",
      "[142]\ttrain-logloss:0.236869\tval-logloss:0.245987\n",
      "[143]\ttrain-logloss:0.236822\tval-logloss:0.245989\n",
      "[144]\ttrain-logloss:0.23677\tval-logloss:0.245976\n",
      "[145]\ttrain-logloss:0.236729\tval-logloss:0.245977\n",
      "[146]\ttrain-logloss:0.236694\tval-logloss:0.24598\n",
      "[147]\ttrain-logloss:0.23663\tval-logloss:0.245977\n",
      "[148]\ttrain-logloss:0.236583\tval-logloss:0.245974\n",
      "[149]\ttrain-logloss:0.236516\tval-logloss:0.245972\n",
      "Doing Cross 1 Validation\n",
      "validation start: 20620, end: 41240\n",
      "Split train and valid data/label by user_id\n",
      "[0]\ttrain-logloss:0.626535\tval-logloss:0.626713\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[1]\ttrain-logloss:0.570878\tval-logloss:0.571189\n",
      "[2]\ttrain-logloss:0.524705\tval-logloss:0.525146\n",
      "[3]\ttrain-logloss:0.48597\tval-logloss:0.486523\n",
      "[4]\ttrain-logloss:0.453249\tval-logloss:0.453903\n",
      "[5]\ttrain-logloss:0.425313\tval-logloss:0.426067\n",
      "[6]\ttrain-logloss:0.40139\tval-logloss:0.402216\n",
      "[7]\ttrain-logloss:0.380815\tval-logloss:0.381728\n",
      "[8]\ttrain-logloss:0.363074\tval-logloss:0.364061\n",
      "[9]\ttrain-logloss:0.34771\tval-logloss:0.348774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttrain-logloss:0.334393\tval-logloss:0.335535\n",
      "[11]\ttrain-logloss:0.322825\tval-logloss:0.324027\n",
      "[12]\ttrain-logloss:0.312763\tval-logloss:0.314024\n",
      "[13]\ttrain-logloss:0.304009\tval-logloss:0.305331\n",
      "[14]\ttrain-logloss:0.296376\tval-logloss:0.297756\n",
      "[15]\ttrain-logloss:0.289718\tval-logloss:0.291157\n",
      "[16]\ttrain-logloss:0.283917\tval-logloss:0.285417\n",
      "[17]\ttrain-logloss:0.278849\tval-logloss:0.280403\n",
      "[18]\ttrain-logloss:0.274423\tval-logloss:0.276032\n",
      "[19]\ttrain-logloss:0.270554\tval-logloss:0.272221\n",
      "[20]\ttrain-logloss:0.26717\tval-logloss:0.26889\n",
      "[21]\ttrain-logloss:0.264418\tval-logloss:0.266224\n",
      "[22]\ttrain-logloss:0.261825\tval-logloss:0.26368\n",
      "[23]\ttrain-logloss:0.259559\tval-logloss:0.261472\n",
      "[24]\ttrain-logloss:0.257589\tval-logloss:0.25955\n",
      "[25]\ttrain-logloss:0.25585\tval-logloss:0.257872\n",
      "[26]\ttrain-logloss:0.25434\tval-logloss:0.256412\n",
      "[27]\ttrain-logloss:0.253018\tval-logloss:0.255144\n",
      "[28]\ttrain-logloss:0.251975\tval-logloss:0.254177\n",
      "[29]\ttrain-logloss:0.250951\tval-logloss:0.25321\n",
      "[30]\ttrain-logloss:0.250049\tval-logloss:0.252367\n",
      "[31]\ttrain-logloss:0.249261\tval-logloss:0.251644\n",
      "[32]\ttrain-logloss:0.24864\tval-logloss:0.251099\n",
      "[33]\ttrain-logloss:0.248011\tval-logloss:0.250534\n",
      "[34]\ttrain-logloss:0.247461\tval-logloss:0.250033\n",
      "[35]\ttrain-logloss:0.246965\tval-logloss:0.249602\n",
      "[36]\ttrain-logloss:0.246533\tval-logloss:0.249231\n",
      "[37]\ttrain-logloss:0.246153\tval-logloss:0.248918\n",
      "[38]\ttrain-logloss:0.245801\tval-logloss:0.248628\n",
      "[39]\ttrain-logloss:0.245497\tval-logloss:0.248387\n",
      "[40]\ttrain-logloss:0.245206\tval-logloss:0.248169\n",
      "[41]\ttrain-logloss:0.244962\tval-logloss:0.247985\n",
      "[42]\ttrain-logloss:0.244737\tval-logloss:0.247814\n",
      "[43]\ttrain-logloss:0.244535\tval-logloss:0.247672\n",
      "[44]\ttrain-logloss:0.24433\tval-logloss:0.247534\n",
      "[45]\ttrain-logloss:0.244151\tval-logloss:0.247412\n",
      "[46]\ttrain-logloss:0.243997\tval-logloss:0.247308\n",
      "[47]\ttrain-logloss:0.243831\tval-logloss:0.247208\n",
      "[48]\ttrain-logloss:0.243667\tval-logloss:0.247125\n",
      "[49]\ttrain-logloss:0.243531\tval-logloss:0.247064\n",
      "[50]\ttrain-logloss:0.243416\tval-logloss:0.247005\n",
      "[51]\ttrain-logloss:0.24329\tval-logloss:0.246944\n",
      "[52]\ttrain-logloss:0.243165\tval-logloss:0.246894\n",
      "[53]\ttrain-logloss:0.243042\tval-logloss:0.246843\n",
      "[54]\ttrain-logloss:0.242948\tval-logloss:0.246805\n",
      "[55]\ttrain-logloss:0.242839\tval-logloss:0.246776\n",
      "[56]\ttrain-logloss:0.242712\tval-logloss:0.246741\n",
      "[57]\ttrain-logloss:0.242626\tval-logloss:0.246712\n",
      "[58]\ttrain-logloss:0.242549\tval-logloss:0.246686\n",
      "[59]\ttrain-logloss:0.242441\tval-logloss:0.246657\n",
      "[60]\ttrain-logloss:0.242327\tval-logloss:0.246636\n",
      "[61]\ttrain-logloss:0.242243\tval-logloss:0.246613\n",
      "[62]\ttrain-logloss:0.24214\tval-logloss:0.246584\n",
      "[63]\ttrain-logloss:0.242073\tval-logloss:0.246568\n",
      "[64]\ttrain-logloss:0.24197\tval-logloss:0.246545\n",
      "[65]\ttrain-logloss:0.241874\tval-logloss:0.246529\n",
      "[66]\ttrain-logloss:0.241803\tval-logloss:0.246513\n",
      "[67]\ttrain-logloss:0.241756\tval-logloss:0.246499\n",
      "[68]\ttrain-logloss:0.241661\tval-logloss:0.246484\n",
      "[69]\ttrain-logloss:0.241583\tval-logloss:0.246471\n",
      "[70]\ttrain-logloss:0.241507\tval-logloss:0.246461\n",
      "[71]\ttrain-logloss:0.241435\tval-logloss:0.246454\n",
      "[72]\ttrain-logloss:0.241349\tval-logloss:0.246443\n",
      "[73]\ttrain-logloss:0.24128\tval-logloss:0.246431\n",
      "[74]\ttrain-logloss:0.241206\tval-logloss:0.246427\n",
      "[75]\ttrain-logloss:0.24111\tval-logloss:0.246415\n",
      "[76]\ttrain-logloss:0.241003\tval-logloss:0.246402\n",
      "[77]\ttrain-logloss:0.24091\tval-logloss:0.246394\n",
      "[78]\ttrain-logloss:0.240815\tval-logloss:0.246374\n",
      "[79]\ttrain-logloss:0.24073\tval-logloss:0.246364\n",
      "[80]\ttrain-logloss:0.240636\tval-logloss:0.246365\n",
      "[81]\ttrain-logloss:0.240581\tval-logloss:0.246363\n",
      "[82]\ttrain-logloss:0.240494\tval-logloss:0.246345\n",
      "[83]\ttrain-logloss:0.240429\tval-logloss:0.246338\n",
      "[84]\ttrain-logloss:0.240363\tval-logloss:0.246335\n",
      "[85]\ttrain-logloss:0.240323\tval-logloss:0.24633\n",
      "[86]\ttrain-logloss:0.240287\tval-logloss:0.246325\n",
      "[87]\ttrain-logloss:0.240236\tval-logloss:0.246324\n",
      "[88]\ttrain-logloss:0.240159\tval-logloss:0.246312\n",
      "[89]\ttrain-logloss:0.240102\tval-logloss:0.246306\n",
      "[90]\ttrain-logloss:0.240025\tval-logloss:0.246285\n",
      "[91]\ttrain-logloss:0.23995\tval-logloss:0.246289\n",
      "[92]\ttrain-logloss:0.23989\tval-logloss:0.246279\n",
      "[93]\ttrain-logloss:0.239831\tval-logloss:0.246281\n",
      "[94]\ttrain-logloss:0.239768\tval-logloss:0.246276\n",
      "[95]\ttrain-logloss:0.239685\tval-logloss:0.246244\n",
      "[96]\ttrain-logloss:0.239629\tval-logloss:0.246241\n",
      "[97]\ttrain-logloss:0.239562\tval-logloss:0.24624\n",
      "[98]\ttrain-logloss:0.239483\tval-logloss:0.246241\n",
      "[99]\ttrain-logloss:0.239407\tval-logloss:0.246245\n",
      "[100]\ttrain-logloss:0.239331\tval-logloss:0.246249\n",
      "[101]\ttrain-logloss:0.239269\tval-logloss:0.246251\n",
      "[102]\ttrain-logloss:0.23919\tval-logloss:0.246243\n",
      "[103]\ttrain-logloss:0.239143\tval-logloss:0.24623\n",
      "[104]\ttrain-logloss:0.239078\tval-logloss:0.246235\n",
      "[105]\ttrain-logloss:0.239034\tval-logloss:0.246237\n",
      "[106]\ttrain-logloss:0.238981\tval-logloss:0.246244\n",
      "[107]\ttrain-logloss:0.238929\tval-logloss:0.246249\n",
      "[108]\ttrain-logloss:0.238863\tval-logloss:0.246252\n",
      "[109]\ttrain-logloss:0.238816\tval-logloss:0.246244\n",
      "[110]\ttrain-logloss:0.238752\tval-logloss:0.246241\n",
      "[111]\ttrain-logloss:0.238679\tval-logloss:0.24623\n",
      "[112]\ttrain-logloss:0.238597\tval-logloss:0.246231\n",
      "[113]\ttrain-logloss:0.238546\tval-logloss:0.246237\n",
      "[114]\ttrain-logloss:0.238495\tval-logloss:0.246238\n",
      "[115]\ttrain-logloss:0.238432\tval-logloss:0.246225\n",
      "[116]\ttrain-logloss:0.238368\tval-logloss:0.24622\n",
      "[117]\ttrain-logloss:0.238308\tval-logloss:0.246206\n",
      "[118]\ttrain-logloss:0.23822\tval-logloss:0.246207\n",
      "[119]\ttrain-logloss:0.238172\tval-logloss:0.246197\n",
      "[120]\ttrain-logloss:0.238102\tval-logloss:0.246188\n",
      "[121]\ttrain-logloss:0.238042\tval-logloss:0.246186\n",
      "[122]\ttrain-logloss:0.238006\tval-logloss:0.246182\n",
      "[123]\ttrain-logloss:0.237918\tval-logloss:0.246162\n",
      "[124]\ttrain-logloss:0.237862\tval-logloss:0.246161\n",
      "[125]\ttrain-logloss:0.237784\tval-logloss:0.246166\n",
      "[126]\ttrain-logloss:0.237739\tval-logloss:0.246169\n",
      "[127]\ttrain-logloss:0.237641\tval-logloss:0.246165\n",
      "[128]\ttrain-logloss:0.237547\tval-logloss:0.24617\n",
      "[129]\ttrain-logloss:0.237457\tval-logloss:0.246182\n",
      "[130]\ttrain-logloss:0.237414\tval-logloss:0.246182\n",
      "[131]\ttrain-logloss:0.237347\tval-logloss:0.246176\n",
      "[132]\ttrain-logloss:0.237275\tval-logloss:0.246181\n",
      "[133]\ttrain-logloss:0.237187\tval-logloss:0.246184\n",
      "[134]\ttrain-logloss:0.237119\tval-logloss:0.246168\n",
      "[135]\ttrain-logloss:0.237053\tval-logloss:0.246173\n",
      "[136]\ttrain-logloss:0.237001\tval-logloss:0.24617\n",
      "[137]\ttrain-logloss:0.236936\tval-logloss:0.246175\n",
      "[138]\ttrain-logloss:0.236901\tval-logloss:0.246176\n",
      "[139]\ttrain-logloss:0.236816\tval-logloss:0.24618\n",
      "[140]\ttrain-logloss:0.236768\tval-logloss:0.246179\n",
      "[141]\ttrain-logloss:0.236709\tval-logloss:0.246189\n",
      "[142]\ttrain-logloss:0.236654\tval-logloss:0.246194\n",
      "[143]\ttrain-logloss:0.236573\tval-logloss:0.246184\n",
      "[144]\ttrain-logloss:0.236529\tval-logloss:0.24618\n",
      "[145]\ttrain-logloss:0.236471\tval-logloss:0.24618\n",
      "[146]\ttrain-logloss:0.236384\tval-logloss:0.246191\n",
      "[147]\ttrain-logloss:0.236328\tval-logloss:0.246194\n",
      "[148]\ttrain-logloss:0.236291\tval-logloss:0.246197\n",
      "[149]\ttrain-logloss:0.236245\tval-logloss:0.246203\n",
      "Doing Cross 2 Validation\n",
      "validation start: 41240, end: 61860\n",
      "Split train and valid data/label by user_id\n",
      "[0]\ttrain-logloss:0.625378\tval-logloss:0.625323\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[1]\ttrain-logloss:0.569947\tval-logloss:0.569864\n",
      "[2]\ttrain-logloss:0.523951\tval-logloss:0.523847\n",
      "[3]\ttrain-logloss:0.485343\tval-logloss:0.485231\n",
      "[4]\ttrain-logloss:0.452676\tval-logloss:0.452576\n",
      "[5]\ttrain-logloss:0.424845\tval-logloss:0.42476\n",
      "[6]\ttrain-logloss:0.401006\tval-logloss:0.400929\n",
      "[7]\ttrain-logloss:0.3805\tval-logloss:0.380439\n",
      "[8]\ttrain-logloss:0.362811\tval-logloss:0.362774\n",
      "[9]\ttrain-logloss:0.347506\tval-logloss:0.347503\n",
      "[10]\ttrain-logloss:0.334235\tval-logloss:0.334268\n",
      "[11]\ttrain-logloss:0.322707\tval-logloss:0.322767\n",
      "[12]\ttrain-logloss:0.312693\tval-logloss:0.312782\n",
      "[13]\ttrain-logloss:0.30396\tval-logloss:0.304077\n",
      "[14]\ttrain-logloss:0.296356\tval-logloss:0.2965\n",
      "[15]\ttrain-logloss:0.289722\tval-logloss:0.289908\n",
      "[16]\ttrain-logloss:0.283927\tval-logloss:0.284153\n",
      "[17]\ttrain-logloss:0.27887\tval-logloss:0.279129\n",
      "[18]\ttrain-logloss:0.27446\tval-logloss:0.274761\n",
      "[19]\ttrain-logloss:0.270616\tval-logloss:0.270955\n",
      "[20]\ttrain-logloss:0.267252\tval-logloss:0.267634\n",
      "[21]\ttrain-logloss:0.264314\tval-logloss:0.264737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22]\ttrain-logloss:0.261921\tval-logloss:0.262405\n",
      "[23]\ttrain-logloss:0.259665\tval-logloss:0.260198\n",
      "[24]\ttrain-logloss:0.257702\tval-logloss:0.258276\n",
      "[25]\ttrain-logloss:0.255977\tval-logloss:0.256594\n",
      "[26]\ttrain-logloss:0.254462\tval-logloss:0.255134\n",
      "[27]\ttrain-logloss:0.253138\tval-logloss:0.253864\n",
      "[28]\ttrain-logloss:0.251992\tval-logloss:0.252762\n",
      "[29]\ttrain-logloss:0.25099\tval-logloss:0.251806\n",
      "[30]\ttrain-logloss:0.250109\tval-logloss:0.25098\n",
      "[31]\ttrain-logloss:0.249313\tval-logloss:0.250262\n",
      "[32]\ttrain-logloss:0.248616\tval-logloss:0.249628\n",
      "[33]\ttrain-logloss:0.248017\tval-logloss:0.249088\n",
      "[34]\ttrain-logloss:0.247476\tval-logloss:0.248616\n",
      "[35]\ttrain-logloss:0.246996\tval-logloss:0.248204\n",
      "[36]\ttrain-logloss:0.246595\tval-logloss:0.247858\n",
      "[37]\ttrain-logloss:0.246208\tval-logloss:0.247539\n",
      "[38]\ttrain-logloss:0.245881\tval-logloss:0.247281\n",
      "[39]\ttrain-logloss:0.245588\tval-logloss:0.247051\n",
      "[40]\ttrain-logloss:0.245305\tval-logloss:0.246833\n",
      "[41]\ttrain-logloss:0.245054\tval-logloss:0.246647\n",
      "[42]\ttrain-logloss:0.244826\tval-logloss:0.246477\n",
      "[43]\ttrain-logloss:0.244629\tval-logloss:0.246341\n",
      "[44]\ttrain-logloss:0.244446\tval-logloss:0.246222\n",
      "[45]\ttrain-logloss:0.244271\tval-logloss:0.24611\n",
      "[46]\ttrain-logloss:0.244095\tval-logloss:0.245998\n",
      "[47]\ttrain-logloss:0.243965\tval-logloss:0.245918\n",
      "[48]\ttrain-logloss:0.243804\tval-logloss:0.245829\n",
      "[49]\ttrain-logloss:0.243664\tval-logloss:0.245759\n",
      "[50]\ttrain-logloss:0.24355\tval-logloss:0.2457\n",
      "[51]\ttrain-logloss:0.243428\tval-logloss:0.245635\n",
      "[52]\ttrain-logloss:0.243294\tval-logloss:0.245565\n",
      "[53]\ttrain-logloss:0.243198\tval-logloss:0.245523\n",
      "[54]\ttrain-logloss:0.243079\tval-logloss:0.245489\n",
      "[55]\ttrain-logloss:0.242961\tval-logloss:0.245455\n",
      "[56]\ttrain-logloss:0.242849\tval-logloss:0.245412\n",
      "[57]\ttrain-logloss:0.24274\tval-logloss:0.245387\n",
      "[58]\ttrain-logloss:0.242654\tval-logloss:0.245371\n",
      "[59]\ttrain-logloss:0.242565\tval-logloss:0.245327\n",
      "[60]\ttrain-logloss:0.242477\tval-logloss:0.245306\n",
      "[61]\ttrain-logloss:0.242382\tval-logloss:0.245264\n",
      "[62]\ttrain-logloss:0.242282\tval-logloss:0.245246\n",
      "[63]\ttrain-logloss:0.242214\tval-logloss:0.245229\n",
      "[64]\ttrain-logloss:0.242113\tval-logloss:0.245206\n",
      "[65]\ttrain-logloss:0.242028\tval-logloss:0.245193\n",
      "[66]\ttrain-logloss:0.24192\tval-logloss:0.245183\n",
      "[67]\ttrain-logloss:0.241851\tval-logloss:0.245178\n",
      "[68]\ttrain-logloss:0.241768\tval-logloss:0.245173\n",
      "[69]\ttrain-logloss:0.2417\tval-logloss:0.245157\n",
      "[70]\ttrain-logloss:0.241652\tval-logloss:0.245143\n",
      "[71]\ttrain-logloss:0.24154\tval-logloss:0.245132\n",
      "[72]\ttrain-logloss:0.241478\tval-logloss:0.245121\n",
      "[73]\ttrain-logloss:0.241386\tval-logloss:0.24511\n",
      "[74]\ttrain-logloss:0.241262\tval-logloss:0.245094\n",
      "[75]\ttrain-logloss:0.241187\tval-logloss:0.245088\n",
      "[76]\ttrain-logloss:0.241077\tval-logloss:0.245086\n",
      "[77]\ttrain-logloss:0.24101\tval-logloss:0.245077\n",
      "[78]\ttrain-logloss:0.240966\tval-logloss:0.245077\n",
      "[79]\ttrain-logloss:0.24092\tval-logloss:0.245069\n",
      "[80]\ttrain-logloss:0.240842\tval-logloss:0.245054\n",
      "[81]\ttrain-logloss:0.240775\tval-logloss:0.245043\n",
      "[82]\ttrain-logloss:0.240645\tval-logloss:0.245038\n",
      "[83]\ttrain-logloss:0.240591\tval-logloss:0.245033\n",
      "[84]\ttrain-logloss:0.240493\tval-logloss:0.245028\n",
      "[85]\ttrain-logloss:0.240395\tval-logloss:0.245024\n",
      "[86]\ttrain-logloss:0.240347\tval-logloss:0.24502\n",
      "[87]\ttrain-logloss:0.240244\tval-logloss:0.24503\n",
      "[88]\ttrain-logloss:0.24016\tval-logloss:0.24502\n",
      "[89]\ttrain-logloss:0.240075\tval-logloss:0.245009\n",
      "[90]\ttrain-logloss:0.240015\tval-logloss:0.245005\n",
      "[91]\ttrain-logloss:0.239968\tval-logloss:0.245003\n",
      "[92]\ttrain-logloss:0.239901\tval-logloss:0.245005\n",
      "[93]\ttrain-logloss:0.239865\tval-logloss:0.244999\n",
      "[94]\ttrain-logloss:0.239785\tval-logloss:0.245006\n",
      "[95]\ttrain-logloss:0.239705\tval-logloss:0.245002\n",
      "[96]\ttrain-logloss:0.239666\tval-logloss:0.244992\n",
      "[97]\ttrain-logloss:0.239576\tval-logloss:0.244995\n",
      "[98]\ttrain-logloss:0.239469\tval-logloss:0.244998\n",
      "[99]\ttrain-logloss:0.239397\tval-logloss:0.244995\n",
      "[100]\ttrain-logloss:0.239333\tval-logloss:0.244994\n",
      "[101]\ttrain-logloss:0.239304\tval-logloss:0.244991\n",
      "[102]\ttrain-logloss:0.239218\tval-logloss:0.244999\n",
      "[103]\ttrain-logloss:0.239183\tval-logloss:0.244996\n",
      "[104]\ttrain-logloss:0.239121\tval-logloss:0.244992\n",
      "[105]\ttrain-logloss:0.239084\tval-logloss:0.24499\n",
      "[106]\ttrain-logloss:0.239031\tval-logloss:0.244998\n",
      "[107]\ttrain-logloss:0.238982\tval-logloss:0.244997\n",
      "[108]\ttrain-logloss:0.238915\tval-logloss:0.245\n",
      "[109]\ttrain-logloss:0.238825\tval-logloss:0.244997\n",
      "[110]\ttrain-logloss:0.238786\tval-logloss:0.244995\n",
      "[111]\ttrain-logloss:0.238713\tval-logloss:0.244995\n",
      "[112]\ttrain-logloss:0.238645\tval-logloss:0.244995\n",
      "[113]\ttrain-logloss:0.238601\tval-logloss:0.24499\n",
      "[114]\ttrain-logloss:0.238541\tval-logloss:0.244993\n",
      "[115]\ttrain-logloss:0.23848\tval-logloss:0.244973\n",
      "[116]\ttrain-logloss:0.238414\tval-logloss:0.244972\n",
      "[117]\ttrain-logloss:0.238326\tval-logloss:0.244978\n",
      "[118]\ttrain-logloss:0.238279\tval-logloss:0.244979\n",
      "[119]\ttrain-logloss:0.238214\tval-logloss:0.244986\n",
      "[120]\ttrain-logloss:0.23814\tval-logloss:0.244994\n",
      "[121]\ttrain-logloss:0.238089\tval-logloss:0.244996\n",
      "[122]\ttrain-logloss:0.23801\tval-logloss:0.245016\n",
      "[123]\ttrain-logloss:0.237952\tval-logloss:0.24502\n",
      "[124]\ttrain-logloss:0.237896\tval-logloss:0.245026\n",
      "[125]\ttrain-logloss:0.237771\tval-logloss:0.245021\n",
      "[126]\ttrain-logloss:0.237696\tval-logloss:0.245005\n",
      "[127]\ttrain-logloss:0.237588\tval-logloss:0.245006\n",
      "[128]\ttrain-logloss:0.237526\tval-logloss:0.245004\n",
      "[129]\ttrain-logloss:0.237474\tval-logloss:0.245006\n",
      "[130]\ttrain-logloss:0.237404\tval-logloss:0.245007\n",
      "[131]\ttrain-logloss:0.237296\tval-logloss:0.245003\n",
      "[132]\ttrain-logloss:0.23724\tval-logloss:0.245005\n",
      "[133]\ttrain-logloss:0.237184\tval-logloss:0.245014\n",
      "[134]\ttrain-logloss:0.237126\tval-logloss:0.245015\n",
      "[135]\ttrain-logloss:0.237067\tval-logloss:0.245013\n",
      "[136]\ttrain-logloss:0.23701\tval-logloss:0.245014\n",
      "[137]\ttrain-logloss:0.236934\tval-logloss:0.245009\n",
      "[138]\ttrain-logloss:0.236873\tval-logloss:0.245007\n",
      "[139]\ttrain-logloss:0.236814\tval-logloss:0.245005\n",
      "[140]\ttrain-logloss:0.236793\tval-logloss:0.245\n",
      "[141]\ttrain-logloss:0.236726\tval-logloss:0.244993\n",
      "[142]\ttrain-logloss:0.236676\tval-logloss:0.24499\n",
      "[143]\ttrain-logloss:0.236618\tval-logloss:0.244985\n",
      "[144]\ttrain-logloss:0.236574\tval-logloss:0.244986\n",
      "[145]\ttrain-logloss:0.236493\tval-logloss:0.244988\n",
      "[146]\ttrain-logloss:0.236456\tval-logloss:0.244988\n",
      "[147]\ttrain-logloss:0.236381\tval-logloss:0.244977\n",
      "[148]\ttrain-logloss:0.2363\tval-logloss:0.24497\n",
      "[149]\ttrain-logloss:0.236251\tval-logloss:0.244969\n",
      "Doing Cross 3 Validation\n",
      "validation start: 61860, end: 82480\n",
      "Split train and valid data/label by user_id\n",
      "[0]\ttrain-logloss:0.625394\tval-logloss:0.625279\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[1]\ttrain-logloss:0.569979\tval-logloss:0.569773\n",
      "[2]\ttrain-logloss:0.523985\tval-logloss:0.523709\n",
      "[3]\ttrain-logloss:0.485402\tval-logloss:0.485073\n",
      "[4]\ttrain-logloss:0.452756\tval-logloss:0.452381\n",
      "[5]\ttrain-logloss:0.424916\tval-logloss:0.424508\n",
      "[6]\ttrain-logloss:0.401146\tval-logloss:0.400713\n",
      "[7]\ttrain-logloss:0.380617\tval-logloss:0.380168\n",
      "[8]\ttrain-logloss:0.362905\tval-logloss:0.362448\n",
      "[9]\ttrain-logloss:0.3476\tval-logloss:0.347138\n",
      "[10]\ttrain-logloss:0.334323\tval-logloss:0.333864\n",
      "[11]\ttrain-logloss:0.322792\tval-logloss:0.322338\n",
      "[12]\ttrain-logloss:0.312781\tval-logloss:0.312335\n",
      "[13]\ttrain-logloss:0.304044\tval-logloss:0.303605\n",
      "[14]\ttrain-logloss:0.296467\tval-logloss:0.296038\n",
      "[15]\ttrain-logloss:0.289826\tval-logloss:0.289415\n",
      "[16]\ttrain-logloss:0.284029\tval-logloss:0.283638\n",
      "[17]\ttrain-logloss:0.27897\tval-logloss:0.278598\n",
      "[18]\ttrain-logloss:0.274573\tval-logloss:0.274221\n",
      "[19]\ttrain-logloss:0.270718\tval-logloss:0.270384\n",
      "[20]\ttrain-logloss:0.267353\tval-logloss:0.267043\n",
      "[21]\ttrain-logloss:0.264415\tval-logloss:0.264127\n",
      "[22]\ttrain-logloss:0.261858\tval-logloss:0.261598\n",
      "[23]\ttrain-logloss:0.259611\tval-logloss:0.259385\n",
      "[24]\ttrain-logloss:0.257655\tval-logloss:0.257472\n",
      "[25]\ttrain-logloss:0.25595\tval-logloss:0.2558\n",
      "[26]\ttrain-logloss:0.254454\tval-logloss:0.254347\n",
      "[27]\ttrain-logloss:0.253148\tval-logloss:0.253073\n",
      "[28]\ttrain-logloss:0.252014\tval-logloss:0.251981\n",
      "[29]\ttrain-logloss:0.251008\tval-logloss:0.25102\n",
      "[30]\ttrain-logloss:0.250211\tval-logloss:0.250284\n",
      "[31]\ttrain-logloss:0.249435\tval-logloss:0.249556\n",
      "[32]\ttrain-logloss:0.248751\tval-logloss:0.248916\n",
      "[33]\ttrain-logloss:0.248141\tval-logloss:0.248369\n",
      "[34]\ttrain-logloss:0.24761\tval-logloss:0.247895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35]\ttrain-logloss:0.247133\tval-logloss:0.247479\n",
      "[36]\ttrain-logloss:0.246749\tval-logloss:0.247167\n",
      "[37]\ttrain-logloss:0.246371\tval-logloss:0.246847\n",
      "[38]\ttrain-logloss:0.246021\tval-logloss:0.246543\n",
      "[39]\ttrain-logloss:0.245722\tval-logloss:0.246292\n",
      "[40]\ttrain-logloss:0.245457\tval-logloss:0.246086\n",
      "[41]\ttrain-logloss:0.245193\tval-logloss:0.245898\n",
      "[42]\ttrain-logloss:0.244976\tval-logloss:0.245733\n",
      "[43]\ttrain-logloss:0.244751\tval-logloss:0.245568\n",
      "[44]\ttrain-logloss:0.244564\tval-logloss:0.245442\n",
      "[45]\ttrain-logloss:0.244384\tval-logloss:0.245319\n",
      "[46]\ttrain-logloss:0.244224\tval-logloss:0.245215\n",
      "[47]\ttrain-logloss:0.24408\tval-logloss:0.245125\n",
      "[48]\ttrain-logloss:0.243924\tval-logloss:0.245047\n",
      "[49]\ttrain-logloss:0.243797\tval-logloss:0.244969\n",
      "[50]\ttrain-logloss:0.243675\tval-logloss:0.24491\n",
      "[51]\ttrain-logloss:0.243557\tval-logloss:0.244847\n",
      "[52]\ttrain-logloss:0.243423\tval-logloss:0.244793\n",
      "[53]\ttrain-logloss:0.243305\tval-logloss:0.244737\n",
      "[54]\ttrain-logloss:0.243156\tval-logloss:0.244686\n",
      "[55]\ttrain-logloss:0.243064\tval-logloss:0.244642\n",
      "[56]\ttrain-logloss:0.242954\tval-logloss:0.244602\n",
      "[57]\ttrain-logloss:0.24286\tval-logloss:0.244575\n",
      "[58]\ttrain-logloss:0.242757\tval-logloss:0.244532\n",
      "[59]\ttrain-logloss:0.242619\tval-logloss:0.244496\n",
      "[60]\ttrain-logloss:0.242536\tval-logloss:0.24448\n",
      "[61]\ttrain-logloss:0.24245\tval-logloss:0.244462\n",
      "[62]\ttrain-logloss:0.242345\tval-logloss:0.244438\n",
      "[63]\ttrain-logloss:0.242246\tval-logloss:0.244422\n",
      "[64]\ttrain-logloss:0.242169\tval-logloss:0.244396\n",
      "[65]\ttrain-logloss:0.242098\tval-logloss:0.244378\n",
      "[66]\ttrain-logloss:0.241996\tval-logloss:0.244353\n",
      "[67]\ttrain-logloss:0.241908\tval-logloss:0.244335\n",
      "[68]\ttrain-logloss:0.241855\tval-logloss:0.24432\n",
      "[69]\ttrain-logloss:0.241775\tval-logloss:0.244306\n",
      "[70]\ttrain-logloss:0.241698\tval-logloss:0.244294\n",
      "[71]\ttrain-logloss:0.241625\tval-logloss:0.244283\n",
      "[72]\ttrain-logloss:0.241565\tval-logloss:0.244274\n",
      "[73]\ttrain-logloss:0.241478\tval-logloss:0.244277\n",
      "[74]\ttrain-logloss:0.24142\tval-logloss:0.244266\n",
      "[75]\ttrain-logloss:0.241318\tval-logloss:0.244269\n",
      "[76]\ttrain-logloss:0.241238\tval-logloss:0.244267\n",
      "[77]\ttrain-logloss:0.241169\tval-logloss:0.244242\n",
      "[78]\ttrain-logloss:0.241086\tval-logloss:0.244249\n",
      "[79]\ttrain-logloss:0.241049\tval-logloss:0.244242\n",
      "[80]\ttrain-logloss:0.240968\tval-logloss:0.244239\n",
      "[81]\ttrain-logloss:0.240911\tval-logloss:0.24423\n",
      "[82]\ttrain-logloss:0.240837\tval-logloss:0.244226\n",
      "[83]\ttrain-logloss:0.240763\tval-logloss:0.244219\n",
      "[84]\ttrain-logloss:0.240706\tval-logloss:0.244207\n",
      "[85]\ttrain-logloss:0.24064\tval-logloss:0.244203\n",
      "[86]\ttrain-logloss:0.240532\tval-logloss:0.244199\n",
      "[87]\ttrain-logloss:0.240474\tval-logloss:0.244199\n",
      "[88]\ttrain-logloss:0.240403\tval-logloss:0.24419\n",
      "[89]\ttrain-logloss:0.240312\tval-logloss:0.244179\n",
      "[90]\ttrain-logloss:0.240246\tval-logloss:0.244172\n",
      "[91]\ttrain-logloss:0.240187\tval-logloss:0.244173\n",
      "[92]\ttrain-logloss:0.24011\tval-logloss:0.244164\n",
      "[93]\ttrain-logloss:0.24004\tval-logloss:0.244159\n",
      "[94]\ttrain-logloss:0.23995\tval-logloss:0.244159\n",
      "[95]\ttrain-logloss:0.239889\tval-logloss:0.244147\n",
      "[96]\ttrain-logloss:0.239834\tval-logloss:0.244142\n",
      "[97]\ttrain-logloss:0.239774\tval-logloss:0.244136\n",
      "[98]\ttrain-logloss:0.239723\tval-logloss:0.244123\n",
      "[99]\ttrain-logloss:0.239645\tval-logloss:0.244109\n",
      "[100]\ttrain-logloss:0.239576\tval-logloss:0.244115\n",
      "[101]\ttrain-logloss:0.239483\tval-logloss:0.244111\n",
      "[102]\ttrain-logloss:0.239404\tval-logloss:0.244108\n",
      "[103]\ttrain-logloss:0.239328\tval-logloss:0.244092\n",
      "[104]\ttrain-logloss:0.239269\tval-logloss:0.244086\n",
      "[105]\ttrain-logloss:0.239197\tval-logloss:0.244096\n",
      "[106]\ttrain-logloss:0.239131\tval-logloss:0.244094\n",
      "[107]\ttrain-logloss:0.239053\tval-logloss:0.244111\n",
      "[108]\ttrain-logloss:0.239002\tval-logloss:0.244107\n",
      "[109]\ttrain-logloss:0.238904\tval-logloss:0.24411\n",
      "[110]\ttrain-logloss:0.238836\tval-logloss:0.244098\n",
      "[111]\ttrain-logloss:0.238784\tval-logloss:0.244101\n",
      "[112]\ttrain-logloss:0.238723\tval-logloss:0.244111\n",
      "[113]\ttrain-logloss:0.238685\tval-logloss:0.244107\n",
      "[114]\ttrain-logloss:0.238617\tval-logloss:0.244099\n",
      "[115]\ttrain-logloss:0.23854\tval-logloss:0.244076\n",
      "[116]\ttrain-logloss:0.238474\tval-logloss:0.244078\n",
      "[117]\ttrain-logloss:0.238394\tval-logloss:0.244085\n",
      "[118]\ttrain-logloss:0.238359\tval-logloss:0.244083\n",
      "[119]\ttrain-logloss:0.238287\tval-logloss:0.24408\n",
      "[120]\ttrain-logloss:0.238235\tval-logloss:0.244087\n",
      "[121]\ttrain-logloss:0.238163\tval-logloss:0.244088\n",
      "[122]\ttrain-logloss:0.238104\tval-logloss:0.244088\n",
      "[123]\ttrain-logloss:0.238039\tval-logloss:0.24409\n",
      "[124]\ttrain-logloss:0.237971\tval-logloss:0.244092\n",
      "[125]\ttrain-logloss:0.237919\tval-logloss:0.244094\n",
      "[126]\ttrain-logloss:0.237881\tval-logloss:0.24409\n",
      "[127]\ttrain-logloss:0.237828\tval-logloss:0.244092\n",
      "[128]\ttrain-logloss:0.237766\tval-logloss:0.244088\n",
      "[129]\ttrain-logloss:0.237724\tval-logloss:0.244084\n",
      "[130]\ttrain-logloss:0.23766\tval-logloss:0.244073\n",
      "[131]\ttrain-logloss:0.237585\tval-logloss:0.244064\n",
      "[132]\ttrain-logloss:0.237535\tval-logloss:0.244063\n",
      "[133]\ttrain-logloss:0.237467\tval-logloss:0.244062\n",
      "[134]\ttrain-logloss:0.23739\tval-logloss:0.244065\n",
      "[135]\ttrain-logloss:0.237346\tval-logloss:0.244067\n",
      "[136]\ttrain-logloss:0.237307\tval-logloss:0.244064\n",
      "[137]\ttrain-logloss:0.237267\tval-logloss:0.244057\n",
      "[138]\ttrain-logloss:0.237208\tval-logloss:0.244059\n",
      "[139]\ttrain-logloss:0.237144\tval-logloss:0.244062\n",
      "[140]\ttrain-logloss:0.237095\tval-logloss:0.244069\n",
      "[141]\ttrain-logloss:0.237057\tval-logloss:0.244071\n",
      "[142]\ttrain-logloss:0.237009\tval-logloss:0.244071\n",
      "[143]\ttrain-logloss:0.236973\tval-logloss:0.244056\n",
      "[144]\ttrain-logloss:0.236919\tval-logloss:0.244063\n",
      "[145]\ttrain-logloss:0.236878\tval-logloss:0.244067\n",
      "[146]\ttrain-logloss:0.236803\tval-logloss:0.244065\n",
      "[147]\ttrain-logloss:0.236727\tval-logloss:0.244072\n",
      "[148]\ttrain-logloss:0.236678\tval-logloss:0.244071\n",
      "[149]\ttrain-logloss:0.236596\tval-logloss:0.244062\n",
      "Doing Cross 4 Validation\n",
      "validation start: 82480, end: 103100\n",
      "Split train and valid data/label by user_id\n",
      "[0]\ttrain-logloss:0.625389\tval-logloss:0.625347\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[1]\ttrain-logloss:0.569966\tval-logloss:0.569875\n",
      "[2]\ttrain-logloss:0.523971\tval-logloss:0.523851\n",
      "[3]\ttrain-logloss:0.485386\tval-logloss:0.485242\n",
      "[4]\ttrain-logloss:0.452745\tval-logloss:0.452567\n",
      "[5]\ttrain-logloss:0.424904\tval-logloss:0.424717\n",
      "[6]\ttrain-logloss:0.401102\tval-logloss:0.400911\n",
      "[7]\ttrain-logloss:0.380587\tval-logloss:0.380396\n",
      "[8]\ttrain-logloss:0.3629\tval-logloss:0.362707\n",
      "[9]\ttrain-logloss:0.347596\tval-logloss:0.347403\n",
      "[10]\ttrain-logloss:0.334325\tval-logloss:0.334139\n",
      "[11]\ttrain-logloss:0.322787\tval-logloss:0.322603\n",
      "[12]\ttrain-logloss:0.312756\tval-logloss:0.312576\n",
      "[13]\ttrain-logloss:0.304014\tval-logloss:0.303842\n",
      "[14]\ttrain-logloss:0.296405\tval-logloss:0.29624\n",
      "[15]\ttrain-logloss:0.289782\tval-logloss:0.289635\n",
      "[16]\ttrain-logloss:0.28399\tval-logloss:0.28386\n",
      "[17]\ttrain-logloss:0.278953\tval-logloss:0.278852\n",
      "[18]\ttrain-logloss:0.274542\tval-logloss:0.274463\n",
      "[19]\ttrain-logloss:0.270681\tval-logloss:0.270633\n",
      "[20]\ttrain-logloss:0.267321\tval-logloss:0.267299\n",
      "[21]\ttrain-logloss:0.264385\tval-logloss:0.264388\n",
      "[22]\ttrain-logloss:0.261822\tval-logloss:0.26185\n",
      "[23]\ttrain-logloss:0.25958\tval-logloss:0.25965\n",
      "[24]\ttrain-logloss:0.257621\tval-logloss:0.257732\n",
      "[25]\ttrain-logloss:0.255909\tval-logloss:0.25605\n",
      "[26]\ttrain-logloss:0.254408\tval-logloss:0.254596\n",
      "[27]\ttrain-logloss:0.253098\tval-logloss:0.253321\n",
      "[28]\ttrain-logloss:0.251962\tval-logloss:0.252223\n",
      "[29]\ttrain-logloss:0.25097\tval-logloss:0.251283\n",
      "[30]\ttrain-logloss:0.250098\tval-logloss:0.250461\n",
      "[31]\ttrain-logloss:0.249331\tval-logloss:0.249735\n",
      "[32]\ttrain-logloss:0.248721\tval-logloss:0.249184\n",
      "[33]\ttrain-logloss:0.248121\tval-logloss:0.248624\n",
      "[34]\ttrain-logloss:0.247585\tval-logloss:0.248135\n",
      "[35]\ttrain-logloss:0.247144\tval-logloss:0.247768\n",
      "[36]\ttrain-logloss:0.246718\tval-logloss:0.247388\n",
      "[37]\ttrain-logloss:0.246343\tval-logloss:0.24706\n",
      "[38]\ttrain-logloss:0.246008\tval-logloss:0.246769\n",
      "[39]\ttrain-logloss:0.245705\tval-logloss:0.246527\n",
      "[40]\ttrain-logloss:0.24543\tval-logloss:0.246312\n",
      "[41]\ttrain-logloss:0.245177\tval-logloss:0.246125\n",
      "[42]\ttrain-logloss:0.244972\tval-logloss:0.245966\n",
      "[43]\ttrain-logloss:0.244763\tval-logloss:0.245817\n",
      "[44]\ttrain-logloss:0.244588\tval-logloss:0.245697\n",
      "[45]\ttrain-logloss:0.244389\tval-logloss:0.245567\n",
      "[46]\ttrain-logloss:0.244231\tval-logloss:0.245459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47]\ttrain-logloss:0.244095\tval-logloss:0.245375\n",
      "[48]\ttrain-logloss:0.243939\tval-logloss:0.245286\n",
      "[49]\ttrain-logloss:0.243767\tval-logloss:0.245196\n",
      "[50]\ttrain-logloss:0.243624\tval-logloss:0.245117\n",
      "[51]\ttrain-logloss:0.243508\tval-logloss:0.245063\n",
      "[52]\ttrain-logloss:0.243382\tval-logloss:0.244996\n",
      "[53]\ttrain-logloss:0.243253\tval-logloss:0.244923\n",
      "[54]\ttrain-logloss:0.243137\tval-logloss:0.244876\n",
      "[55]\ttrain-logloss:0.243005\tval-logloss:0.244827\n",
      "[56]\ttrain-logloss:0.242879\tval-logloss:0.244788\n",
      "[57]\ttrain-logloss:0.24276\tval-logloss:0.244748\n",
      "[58]\ttrain-logloss:0.242678\tval-logloss:0.244717\n",
      "[59]\ttrain-logloss:0.242597\tval-logloss:0.244689\n",
      "[60]\ttrain-logloss:0.242497\tval-logloss:0.244673\n",
      "[61]\ttrain-logloss:0.24242\tval-logloss:0.24465\n",
      "[62]\ttrain-logloss:0.242345\tval-logloss:0.244626\n",
      "[63]\ttrain-logloss:0.24225\tval-logloss:0.244595\n",
      "[64]\ttrain-logloss:0.24215\tval-logloss:0.244574\n",
      "[65]\ttrain-logloss:0.242079\tval-logloss:0.244553\n",
      "[66]\ttrain-logloss:0.242004\tval-logloss:0.244536\n",
      "[67]\ttrain-logloss:0.241931\tval-logloss:0.244512\n",
      "[68]\ttrain-logloss:0.241839\tval-logloss:0.244498\n",
      "[69]\ttrain-logloss:0.241747\tval-logloss:0.244478\n",
      "[70]\ttrain-logloss:0.241659\tval-logloss:0.244468\n",
      "[71]\ttrain-logloss:0.241559\tval-logloss:0.244447\n",
      "[72]\ttrain-logloss:0.241495\tval-logloss:0.244441\n",
      "[73]\ttrain-logloss:0.241396\tval-logloss:0.244436\n",
      "[74]\ttrain-logloss:0.241347\tval-logloss:0.244439\n",
      "[75]\ttrain-logloss:0.24125\tval-logloss:0.244434\n",
      "[76]\ttrain-logloss:0.241152\tval-logloss:0.244435\n",
      "[77]\ttrain-logloss:0.241104\tval-logloss:0.244425\n",
      "[78]\ttrain-logloss:0.241027\tval-logloss:0.24441\n",
      "[79]\ttrain-logloss:0.240934\tval-logloss:0.244405\n",
      "[80]\ttrain-logloss:0.240848\tval-logloss:0.244395\n",
      "[81]\ttrain-logloss:0.240752\tval-logloss:0.24439\n",
      "[82]\ttrain-logloss:0.240701\tval-logloss:0.244386\n",
      "[83]\ttrain-logloss:0.240603\tval-logloss:0.244375\n",
      "[84]\ttrain-logloss:0.240548\tval-logloss:0.244361\n",
      "[85]\ttrain-logloss:0.240496\tval-logloss:0.244346\n",
      "[86]\ttrain-logloss:0.240402\tval-logloss:0.244346\n",
      "[87]\ttrain-logloss:0.240345\tval-logloss:0.24434\n",
      "[88]\ttrain-logloss:0.240253\tval-logloss:0.244342\n",
      "[89]\ttrain-logloss:0.240196\tval-logloss:0.244337\n",
      "[90]\ttrain-logloss:0.240128\tval-logloss:0.24433\n",
      "[91]\ttrain-logloss:0.240077\tval-logloss:0.24433\n",
      "[92]\ttrain-logloss:0.239995\tval-logloss:0.244323\n",
      "[93]\ttrain-logloss:0.239905\tval-logloss:0.244313\n",
      "[94]\ttrain-logloss:0.239812\tval-logloss:0.244311\n",
      "[95]\ttrain-logloss:0.239771\tval-logloss:0.244304\n",
      "[96]\ttrain-logloss:0.239699\tval-logloss:0.244298\n",
      "[97]\ttrain-logloss:0.239649\tval-logloss:0.244296\n",
      "[98]\ttrain-logloss:0.239557\tval-logloss:0.244288\n",
      "[99]\ttrain-logloss:0.239493\tval-logloss:0.244294\n",
      "[100]\ttrain-logloss:0.239447\tval-logloss:0.244294\n",
      "[101]\ttrain-logloss:0.23936\tval-logloss:0.244298\n",
      "[102]\ttrain-logloss:0.239302\tval-logloss:0.2443\n",
      "[103]\ttrain-logloss:0.239255\tval-logloss:0.244297\n",
      "[104]\ttrain-logloss:0.239183\tval-logloss:0.244294\n",
      "[105]\ttrain-logloss:0.239105\tval-logloss:0.244289\n",
      "[106]\ttrain-logloss:0.23904\tval-logloss:0.244284\n",
      "[107]\ttrain-logloss:0.23899\tval-logloss:0.244285\n",
      "[108]\ttrain-logloss:0.23892\tval-logloss:0.244285\n",
      "[109]\ttrain-logloss:0.238845\tval-logloss:0.244287\n",
      "[110]\ttrain-logloss:0.23881\tval-logloss:0.244284\n",
      "[111]\ttrain-logloss:0.238751\tval-logloss:0.244272\n",
      "[112]\ttrain-logloss:0.238674\tval-logloss:0.244263\n",
      "[113]\ttrain-logloss:0.238603\tval-logloss:0.244269\n",
      "[114]\ttrain-logloss:0.238524\tval-logloss:0.244257\n",
      "[115]\ttrain-logloss:0.23847\tval-logloss:0.244257\n",
      "[116]\ttrain-logloss:0.238403\tval-logloss:0.244257\n",
      "[117]\ttrain-logloss:0.238316\tval-logloss:0.24426\n",
      "[118]\ttrain-logloss:0.238268\tval-logloss:0.244265\n",
      "[119]\ttrain-logloss:0.238215\tval-logloss:0.244262\n",
      "[120]\ttrain-logloss:0.238171\tval-logloss:0.244261\n",
      "[121]\ttrain-logloss:0.238119\tval-logloss:0.244249\n",
      "[122]\ttrain-logloss:0.238049\tval-logloss:0.24425\n",
      "[123]\ttrain-logloss:0.237977\tval-logloss:0.244256\n",
      "[124]\ttrain-logloss:0.237909\tval-logloss:0.244259\n",
      "[125]\ttrain-logloss:0.237823\tval-logloss:0.244241\n",
      "[126]\ttrain-logloss:0.237762\tval-logloss:0.244241\n",
      "[127]\ttrain-logloss:0.237715\tval-logloss:0.244239\n",
      "[128]\ttrain-logloss:0.237683\tval-logloss:0.244241\n",
      "[129]\ttrain-logloss:0.237635\tval-logloss:0.244244\n",
      "[130]\ttrain-logloss:0.237555\tval-logloss:0.244251\n",
      "[131]\ttrain-logloss:0.237482\tval-logloss:0.244248\n",
      "[132]\ttrain-logloss:0.237436\tval-logloss:0.244245\n",
      "[133]\ttrain-logloss:0.237357\tval-logloss:0.244238\n",
      "[134]\ttrain-logloss:0.237286\tval-logloss:0.24424\n",
      "[135]\ttrain-logloss:0.237223\tval-logloss:0.244236\n",
      "[136]\ttrain-logloss:0.237176\tval-logloss:0.244234\n",
      "[137]\ttrain-logloss:0.237132\tval-logloss:0.244229\n",
      "[138]\ttrain-logloss:0.237088\tval-logloss:0.244225\n",
      "[139]\ttrain-logloss:0.237018\tval-logloss:0.244223\n",
      "[140]\ttrain-logloss:0.236967\tval-logloss:0.244218\n",
      "[141]\ttrain-logloss:0.236889\tval-logloss:0.244224\n",
      "[142]\ttrain-logloss:0.236808\tval-logloss:0.24422\n",
      "[143]\ttrain-logloss:0.236755\tval-logloss:0.244216\n",
      "[144]\ttrain-logloss:0.236707\tval-logloss:0.244214\n",
      "[145]\ttrain-logloss:0.236626\tval-logloss:0.244217\n",
      "[146]\ttrain-logloss:0.236577\tval-logloss:0.244222\n",
      "[147]\ttrain-logloss:0.236528\tval-logloss:0.244222\n",
      "[148]\ttrain-logloss:0.236452\tval-logloss:0.244221\n",
      "[149]\ttrain-logloss:0.236398\tval-logloss:0.244224\n",
      "Doing Cross 5 Validation\n",
      "validation start: 103100, end: 123720\n",
      "Split train and valid data/label by user_id\n",
      "[0]\ttrain-logloss:0.625363\tval-logloss:0.625451\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[1]\ttrain-logloss:0.569941\tval-logloss:0.570121\n",
      "[2]\ttrain-logloss:0.523921\tval-logloss:0.524186\n",
      "[3]\ttrain-logloss:0.485309\tval-logloss:0.485662\n",
      "[4]\ttrain-logloss:0.452638\tval-logloss:0.453074\n",
      "[5]\ttrain-logloss:0.424785\tval-logloss:0.425304\n",
      "[6]\ttrain-logloss:0.400956\tval-logloss:0.401559\n",
      "[7]\ttrain-logloss:0.380443\tval-logloss:0.381121\n",
      "[8]\ttrain-logloss:0.363189\tval-logloss:0.363939\n",
      "[9]\ttrain-logloss:0.347869\tval-logloss:0.348687\n",
      "[10]\ttrain-logloss:0.334541\tval-logloss:0.335423\n",
      "[11]\ttrain-logloss:0.322971\tval-logloss:0.323916\n",
      "[12]\ttrain-logloss:0.312891\tval-logloss:0.313901\n",
      "[13]\ttrain-logloss:0.304125\tval-logloss:0.305206\n",
      "[14]\ttrain-logloss:0.296481\tval-logloss:0.297632\n",
      "[15]\ttrain-logloss:0.289826\tval-logloss:0.291041\n",
      "[16]\ttrain-logloss:0.284011\tval-logloss:0.285287\n",
      "[17]\ttrain-logloss:0.278949\tval-logloss:0.280284\n",
      "[18]\ttrain-logloss:0.274521\tval-logloss:0.275904\n",
      "[19]\ttrain-logloss:0.270644\tval-logloss:0.272091\n",
      "[20]\ttrain-logloss:0.267492\tval-logloss:0.269023\n",
      "[21]\ttrain-logloss:0.264512\tval-logloss:0.266101\n",
      "[22]\ttrain-logloss:0.261894\tval-logloss:0.263538\n",
      "[23]\ttrain-logloss:0.259625\tval-logloss:0.261327\n",
      "[24]\ttrain-logloss:0.257633\tval-logloss:0.259401\n",
      "[25]\ttrain-logloss:0.255895\tval-logloss:0.257725\n",
      "[26]\ttrain-logloss:0.254372\tval-logloss:0.256269\n",
      "[27]\ttrain-logloss:0.25305\tval-logloss:0.255004\n",
      "[28]\ttrain-logloss:0.251897\tval-logloss:0.253909\n",
      "[29]\ttrain-logloss:0.25088\tval-logloss:0.252953\n",
      "[30]\ttrain-logloss:0.249992\tval-logloss:0.252125\n",
      "[31]\ttrain-logloss:0.249201\tval-logloss:0.251402\n",
      "[32]\ttrain-logloss:0.248506\tval-logloss:0.250773\n",
      "[33]\ttrain-logloss:0.24791\tval-logloss:0.250228\n",
      "[34]\ttrain-logloss:0.247368\tval-logloss:0.249738\n",
      "[35]\ttrain-logloss:0.246883\tval-logloss:0.249317\n",
      "[36]\ttrain-logloss:0.246454\tval-logloss:0.248963\n",
      "[37]\ttrain-logloss:0.246085\tval-logloss:0.248654\n",
      "[38]\ttrain-logloss:0.245751\tval-logloss:0.248374\n",
      "[39]\ttrain-logloss:0.245464\tval-logloss:0.248143\n",
      "[40]\ttrain-logloss:0.245184\tval-logloss:0.247927\n",
      "[41]\ttrain-logloss:0.244923\tval-logloss:0.247734\n",
      "[42]\ttrain-logloss:0.244703\tval-logloss:0.247578\n",
      "[43]\ttrain-logloss:0.24449\tval-logloss:0.247452\n",
      "[44]\ttrain-logloss:0.244276\tval-logloss:0.247301\n",
      "[45]\ttrain-logloss:0.244089\tval-logloss:0.24718\n",
      "[46]\ttrain-logloss:0.243932\tval-logloss:0.247083\n",
      "[47]\ttrain-logloss:0.24379\tval-logloss:0.24701\n",
      "[48]\ttrain-logloss:0.243659\tval-logloss:0.246934\n",
      "[49]\ttrain-logloss:0.243513\tval-logloss:0.246865\n",
      "[50]\ttrain-logloss:0.24339\tval-logloss:0.246802\n",
      "[51]\ttrain-logloss:0.24325\tval-logloss:0.246734\n",
      "[52]\ttrain-logloss:0.24313\tval-logloss:0.246681\n",
      "[53]\ttrain-logloss:0.243047\tval-logloss:0.246639\n",
      "[54]\ttrain-logloss:0.242913\tval-logloss:0.246599\n",
      "[55]\ttrain-logloss:0.242795\tval-logloss:0.246557\n",
      "[56]\ttrain-logloss:0.242707\tval-logloss:0.246529\n",
      "[57]\ttrain-logloss:0.242588\tval-logloss:0.24648\n",
      "[58]\ttrain-logloss:0.242446\tval-logloss:0.246434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[59]\ttrain-logloss:0.24232\tval-logloss:0.246409\n",
      "[60]\ttrain-logloss:0.242263\tval-logloss:0.246395\n",
      "[61]\ttrain-logloss:0.242161\tval-logloss:0.24638\n",
      "[62]\ttrain-logloss:0.242071\tval-logloss:0.246355\n",
      "[63]\ttrain-logloss:0.242\tval-logloss:0.246324\n",
      "[64]\ttrain-logloss:0.241897\tval-logloss:0.246299\n",
      "[65]\ttrain-logloss:0.241802\tval-logloss:0.246287\n",
      "[66]\ttrain-logloss:0.241714\tval-logloss:0.246267\n",
      "[67]\ttrain-logloss:0.241634\tval-logloss:0.246249\n",
      "[68]\ttrain-logloss:0.241516\tval-logloss:0.246231\n",
      "[69]\ttrain-logloss:0.241436\tval-logloss:0.246211\n",
      "[70]\ttrain-logloss:0.241343\tval-logloss:0.246195\n",
      "[71]\ttrain-logloss:0.24124\tval-logloss:0.246187\n",
      "[72]\ttrain-logloss:0.241154\tval-logloss:0.246179\n",
      "[73]\ttrain-logloss:0.241091\tval-logloss:0.24617\n",
      "[74]\ttrain-logloss:0.241021\tval-logloss:0.246163\n",
      "[75]\ttrain-logloss:0.240974\tval-logloss:0.246155\n",
      "[76]\ttrain-logloss:0.2409\tval-logloss:0.246146\n",
      "[77]\ttrain-logloss:0.240793\tval-logloss:0.246137\n",
      "[78]\ttrain-logloss:0.240728\tval-logloss:0.246125\n",
      "[79]\ttrain-logloss:0.240667\tval-logloss:0.24612\n",
      "[80]\ttrain-logloss:0.240612\tval-logloss:0.246112\n",
      "[81]\ttrain-logloss:0.240522\tval-logloss:0.246101\n",
      "[82]\ttrain-logloss:0.240467\tval-logloss:0.246085\n",
      "[83]\ttrain-logloss:0.24038\tval-logloss:0.246076\n",
      "[84]\ttrain-logloss:0.240268\tval-logloss:0.246061\n",
      "[85]\ttrain-logloss:0.240183\tval-logloss:0.246059\n",
      "[86]\ttrain-logloss:0.240104\tval-logloss:0.246067\n",
      "[87]\ttrain-logloss:0.240028\tval-logloss:0.246055\n",
      "[88]\ttrain-logloss:0.239943\tval-logloss:0.246044\n",
      "[89]\ttrain-logloss:0.239902\tval-logloss:0.246049\n",
      "[90]\ttrain-logloss:0.23984\tval-logloss:0.246038\n",
      "[91]\ttrain-logloss:0.239771\tval-logloss:0.246033\n",
      "[92]\ttrain-logloss:0.239721\tval-logloss:0.246038\n",
      "[93]\ttrain-logloss:0.239633\tval-logloss:0.246033\n",
      "[94]\ttrain-logloss:0.239569\tval-logloss:0.246035\n",
      "[95]\ttrain-logloss:0.239517\tval-logloss:0.246035\n",
      "[96]\ttrain-logloss:0.239411\tval-logloss:0.246028\n",
      "[97]\ttrain-logloss:0.239354\tval-logloss:0.246032\n",
      "[98]\ttrain-logloss:0.239275\tval-logloss:0.246015\n",
      "[99]\ttrain-logloss:0.239192\tval-logloss:0.246015\n",
      "[100]\ttrain-logloss:0.2391\tval-logloss:0.246019\n",
      "[101]\ttrain-logloss:0.239044\tval-logloss:0.246018\n",
      "[102]\ttrain-logloss:0.238977\tval-logloss:0.246003\n",
      "[103]\ttrain-logloss:0.23891\tval-logloss:0.246004\n",
      "[104]\ttrain-logloss:0.238857\tval-logloss:0.245998\n",
      "[105]\ttrain-logloss:0.238763\tval-logloss:0.246006\n",
      "[106]\ttrain-logloss:0.238717\tval-logloss:0.246007\n",
      "[107]\ttrain-logloss:0.238661\tval-logloss:0.245993\n",
      "[108]\ttrain-logloss:0.23862\tval-logloss:0.245995\n",
      "[109]\ttrain-logloss:0.238563\tval-logloss:0.245989\n",
      "[110]\ttrain-logloss:0.238523\tval-logloss:0.245982\n",
      "[111]\ttrain-logloss:0.23845\tval-logloss:0.245984\n",
      "[112]\ttrain-logloss:0.238387\tval-logloss:0.245986\n",
      "[113]\ttrain-logloss:0.238339\tval-logloss:0.24599\n",
      "[114]\ttrain-logloss:0.238297\tval-logloss:0.245986\n",
      "[115]\ttrain-logloss:0.238245\tval-logloss:0.245988\n",
      "[116]\ttrain-logloss:0.238176\tval-logloss:0.24599\n",
      "[117]\ttrain-logloss:0.238142\tval-logloss:0.245994\n",
      "[118]\ttrain-logloss:0.238062\tval-logloss:0.245992\n",
      "[119]\ttrain-logloss:0.237977\tval-logloss:0.245991\n",
      "[120]\ttrain-logloss:0.237922\tval-logloss:0.245995\n",
      "[121]\ttrain-logloss:0.237887\tval-logloss:0.245991\n",
      "[122]\ttrain-logloss:0.237814\tval-logloss:0.245991\n",
      "[123]\ttrain-logloss:0.23778\tval-logloss:0.245992\n",
      "[124]\ttrain-logloss:0.237724\tval-logloss:0.24598\n",
      "[125]\ttrain-logloss:0.237672\tval-logloss:0.24598\n",
      "[126]\ttrain-logloss:0.237627\tval-logloss:0.245984\n",
      "[127]\ttrain-logloss:0.237574\tval-logloss:0.245985\n",
      "[128]\ttrain-logloss:0.237503\tval-logloss:0.245991\n",
      "[129]\ttrain-logloss:0.237437\tval-logloss:0.245993\n",
      "[130]\ttrain-logloss:0.237395\tval-logloss:0.24599\n",
      "[131]\ttrain-logloss:0.237358\tval-logloss:0.245991\n",
      "[132]\ttrain-logloss:0.237317\tval-logloss:0.24599\n",
      "[133]\ttrain-logloss:0.237252\tval-logloss:0.245994\n",
      "[134]\ttrain-logloss:0.237201\tval-logloss:0.245997\n",
      "[135]\ttrain-logloss:0.237104\tval-logloss:0.245992\n",
      "[136]\ttrain-logloss:0.237029\tval-logloss:0.24599\n",
      "[137]\ttrain-logloss:0.23695\tval-logloss:0.24599\n",
      "[138]\ttrain-logloss:0.236877\tval-logloss:0.245992\n",
      "[139]\ttrain-logloss:0.23681\tval-logloss:0.245996\n",
      "[140]\ttrain-logloss:0.236735\tval-logloss:0.246002\n",
      "[141]\ttrain-logloss:0.236703\tval-logloss:0.245996\n",
      "[142]\ttrain-logloss:0.236655\tval-logloss:0.245997\n",
      "[143]\ttrain-logloss:0.23661\tval-logloss:0.245991\n",
      "[144]\ttrain-logloss:0.236557\tval-logloss:0.245982\n",
      "[145]\ttrain-logloss:0.236485\tval-logloss:0.245981\n",
      "[146]\ttrain-logloss:0.236424\tval-logloss:0.245974\n",
      "[147]\ttrain-logloss:0.23635\tval-logloss:0.245979\n",
      "[148]\ttrain-logloss:0.236285\tval-logloss:0.245967\n",
      "[149]\ttrain-logloss:0.236235\tval-logloss:0.245972\n",
      "Doing Cross 6 Validation\n",
      "validation start: 123720, end: 144340\n",
      "Split train and valid data/label by user_id\n",
      "[0]\ttrain-logloss:0.625389\tval-logloss:0.625477\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[1]\ttrain-logloss:0.569964\tval-logloss:0.570126\n",
      "[2]\ttrain-logloss:0.52396\tval-logloss:0.524185\n",
      "[3]\ttrain-logloss:0.485359\tval-logloss:0.485636\n",
      "[4]\ttrain-logloss:0.452772\tval-logloss:0.453112\n",
      "[5]\ttrain-logloss:0.424905\tval-logloss:0.425299\n",
      "[6]\ttrain-logloss:0.401047\tval-logloss:0.401488\n",
      "[7]\ttrain-logloss:0.380525\tval-logloss:0.381018\n",
      "[8]\ttrain-logloss:0.362836\tval-logloss:0.363377\n",
      "[9]\ttrain-logloss:0.347523\tval-logloss:0.348105\n",
      "[10]\ttrain-logloss:0.334246\tval-logloss:0.334868\n",
      "[11]\ttrain-logloss:0.322718\tval-logloss:0.323389\n",
      "[12]\ttrain-logloss:0.313039\tval-logloss:0.313766\n",
      "[13]\ttrain-logloss:0.304256\tval-logloss:0.305032\n",
      "[14]\ttrain-logloss:0.296624\tval-logloss:0.297455\n",
      "[15]\ttrain-logloss:0.289944\tval-logloss:0.290824\n",
      "[16]\ttrain-logloss:0.28412\tval-logloss:0.285049\n",
      "[17]\ttrain-logloss:0.279036\tval-logloss:0.280012\n",
      "[18]\ttrain-logloss:0.274608\tval-logloss:0.275632\n",
      "[19]\ttrain-logloss:0.270729\tval-logloss:0.271792\n",
      "[20]\ttrain-logloss:0.267347\tval-logloss:0.268452\n",
      "[21]\ttrain-logloss:0.264384\tval-logloss:0.265545\n",
      "[22]\ttrain-logloss:0.2618\tval-logloss:0.263011\n",
      "[23]\ttrain-logloss:0.259547\tval-logloss:0.260803\n",
      "[24]\ttrain-logloss:0.257581\tval-logloss:0.25888\n",
      "[25]\ttrain-logloss:0.255863\tval-logloss:0.257214\n",
      "[26]\ttrain-logloss:0.254355\tval-logloss:0.255766\n",
      "[27]\ttrain-logloss:0.253042\tval-logloss:0.25451\n",
      "[28]\ttrain-logloss:0.251895\tval-logloss:0.253414\n",
      "[29]\ttrain-logloss:0.250894\tval-logloss:0.252467\n",
      "[30]\ttrain-logloss:0.250022\tval-logloss:0.251641\n",
      "[31]\ttrain-logloss:0.249253\tval-logloss:0.250924\n",
      "[32]\ttrain-logloss:0.24857\tval-logloss:0.250295\n",
      "[33]\ttrain-logloss:0.247974\tval-logloss:0.249752\n",
      "[34]\ttrain-logloss:0.247436\tval-logloss:0.249282\n",
      "[35]\ttrain-logloss:0.246973\tval-logloss:0.248875\n",
      "[36]\ttrain-logloss:0.246562\tval-logloss:0.248514\n",
      "[37]\ttrain-logloss:0.24618\tval-logloss:0.248201\n",
      "[38]\ttrain-logloss:0.245837\tval-logloss:0.247923\n",
      "[39]\ttrain-logloss:0.245529\tval-logloss:0.247683\n",
      "[40]\ttrain-logloss:0.245255\tval-logloss:0.24747\n",
      "[41]\ttrain-logloss:0.245006\tval-logloss:0.247279\n",
      "[42]\ttrain-logloss:0.244791\tval-logloss:0.247116\n",
      "[43]\ttrain-logloss:0.244581\tval-logloss:0.246958\n",
      "[44]\ttrain-logloss:0.2444\tval-logloss:0.246835\n",
      "[45]\ttrain-logloss:0.244242\tval-logloss:0.246731\n",
      "[46]\ttrain-logloss:0.244086\tval-logloss:0.246637\n",
      "[47]\ttrain-logloss:0.243938\tval-logloss:0.246545\n",
      "[48]\ttrain-logloss:0.243801\tval-logloss:0.246467\n",
      "[49]\ttrain-logloss:0.24365\tval-logloss:0.246378\n",
      "[50]\ttrain-logloss:0.243529\tval-logloss:0.246318\n",
      "[51]\ttrain-logloss:0.243411\tval-logloss:0.246259\n",
      "[52]\ttrain-logloss:0.243324\tval-logloss:0.246216\n",
      "[53]\ttrain-logloss:0.243226\tval-logloss:0.246185\n",
      "[54]\ttrain-logloss:0.243098\tval-logloss:0.246137\n",
      "[55]\ttrain-logloss:0.242965\tval-logloss:0.24609\n",
      "[56]\ttrain-logloss:0.24283\tval-logloss:0.246053\n",
      "[57]\ttrain-logloss:0.242709\tval-logloss:0.246021\n",
      "[58]\ttrain-logloss:0.242612\tval-logloss:0.245979\n",
      "[59]\ttrain-logloss:0.242516\tval-logloss:0.245959\n",
      "[60]\ttrain-logloss:0.242381\tval-logloss:0.245915\n",
      "[61]\ttrain-logloss:0.242281\tval-logloss:0.24589\n",
      "[62]\ttrain-logloss:0.242186\tval-logloss:0.245864\n",
      "[63]\ttrain-logloss:0.242112\tval-logloss:0.245838\n",
      "[64]\ttrain-logloss:0.242001\tval-logloss:0.245814\n",
      "[65]\ttrain-logloss:0.241885\tval-logloss:0.245773\n",
      "[66]\ttrain-logloss:0.241824\tval-logloss:0.245765\n",
      "[67]\ttrain-logloss:0.241727\tval-logloss:0.245745\n",
      "[68]\ttrain-logloss:0.241666\tval-logloss:0.245734\n",
      "[69]\ttrain-logloss:0.241553\tval-logloss:0.245719\n",
      "[70]\ttrain-logloss:0.241482\tval-logloss:0.245707\n",
      "[71]\ttrain-logloss:0.241421\tval-logloss:0.245697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[72]\ttrain-logloss:0.241361\tval-logloss:0.245682\n",
      "[73]\ttrain-logloss:0.241253\tval-logloss:0.245687\n",
      "[74]\ttrain-logloss:0.24114\tval-logloss:0.245684\n",
      "[75]\ttrain-logloss:0.24109\tval-logloss:0.245673\n",
      "[76]\ttrain-logloss:0.241047\tval-logloss:0.245669\n",
      "[77]\ttrain-logloss:0.240938\tval-logloss:0.245678\n",
      "[78]\ttrain-logloss:0.240859\tval-logloss:0.245665\n",
      "[79]\ttrain-logloss:0.240758\tval-logloss:0.245655\n",
      "[80]\ttrain-logloss:0.240676\tval-logloss:0.245656\n",
      "[81]\ttrain-logloss:0.240612\tval-logloss:0.245644\n",
      "[82]\ttrain-logloss:0.240524\tval-logloss:0.245639\n",
      "[83]\ttrain-logloss:0.240456\tval-logloss:0.245626\n",
      "[84]\ttrain-logloss:0.240418\tval-logloss:0.245617\n",
      "[85]\ttrain-logloss:0.240328\tval-logloss:0.245613\n",
      "[86]\ttrain-logloss:0.240231\tval-logloss:0.245606\n",
      "[87]\ttrain-logloss:0.24014\tval-logloss:0.2456\n",
      "[88]\ttrain-logloss:0.24003\tval-logloss:0.245578\n",
      "[89]\ttrain-logloss:0.23997\tval-logloss:0.245574\n",
      "[90]\ttrain-logloss:0.239919\tval-logloss:0.245568\n",
      "[91]\ttrain-logloss:0.239846\tval-logloss:0.245578\n",
      "[92]\ttrain-logloss:0.239767\tval-logloss:0.245573\n",
      "[93]\ttrain-logloss:0.239685\tval-logloss:0.24556\n",
      "[94]\ttrain-logloss:0.239628\tval-logloss:0.245554\n",
      "[95]\ttrain-logloss:0.239553\tval-logloss:0.245557\n",
      "[96]\ttrain-logloss:0.239495\tval-logloss:0.245535\n",
      "[97]\ttrain-logloss:0.239411\tval-logloss:0.245515\n",
      "[98]\ttrain-logloss:0.239336\tval-logloss:0.24551\n",
      "[99]\ttrain-logloss:0.239286\tval-logloss:0.245507\n",
      "[100]\ttrain-logloss:0.239216\tval-logloss:0.245509\n",
      "[101]\ttrain-logloss:0.239168\tval-logloss:0.245507\n",
      "[102]\ttrain-logloss:0.2391\tval-logloss:0.2455\n",
      "[103]\ttrain-logloss:0.239044\tval-logloss:0.245503\n",
      "[104]\ttrain-logloss:0.239001\tval-logloss:0.245496\n",
      "[105]\ttrain-logloss:0.23894\tval-logloss:0.245486\n",
      "[106]\ttrain-logloss:0.238884\tval-logloss:0.245484\n",
      "[107]\ttrain-logloss:0.238832\tval-logloss:0.245483\n",
      "[108]\ttrain-logloss:0.238799\tval-logloss:0.245488\n",
      "[109]\ttrain-logloss:0.238751\tval-logloss:0.245489\n",
      "[110]\ttrain-logloss:0.238699\tval-logloss:0.245496\n",
      "[111]\ttrain-logloss:0.238638\tval-logloss:0.245498\n",
      "[112]\ttrain-logloss:0.238585\tval-logloss:0.2455\n",
      "[113]\ttrain-logloss:0.238547\tval-logloss:0.245497\n",
      "[114]\ttrain-logloss:0.2385\tval-logloss:0.245498\n",
      "[115]\ttrain-logloss:0.238457\tval-logloss:0.245499\n",
      "[116]\ttrain-logloss:0.23841\tval-logloss:0.245499\n",
      "[117]\ttrain-logloss:0.238364\tval-logloss:0.245496\n",
      "[118]\ttrain-logloss:0.238299\tval-logloss:0.245496\n",
      "[119]\ttrain-logloss:0.238228\tval-logloss:0.245484\n",
      "[120]\ttrain-logloss:0.238182\tval-logloss:0.245482\n",
      "[121]\ttrain-logloss:0.238125\tval-logloss:0.245469\n",
      "[122]\ttrain-logloss:0.23807\tval-logloss:0.245469\n",
      "[123]\ttrain-logloss:0.237988\tval-logloss:0.245476\n",
      "[124]\ttrain-logloss:0.237912\tval-logloss:0.245482\n",
      "[125]\ttrain-logloss:0.237846\tval-logloss:0.24547\n",
      "[126]\ttrain-logloss:0.237762\tval-logloss:0.245455\n",
      "[127]\ttrain-logloss:0.237712\tval-logloss:0.245455\n",
      "[128]\ttrain-logloss:0.23766\tval-logloss:0.245458\n",
      "[129]\ttrain-logloss:0.237583\tval-logloss:0.245462\n",
      "[130]\ttrain-logloss:0.237544\tval-logloss:0.245466\n",
      "[131]\ttrain-logloss:0.237484\tval-logloss:0.245463\n",
      "[132]\ttrain-logloss:0.23744\tval-logloss:0.245461\n",
      "[133]\ttrain-logloss:0.237377\tval-logloss:0.245461\n",
      "[134]\ttrain-logloss:0.237309\tval-logloss:0.245464\n",
      "[135]\ttrain-logloss:0.237227\tval-logloss:0.245459\n",
      "[136]\ttrain-logloss:0.237169\tval-logloss:0.245449\n",
      "[137]\ttrain-logloss:0.2371\tval-logloss:0.245447\n",
      "[138]\ttrain-logloss:0.237076\tval-logloss:0.245448\n",
      "[139]\ttrain-logloss:0.236988\tval-logloss:0.245452\n",
      "[140]\ttrain-logloss:0.236921\tval-logloss:0.245455\n",
      "[141]\ttrain-logloss:0.236856\tval-logloss:0.245463\n",
      "[142]\ttrain-logloss:0.23681\tval-logloss:0.245465\n",
      "[143]\ttrain-logloss:0.236743\tval-logloss:0.24547\n",
      "[144]\ttrain-logloss:0.236692\tval-logloss:0.24548\n",
      "[145]\ttrain-logloss:0.236629\tval-logloss:0.245484\n",
      "[146]\ttrain-logloss:0.236579\tval-logloss:0.245485\n",
      "[147]\ttrain-logloss:0.236538\tval-logloss:0.245489\n",
      "[148]\ttrain-logloss:0.236489\tval-logloss:0.245489\n",
      "[149]\ttrain-logloss:0.236425\tval-logloss:0.245487\n",
      "Doing Cross 7 Validation\n",
      "validation start: 144340, end: 164960\n",
      "Split train and valid data/label by user_id\n",
      "[0]\ttrain-logloss:0.625358\tval-logloss:0.62538\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[1]\ttrain-logloss:0.569982\tval-logloss:0.57003\n",
      "[2]\ttrain-logloss:0.523957\tval-logloss:0.524048\n",
      "[3]\ttrain-logloss:0.485343\tval-logloss:0.485483\n",
      "[4]\ttrain-logloss:0.452662\tval-logloss:0.452846\n",
      "[5]\ttrain-logloss:0.424841\tval-logloss:0.425081\n",
      "[6]\ttrain-logloss:0.401002\tval-logloss:0.401299\n",
      "[7]\ttrain-logloss:0.38048\tval-logloss:0.380847\n",
      "[8]\ttrain-logloss:0.36279\tval-logloss:0.36322\n",
      "[9]\ttrain-logloss:0.347466\tval-logloss:0.347954\n",
      "[10]\ttrain-logloss:0.33418\tval-logloss:0.334737\n",
      "[11]\ttrain-logloss:0.322648\tval-logloss:0.323267\n",
      "[12]\ttrain-logloss:0.312607\tval-logloss:0.313286\n",
      "[13]\ttrain-logloss:0.303874\tval-logloss:0.304613\n",
      "[14]\ttrain-logloss:0.296265\tval-logloss:0.297069\n",
      "[15]\ttrain-logloss:0.289628\tval-logloss:0.2905\n",
      "[16]\ttrain-logloss:0.283843\tval-logloss:0.284771\n",
      "[17]\ttrain-logloss:0.27878\tval-logloss:0.279783\n",
      "[18]\ttrain-logloss:0.274368\tval-logloss:0.275442\n",
      "[19]\ttrain-logloss:0.270509\tval-logloss:0.27166\n",
      "[20]\ttrain-logloss:0.267148\tval-logloss:0.26837\n",
      "[21]\ttrain-logloss:0.264196\tval-logloss:0.26549\n",
      "[22]\ttrain-logloss:0.261632\tval-logloss:0.262997\n",
      "[23]\ttrain-logloss:0.259394\tval-logloss:0.260828\n",
      "[24]\ttrain-logloss:0.257439\tval-logloss:0.258941\n",
      "[25]\ttrain-logloss:0.255732\tval-logloss:0.257304\n",
      "[26]\ttrain-logloss:0.254239\tval-logloss:0.255886\n",
      "[27]\ttrain-logloss:0.252941\tval-logloss:0.254659\n",
      "[28]\ttrain-logloss:0.251795\tval-logloss:0.253589\n",
      "[29]\ttrain-logloss:0.250786\tval-logloss:0.25266\n",
      "[30]\ttrain-logloss:0.249903\tval-logloss:0.251852\n",
      "[31]\ttrain-logloss:0.249141\tval-logloss:0.251153\n",
      "[32]\ttrain-logloss:0.248467\tval-logloss:0.250547\n",
      "[33]\ttrain-logloss:0.247879\tval-logloss:0.250029\n",
      "[34]\ttrain-logloss:0.247399\tval-logloss:0.249629\n",
      "[35]\ttrain-logloss:0.246933\tval-logloss:0.249236\n",
      "[36]\ttrain-logloss:0.24651\tval-logloss:0.248897\n",
      "[37]\ttrain-logloss:0.246126\tval-logloss:0.248593\n",
      "[38]\ttrain-logloss:0.245799\tval-logloss:0.248339\n",
      "[39]\ttrain-logloss:0.245485\tval-logloss:0.248101\n",
      "[40]\ttrain-logloss:0.245227\tval-logloss:0.247908\n",
      "[41]\ttrain-logloss:0.24498\tval-logloss:0.247729\n",
      "[42]\ttrain-logloss:0.244758\tval-logloss:0.24758\n",
      "[43]\ttrain-logloss:0.24456\tval-logloss:0.247454\n",
      "[44]\ttrain-logloss:0.244377\tval-logloss:0.247339\n",
      "[45]\ttrain-logloss:0.244188\tval-logloss:0.247217\n",
      "[46]\ttrain-logloss:0.244026\tval-logloss:0.247116\n",
      "[47]\ttrain-logloss:0.243876\tval-logloss:0.247032\n",
      "[48]\ttrain-logloss:0.243738\tval-logloss:0.24697\n",
      "[49]\ttrain-logloss:0.243584\tval-logloss:0.246902\n",
      "[50]\ttrain-logloss:0.243457\tval-logloss:0.246851\n",
      "[51]\ttrain-logloss:0.243328\tval-logloss:0.246798\n",
      "[52]\ttrain-logloss:0.243224\tval-logloss:0.246751\n",
      "[53]\ttrain-logloss:0.243121\tval-logloss:0.246719\n",
      "[54]\ttrain-logloss:0.243014\tval-logloss:0.246673\n",
      "[55]\ttrain-logloss:0.242903\tval-logloss:0.246654\n",
      "[56]\ttrain-logloss:0.242802\tval-logloss:0.246611\n",
      "[57]\ttrain-logloss:0.242706\tval-logloss:0.246575\n",
      "[58]\ttrain-logloss:0.242625\tval-logloss:0.246537\n",
      "[59]\ttrain-logloss:0.242523\tval-logloss:0.246508\n",
      "[60]\ttrain-logloss:0.242448\tval-logloss:0.246484\n",
      "[61]\ttrain-logloss:0.242342\tval-logloss:0.246459\n",
      "[62]\ttrain-logloss:0.242239\tval-logloss:0.246429\n",
      "[63]\ttrain-logloss:0.242141\tval-logloss:0.246414\n",
      "[64]\ttrain-logloss:0.242064\tval-logloss:0.246405\n",
      "[65]\ttrain-logloss:0.241964\tval-logloss:0.246389\n",
      "[66]\ttrain-logloss:0.241893\tval-logloss:0.246373\n",
      "[67]\ttrain-logloss:0.241755\tval-logloss:0.246345\n",
      "[68]\ttrain-logloss:0.241691\tval-logloss:0.246332\n",
      "[69]\ttrain-logloss:0.241558\tval-logloss:0.246308\n",
      "[70]\ttrain-logloss:0.241489\tval-logloss:0.246302\n",
      "[71]\ttrain-logloss:0.241384\tval-logloss:0.246288\n",
      "[72]\ttrain-logloss:0.24129\tval-logloss:0.246274\n",
      "[73]\ttrain-logloss:0.241234\tval-logloss:0.246264\n",
      "[74]\ttrain-logloss:0.241159\tval-logloss:0.246261\n",
      "[75]\ttrain-logloss:0.241066\tval-logloss:0.246263\n",
      "[76]\ttrain-logloss:0.241\tval-logloss:0.246246\n",
      "[77]\ttrain-logloss:0.240898\tval-logloss:0.246236\n",
      "[78]\ttrain-logloss:0.240841\tval-logloss:0.246233\n",
      "[79]\ttrain-logloss:0.24075\tval-logloss:0.24622\n",
      "[80]\ttrain-logloss:0.240686\tval-logloss:0.246219\n",
      "[81]\ttrain-logloss:0.240643\tval-logloss:0.24622\n",
      "[82]\ttrain-logloss:0.24056\tval-logloss:0.246218\n",
      "[83]\ttrain-logloss:0.240499\tval-logloss:0.246204\n",
      "[84]\ttrain-logloss:0.240435\tval-logloss:0.246194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[85]\ttrain-logloss:0.24035\tval-logloss:0.246184\n",
      "[86]\ttrain-logloss:0.240269\tval-logloss:0.246182\n",
      "[87]\ttrain-logloss:0.240194\tval-logloss:0.246177\n",
      "[88]\ttrain-logloss:0.24012\tval-logloss:0.246151\n",
      "[89]\ttrain-logloss:0.240044\tval-logloss:0.246156\n",
      "[90]\ttrain-logloss:0.23997\tval-logloss:0.24615\n",
      "[91]\ttrain-logloss:0.239929\tval-logloss:0.246147\n",
      "[92]\ttrain-logloss:0.239888\tval-logloss:0.246148\n",
      "[93]\ttrain-logloss:0.23983\tval-logloss:0.246142\n",
      "[94]\ttrain-logloss:0.239728\tval-logloss:0.246115\n",
      "[95]\ttrain-logloss:0.239671\tval-logloss:0.246118\n",
      "[96]\ttrain-logloss:0.239599\tval-logloss:0.246114\n",
      "[97]\ttrain-logloss:0.239543\tval-logloss:0.246115\n",
      "[98]\ttrain-logloss:0.239433\tval-logloss:0.246109\n",
      "[99]\ttrain-logloss:0.23936\tval-logloss:0.246088\n",
      "[100]\ttrain-logloss:0.239269\tval-logloss:0.246087\n",
      "[101]\ttrain-logloss:0.239226\tval-logloss:0.246075\n",
      "[102]\ttrain-logloss:0.239179\tval-logloss:0.246077\n",
      "[103]\ttrain-logloss:0.239097\tval-logloss:0.246054\n",
      "[104]\ttrain-logloss:0.239047\tval-logloss:0.246046\n",
      "[105]\ttrain-logloss:0.238991\tval-logloss:0.246042\n",
      "[106]\ttrain-logloss:0.23895\tval-logloss:0.246044\n",
      "[107]\ttrain-logloss:0.238865\tval-logloss:0.246053\n",
      "[108]\ttrain-logloss:0.238804\tval-logloss:0.246051\n",
      "[109]\ttrain-logloss:0.238731\tval-logloss:0.246026\n",
      "[110]\ttrain-logloss:0.238663\tval-logloss:0.246024\n",
      "[111]\ttrain-logloss:0.238591\tval-logloss:0.246019\n",
      "[112]\ttrain-logloss:0.238551\tval-logloss:0.24601\n",
      "[113]\ttrain-logloss:0.238461\tval-logloss:0.246015\n",
      "[114]\ttrain-logloss:0.238373\tval-logloss:0.246004\n",
      "[115]\ttrain-logloss:0.238291\tval-logloss:0.246004\n",
      "[116]\ttrain-logloss:0.238198\tval-logloss:0.246002\n",
      "[117]\ttrain-logloss:0.238083\tval-logloss:0.246\n",
      "[118]\ttrain-logloss:0.238036\tval-logloss:0.246\n",
      "[119]\ttrain-logloss:0.237964\tval-logloss:0.245997\n",
      "[120]\ttrain-logloss:0.237876\tval-logloss:0.246004\n",
      "[121]\ttrain-logloss:0.237803\tval-logloss:0.246006\n",
      "[122]\ttrain-logloss:0.237725\tval-logloss:0.246\n",
      "[123]\ttrain-logloss:0.237673\tval-logloss:0.246002\n",
      "[124]\ttrain-logloss:0.237643\tval-logloss:0.246002\n",
      "[125]\ttrain-logloss:0.237595\tval-logloss:0.245995\n",
      "[126]\ttrain-logloss:0.237536\tval-logloss:0.245991\n",
      "[127]\ttrain-logloss:0.237477\tval-logloss:0.245992\n",
      "[128]\ttrain-logloss:0.237428\tval-logloss:0.245985\n",
      "[129]\ttrain-logloss:0.237369\tval-logloss:0.245988\n",
      "[130]\ttrain-logloss:0.237303\tval-logloss:0.245988\n",
      "[131]\ttrain-logloss:0.237266\tval-logloss:0.245994\n",
      "[132]\ttrain-logloss:0.237216\tval-logloss:0.245982\n",
      "[133]\ttrain-logloss:0.237143\tval-logloss:0.245979\n",
      "[134]\ttrain-logloss:0.237069\tval-logloss:0.245981\n",
      "[135]\ttrain-logloss:0.237036\tval-logloss:0.245979\n",
      "[136]\ttrain-logloss:0.236984\tval-logloss:0.245971\n",
      "[137]\ttrain-logloss:0.236903\tval-logloss:0.24597\n",
      "[138]\ttrain-logloss:0.236831\tval-logloss:0.245972\n",
      "[139]\ttrain-logloss:0.236763\tval-logloss:0.245979\n",
      "[140]\ttrain-logloss:0.236676\tval-logloss:0.245981\n",
      "[141]\ttrain-logloss:0.236609\tval-logloss:0.245985\n",
      "[142]\ttrain-logloss:0.236536\tval-logloss:0.245985\n",
      "[143]\ttrain-logloss:0.236485\tval-logloss:0.24598\n",
      "[144]\ttrain-logloss:0.236399\tval-logloss:0.245976\n",
      "[145]\ttrain-logloss:0.236364\tval-logloss:0.245981\n",
      "[146]\ttrain-logloss:0.23632\tval-logloss:0.245981\n",
      "[147]\ttrain-logloss:0.23628\tval-logloss:0.245983\n",
      "[148]\ttrain-logloss:0.236179\tval-logloss:0.245983\n",
      "[149]\ttrain-logloss:0.236115\tval-logloss:0.245982\n",
      "Doing Cross 8 Validation\n",
      "validation start: 164960, end: 185580\n",
      "Split train and valid data/label by user_id\n",
      "[0]\ttrain-logloss:0.625337\tval-logloss:0.625699\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[1]\ttrain-logloss:0.569884\tval-logloss:0.570552\n",
      "[2]\ttrain-logloss:0.523989\tval-logloss:0.524942\n",
      "[3]\ttrain-logloss:0.485327\tval-logloss:0.486507\n",
      "[4]\ttrain-logloss:0.452618\tval-logloss:0.454004\n",
      "[5]\ttrain-logloss:0.424747\tval-logloss:0.426324\n",
      "[6]\ttrain-logloss:0.400876\tval-logloss:0.402622\n",
      "[7]\ttrain-logloss:0.380351\tval-logloss:0.382256\n",
      "[8]\ttrain-logloss:0.362635\tval-logloss:0.364698\n",
      "[9]\ttrain-logloss:0.347307\tval-logloss:0.349514\n",
      "[10]\ttrain-logloss:0.334017\tval-logloss:0.336362\n",
      "[11]\ttrain-logloss:0.322477\tval-logloss:0.324944\n",
      "[12]\ttrain-logloss:0.312437\tval-logloss:0.315013\n",
      "[13]\ttrain-logloss:0.303697\tval-logloss:0.306381\n",
      "[14]\ttrain-logloss:0.296083\tval-logloss:0.298878\n",
      "[15]\ttrain-logloss:0.289435\tval-logloss:0.292338\n",
      "[16]\ttrain-logloss:0.283649\tval-logloss:0.286638\n",
      "[17]\ttrain-logloss:0.278593\tval-logloss:0.281681\n",
      "[18]\ttrain-logloss:0.274179\tval-logloss:0.277365\n",
      "[19]\ttrain-logloss:0.270309\tval-logloss:0.27359\n",
      "[20]\ttrain-logloss:0.266938\tval-logloss:0.270307\n",
      "[21]\ttrain-logloss:0.264001\tval-logloss:0.267451\n",
      "[22]\ttrain-logloss:0.261429\tval-logloss:0.264964\n",
      "[23]\ttrain-logloss:0.259201\tval-logloss:0.262817\n",
      "[24]\ttrain-logloss:0.257231\tval-logloss:0.260924\n",
      "[25]\ttrain-logloss:0.255519\tval-logloss:0.259282\n",
      "[26]\ttrain-logloss:0.254036\tval-logloss:0.257871\n",
      "[27]\ttrain-logloss:0.252725\tval-logloss:0.256634\n",
      "[28]\ttrain-logloss:0.251571\tval-logloss:0.255555\n",
      "[29]\ttrain-logloss:0.250575\tval-logloss:0.254629\n",
      "[30]\ttrain-logloss:0.249686\tval-logloss:0.253811\n",
      "[31]\ttrain-logloss:0.248917\tval-logloss:0.253109\n",
      "[32]\ttrain-logloss:0.248244\tval-logloss:0.252514\n",
      "[33]\ttrain-logloss:0.24764\tval-logloss:0.251975\n",
      "[34]\ttrain-logloss:0.247114\tval-logloss:0.251512\n",
      "[35]\ttrain-logloss:0.246652\tval-logloss:0.251116\n",
      "[36]\ttrain-logloss:0.246218\tval-logloss:0.250758\n",
      "[37]\ttrain-logloss:0.245849\tval-logloss:0.250455\n",
      "[38]\ttrain-logloss:0.24553\tval-logloss:0.250197\n",
      "[39]\ttrain-logloss:0.245246\tval-logloss:0.249996\n",
      "[40]\ttrain-logloss:0.244999\tval-logloss:0.24983\n",
      "[41]\ttrain-logloss:0.244742\tval-logloss:0.249642\n",
      "[42]\ttrain-logloss:0.244509\tval-logloss:0.249473\n",
      "[43]\ttrain-logloss:0.244303\tval-logloss:0.249328\n",
      "[44]\ttrain-logloss:0.244107\tval-logloss:0.249194\n",
      "[45]\ttrain-logloss:0.24393\tval-logloss:0.249066\n",
      "[46]\ttrain-logloss:0.243772\tval-logloss:0.24897\n",
      "[47]\ttrain-logloss:0.243601\tval-logloss:0.248861\n",
      "[48]\ttrain-logloss:0.243455\tval-logloss:0.248775\n",
      "[49]\ttrain-logloss:0.243311\tval-logloss:0.2487\n",
      "[50]\ttrain-logloss:0.243178\tval-logloss:0.248646\n",
      "[51]\ttrain-logloss:0.243068\tval-logloss:0.24859\n",
      "[52]\ttrain-logloss:0.242934\tval-logloss:0.248517\n",
      "[53]\ttrain-logloss:0.242798\tval-logloss:0.248458\n",
      "[54]\ttrain-logloss:0.242674\tval-logloss:0.248413\n",
      "[55]\ttrain-logloss:0.242546\tval-logloss:0.248374\n",
      "[56]\ttrain-logloss:0.242442\tval-logloss:0.248334\n",
      "[57]\ttrain-logloss:0.242354\tval-logloss:0.248302\n",
      "[58]\ttrain-logloss:0.242264\tval-logloss:0.248274\n",
      "[59]\ttrain-logloss:0.242127\tval-logloss:0.248247\n",
      "[60]\ttrain-logloss:0.242052\tval-logloss:0.24822\n",
      "[61]\ttrain-logloss:0.241949\tval-logloss:0.248205\n",
      "[62]\ttrain-logloss:0.24186\tval-logloss:0.248185\n",
      "[63]\ttrain-logloss:0.241787\tval-logloss:0.248172\n",
      "[64]\ttrain-logloss:0.241683\tval-logloss:0.248142\n",
      "[65]\ttrain-logloss:0.241613\tval-logloss:0.248134\n",
      "[66]\ttrain-logloss:0.241533\tval-logloss:0.248117\n",
      "[67]\ttrain-logloss:0.241462\tval-logloss:0.248098\n",
      "[68]\ttrain-logloss:0.241393\tval-logloss:0.248081\n",
      "[69]\ttrain-logloss:0.241283\tval-logloss:0.248066\n",
      "[70]\ttrain-logloss:0.241207\tval-logloss:0.248058\n",
      "[71]\ttrain-logloss:0.241116\tval-logloss:0.248056\n",
      "[72]\ttrain-logloss:0.241049\tval-logloss:0.248053\n",
      "[73]\ttrain-logloss:0.241007\tval-logloss:0.248044\n",
      "[74]\ttrain-logloss:0.2409\tval-logloss:0.248051\n",
      "[75]\ttrain-logloss:0.240821\tval-logloss:0.248042\n",
      "[76]\ttrain-logloss:0.240765\tval-logloss:0.24803\n",
      "[77]\ttrain-logloss:0.240705\tval-logloss:0.248028\n",
      "[78]\ttrain-logloss:0.2406\tval-logloss:0.248027\n",
      "[79]\ttrain-logloss:0.240495\tval-logloss:0.248025\n",
      "[80]\ttrain-logloss:0.24043\tval-logloss:0.248001\n",
      "[81]\ttrain-logloss:0.240372\tval-logloss:0.247993\n",
      "[82]\ttrain-logloss:0.240281\tval-logloss:0.247992\n",
      "[83]\ttrain-logloss:0.240193\tval-logloss:0.248006\n",
      "[84]\ttrain-logloss:0.240134\tval-logloss:0.248005\n",
      "[85]\ttrain-logloss:0.240051\tval-logloss:0.24801\n",
      "[86]\ttrain-logloss:0.239994\tval-logloss:0.248006\n",
      "[87]\ttrain-logloss:0.239913\tval-logloss:0.248006\n",
      "[88]\ttrain-logloss:0.239855\tval-logloss:0.247998\n",
      "[89]\ttrain-logloss:0.239817\tval-logloss:0.247991\n",
      "[90]\ttrain-logloss:0.239712\tval-logloss:0.248004\n",
      "[91]\ttrain-logloss:0.239623\tval-logloss:0.247997\n",
      "[92]\ttrain-logloss:0.239525\tval-logloss:0.248006\n",
      "[93]\ttrain-logloss:0.239485\tval-logloss:0.247999\n",
      "[94]\ttrain-logloss:0.239412\tval-logloss:0.247999\n",
      "[95]\ttrain-logloss:0.239358\tval-logloss:0.247991\n",
      "[96]\ttrain-logloss:0.239277\tval-logloss:0.247995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[97]\ttrain-logloss:0.239208\tval-logloss:0.24799\n",
      "[98]\ttrain-logloss:0.239149\tval-logloss:0.247987\n",
      "[99]\ttrain-logloss:0.239065\tval-logloss:0.247977\n",
      "[100]\ttrain-logloss:0.239002\tval-logloss:0.247981\n",
      "[101]\ttrain-logloss:0.23895\tval-logloss:0.247968\n",
      "[102]\ttrain-logloss:0.238872\tval-logloss:0.247972\n",
      "[103]\ttrain-logloss:0.238835\tval-logloss:0.247967\n",
      "[104]\ttrain-logloss:0.238776\tval-logloss:0.247968\n",
      "[105]\ttrain-logloss:0.238694\tval-logloss:0.247964\n",
      "[106]\ttrain-logloss:0.238642\tval-logloss:0.247963\n",
      "[107]\ttrain-logloss:0.238558\tval-logloss:0.247957\n",
      "[108]\ttrain-logloss:0.238493\tval-logloss:0.247946\n",
      "[109]\ttrain-logloss:0.238387\tval-logloss:0.247951\n",
      "[110]\ttrain-logloss:0.238311\tval-logloss:0.24796\n",
      "[111]\ttrain-logloss:0.238241\tval-logloss:0.247967\n",
      "[112]\ttrain-logloss:0.238177\tval-logloss:0.247949\n",
      "[113]\ttrain-logloss:0.23814\tval-logloss:0.247954\n",
      "[114]\ttrain-logloss:0.238072\tval-logloss:0.247947\n",
      "[115]\ttrain-logloss:0.237998\tval-logloss:0.247946\n",
      "[116]\ttrain-logloss:0.23795\tval-logloss:0.247945\n",
      "[117]\ttrain-logloss:0.237912\tval-logloss:0.247944\n",
      "[118]\ttrain-logloss:0.237853\tval-logloss:0.247941\n",
      "[119]\ttrain-logloss:0.237788\tval-logloss:0.247938\n",
      "[120]\ttrain-logloss:0.237684\tval-logloss:0.247944\n",
      "[121]\ttrain-logloss:0.237652\tval-logloss:0.247941\n",
      "[122]\ttrain-logloss:0.23761\tval-logloss:0.247939\n",
      "[123]\ttrain-logloss:0.237549\tval-logloss:0.247937\n",
      "[124]\ttrain-logloss:0.237482\tval-logloss:0.247929\n",
      "[125]\ttrain-logloss:0.237436\tval-logloss:0.247916\n",
      "[126]\ttrain-logloss:0.237338\tval-logloss:0.247918\n",
      "[127]\ttrain-logloss:0.237294\tval-logloss:0.247915\n",
      "[128]\ttrain-logloss:0.237243\tval-logloss:0.247922\n",
      "[129]\ttrain-logloss:0.237177\tval-logloss:0.247922\n",
      "[130]\ttrain-logloss:0.237138\tval-logloss:0.247919\n",
      "[131]\ttrain-logloss:0.237045\tval-logloss:0.247918\n",
      "[132]\ttrain-logloss:0.236957\tval-logloss:0.247908\n",
      "[133]\ttrain-logloss:0.236879\tval-logloss:0.247896\n",
      "[134]\ttrain-logloss:0.236832\tval-logloss:0.247897\n",
      "[135]\ttrain-logloss:0.236748\tval-logloss:0.247896\n",
      "[136]\ttrain-logloss:0.236681\tval-logloss:0.24789\n",
      "[137]\ttrain-logloss:0.236608\tval-logloss:0.247893\n",
      "[138]\ttrain-logloss:0.236537\tval-logloss:0.247899\n",
      "[139]\ttrain-logloss:0.236459\tval-logloss:0.247882\n",
      "[140]\ttrain-logloss:0.236403\tval-logloss:0.247878\n",
      "[141]\ttrain-logloss:0.236344\tval-logloss:0.24789\n",
      "[142]\ttrain-logloss:0.236295\tval-logloss:0.247892\n",
      "[143]\ttrain-logloss:0.236272\tval-logloss:0.247894\n",
      "[144]\ttrain-logloss:0.236195\tval-logloss:0.247904\n",
      "[145]\ttrain-logloss:0.236103\tval-logloss:0.247891\n",
      "[146]\ttrain-logloss:0.236037\tval-logloss:0.247887\n",
      "[147]\ttrain-logloss:0.235967\tval-logloss:0.247882\n",
      "[148]\ttrain-logloss:0.235907\tval-logloss:0.247887\n",
      "[149]\ttrain-logloss:0.235855\tval-logloss:0.247891\n",
      "Doing Cross 9 Validation\n",
      "validation start: 185580, end: 206209\n",
      "Split train and valid data/label by user_id\n",
      "[0]\ttrain-logloss:0.62658\tval-logloss:0.626538\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[1]\ttrain-logloss:0.570935\tval-logloss:0.570883\n",
      "[2]\ttrain-logloss:0.52478\tval-logloss:0.524719\n",
      "[3]\ttrain-logloss:0.486049\tval-logloss:0.485992\n",
      "[4]\ttrain-logloss:0.453286\tval-logloss:0.453241\n",
      "[5]\ttrain-logloss:0.425406\tval-logloss:0.425376\n",
      "[6]\ttrain-logloss:0.401522\tval-logloss:0.401533\n",
      "[7]\ttrain-logloss:0.38093\tval-logloss:0.380962\n",
      "[8]\ttrain-logloss:0.363181\tval-logloss:0.363227\n",
      "[9]\ttrain-logloss:0.347827\tval-logloss:0.347895\n",
      "[10]\ttrain-logloss:0.334522\tval-logloss:0.334625\n",
      "[11]\ttrain-logloss:0.322958\tval-logloss:0.323089\n",
      "[12]\ttrain-logloss:0.312901\tval-logloss:0.313062\n",
      "[13]\ttrain-logloss:0.304145\tval-logloss:0.304356\n",
      "[14]\ttrain-logloss:0.296531\tval-logloss:0.296772\n",
      "[15]\ttrain-logloss:0.289877\tval-logloss:0.290144\n",
      "[16]\ttrain-logloss:0.28406\tval-logloss:0.284368\n",
      "[17]\ttrain-logloss:0.27899\tval-logloss:0.279362\n",
      "[18]\ttrain-logloss:0.27456\tval-logloss:0.27498\n",
      "[19]\ttrain-logloss:0.270696\tval-logloss:0.271172\n",
      "[20]\ttrain-logloss:0.267319\tval-logloss:0.267837\n",
      "[21]\ttrain-logloss:0.264367\tval-logloss:0.264935\n",
      "[22]\ttrain-logloss:0.26179\tval-logloss:0.262409\n",
      "[23]\ttrain-logloss:0.259543\tval-logloss:0.260208\n",
      "[24]\ttrain-logloss:0.25773\tval-logloss:0.258469\n",
      "[25]\ttrain-logloss:0.255999\tval-logloss:0.256801\n",
      "[26]\ttrain-logloss:0.254483\tval-logloss:0.255343\n",
      "[27]\ttrain-logloss:0.253155\tval-logloss:0.254071\n",
      "[28]\ttrain-logloss:0.251998\tval-logloss:0.252976\n",
      "[29]\ttrain-logloss:0.251002\tval-logloss:0.252042\n",
      "[30]\ttrain-logloss:0.250112\tval-logloss:0.251223\n",
      "[31]\ttrain-logloss:0.24933\tval-logloss:0.250497\n",
      "[32]\ttrain-logloss:0.248642\tval-logloss:0.249873\n",
      "[33]\ttrain-logloss:0.248043\tval-logloss:0.249332\n",
      "[34]\ttrain-logloss:0.247518\tval-logloss:0.248874\n",
      "[35]\ttrain-logloss:0.247053\tval-logloss:0.248466\n",
      "[36]\ttrain-logloss:0.246633\tval-logloss:0.248113\n",
      "[37]\ttrain-logloss:0.246255\tval-logloss:0.247803\n",
      "[38]\ttrain-logloss:0.2459\tval-logloss:0.24752\n",
      "[39]\ttrain-logloss:0.245593\tval-logloss:0.247266\n",
      "[40]\ttrain-logloss:0.245329\tval-logloss:0.247069\n",
      "[41]\ttrain-logloss:0.245079\tval-logloss:0.246883\n",
      "[42]\ttrain-logloss:0.244857\tval-logloss:0.246721\n",
      "[43]\ttrain-logloss:0.244635\tval-logloss:0.246568\n",
      "[44]\ttrain-logloss:0.244439\tval-logloss:0.246445\n",
      "[45]\ttrain-logloss:0.244268\tval-logloss:0.246342\n",
      "[46]\ttrain-logloss:0.244112\tval-logloss:0.246245\n",
      "[47]\ttrain-logloss:0.243969\tval-logloss:0.246172\n",
      "[48]\ttrain-logloss:0.24382\tval-logloss:0.246084\n",
      "[49]\ttrain-logloss:0.243656\tval-logloss:0.246009\n",
      "[50]\ttrain-logloss:0.24353\tval-logloss:0.245946\n",
      "[51]\ttrain-logloss:0.243381\tval-logloss:0.245889\n",
      "[52]\ttrain-logloss:0.243243\tval-logloss:0.245817\n",
      "[53]\ttrain-logloss:0.243139\tval-logloss:0.245768\n",
      "[54]\ttrain-logloss:0.243048\tval-logloss:0.245727\n",
      "[55]\ttrain-logloss:0.242941\tval-logloss:0.245681\n",
      "[56]\ttrain-logloss:0.242829\tval-logloss:0.245635\n",
      "[57]\ttrain-logloss:0.242739\tval-logloss:0.245609\n",
      "[58]\ttrain-logloss:0.242613\tval-logloss:0.245581\n",
      "[59]\ttrain-logloss:0.242527\tval-logloss:0.245548\n",
      "[60]\ttrain-logloss:0.242436\tval-logloss:0.245514\n",
      "[61]\ttrain-logloss:0.242335\tval-logloss:0.245475\n",
      "[62]\ttrain-logloss:0.242262\tval-logloss:0.245452\n",
      "[63]\ttrain-logloss:0.242168\tval-logloss:0.245441\n",
      "[64]\ttrain-logloss:0.242082\tval-logloss:0.245415\n",
      "[65]\ttrain-logloss:0.242007\tval-logloss:0.245392\n",
      "[66]\ttrain-logloss:0.241944\tval-logloss:0.245376\n",
      "[67]\ttrain-logloss:0.241854\tval-logloss:0.245367\n",
      "[68]\ttrain-logloss:0.241767\tval-logloss:0.245357\n",
      "[69]\ttrain-logloss:0.241652\tval-logloss:0.24535\n",
      "[70]\ttrain-logloss:0.241563\tval-logloss:0.24534\n",
      "[71]\ttrain-logloss:0.241449\tval-logloss:0.245331\n",
      "[72]\ttrain-logloss:0.241386\tval-logloss:0.245326\n",
      "[73]\ttrain-logloss:0.241265\tval-logloss:0.2453\n",
      "[74]\ttrain-logloss:0.24119\tval-logloss:0.24529\n",
      "[75]\ttrain-logloss:0.241094\tval-logloss:0.245289\n",
      "[76]\ttrain-logloss:0.241016\tval-logloss:0.245273\n",
      "[77]\ttrain-logloss:0.240954\tval-logloss:0.245264\n",
      "[78]\ttrain-logloss:0.240902\tval-logloss:0.24525\n",
      "[79]\ttrain-logloss:0.24086\tval-logloss:0.245246\n",
      "[80]\ttrain-logloss:0.240743\tval-logloss:0.245233\n",
      "[81]\ttrain-logloss:0.240623\tval-logloss:0.245224\n",
      "[82]\ttrain-logloss:0.240497\tval-logloss:0.245222\n",
      "[83]\ttrain-logloss:0.240402\tval-logloss:0.245222\n",
      "[84]\ttrain-logloss:0.240308\tval-logloss:0.245218\n",
      "[85]\ttrain-logloss:0.240251\tval-logloss:0.245212\n",
      "[86]\ttrain-logloss:0.240182\tval-logloss:0.245214\n",
      "[87]\ttrain-logloss:0.240126\tval-logloss:0.245209\n",
      "[88]\ttrain-logloss:0.240047\tval-logloss:0.245193\n",
      "[89]\ttrain-logloss:0.239993\tval-logloss:0.245194\n",
      "[90]\ttrain-logloss:0.239949\tval-logloss:0.245197\n",
      "[91]\ttrain-logloss:0.239902\tval-logloss:0.245186\n",
      "[92]\ttrain-logloss:0.239824\tval-logloss:0.245181\n",
      "[93]\ttrain-logloss:0.239749\tval-logloss:0.245177\n",
      "[94]\ttrain-logloss:0.239666\tval-logloss:0.245181\n",
      "[95]\ttrain-logloss:0.239579\tval-logloss:0.245159\n",
      "[96]\ttrain-logloss:0.239515\tval-logloss:0.245156\n",
      "[97]\ttrain-logloss:0.239446\tval-logloss:0.245151\n",
      "[98]\ttrain-logloss:0.239393\tval-logloss:0.245149\n",
      "[99]\ttrain-logloss:0.239315\tval-logloss:0.245147\n",
      "[100]\ttrain-logloss:0.239248\tval-logloss:0.245145\n",
      "[101]\ttrain-logloss:0.239193\tval-logloss:0.245146\n",
      "[102]\ttrain-logloss:0.239145\tval-logloss:0.245135\n",
      "[103]\ttrain-logloss:0.23905\tval-logloss:0.245133\n",
      "[104]\ttrain-logloss:0.238962\tval-logloss:0.245141\n",
      "[105]\ttrain-logloss:0.238899\tval-logloss:0.245139\n",
      "[106]\ttrain-logloss:0.238829\tval-logloss:0.245139\n",
      "[107]\ttrain-logloss:0.238748\tval-logloss:0.245148\n",
      "[108]\ttrain-logloss:0.238652\tval-logloss:0.245155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[109]\ttrain-logloss:0.238607\tval-logloss:0.245153\n",
      "[110]\ttrain-logloss:0.238529\tval-logloss:0.245155\n",
      "[111]\ttrain-logloss:0.238476\tval-logloss:0.245165\n",
      "[112]\ttrain-logloss:0.238436\tval-logloss:0.24516\n",
      "[113]\ttrain-logloss:0.238396\tval-logloss:0.245159\n",
      "[114]\ttrain-logloss:0.238349\tval-logloss:0.245158\n",
      "[115]\ttrain-logloss:0.238284\tval-logloss:0.245159\n",
      "[116]\ttrain-logloss:0.238229\tval-logloss:0.245148\n",
      "[117]\ttrain-logloss:0.238136\tval-logloss:0.245127\n",
      "[118]\ttrain-logloss:0.238077\tval-logloss:0.24513\n",
      "[119]\ttrain-logloss:0.238\tval-logloss:0.245135\n",
      "[120]\ttrain-logloss:0.237933\tval-logloss:0.245132\n",
      "[121]\ttrain-logloss:0.237899\tval-logloss:0.245132\n",
      "[122]\ttrain-logloss:0.237831\tval-logloss:0.245135\n",
      "[123]\ttrain-logloss:0.237769\tval-logloss:0.245135\n",
      "[124]\ttrain-logloss:0.237723\tval-logloss:0.245124\n",
      "[125]\ttrain-logloss:0.237666\tval-logloss:0.245129\n",
      "[126]\ttrain-logloss:0.237592\tval-logloss:0.245131\n",
      "[127]\ttrain-logloss:0.237549\tval-logloss:0.245134\n",
      "[128]\ttrain-logloss:0.237473\tval-logloss:0.245174\n",
      "[129]\ttrain-logloss:0.237405\tval-logloss:0.245184\n",
      "[130]\ttrain-logloss:0.237343\tval-logloss:0.245177\n",
      "[131]\ttrain-logloss:0.237292\tval-logloss:0.245174\n",
      "[132]\ttrain-logloss:0.237247\tval-logloss:0.245166\n",
      "[133]\ttrain-logloss:0.237217\tval-logloss:0.245176\n",
      "[134]\ttrain-logloss:0.237164\tval-logloss:0.245167\n",
      "[135]\ttrain-logloss:0.237133\tval-logloss:0.245166\n",
      "[136]\ttrain-logloss:0.237068\tval-logloss:0.24517\n",
      "[137]\ttrain-logloss:0.237018\tval-logloss:0.245168\n",
      "[138]\ttrain-logloss:0.236948\tval-logloss:0.245174\n",
      "[139]\ttrain-logloss:0.236921\tval-logloss:0.245177\n",
      "[140]\ttrain-logloss:0.23688\tval-logloss:0.245168\n",
      "[141]\ttrain-logloss:0.236812\tval-logloss:0.245216\n",
      "[142]\ttrain-logloss:0.236747\tval-logloss:0.245216\n",
      "[143]\ttrain-logloss:0.236682\tval-logloss:0.245218\n",
      "[144]\ttrain-logloss:0.23663\tval-logloss:0.245222\n",
      "[145]\ttrain-logloss:0.236552\tval-logloss:0.245232\n",
      "[146]\ttrain-logloss:0.236491\tval-logloss:0.245233\n",
      "[147]\ttrain-logloss:0.23646\tval-logloss:0.245235\n",
      "[148]\ttrain-logloss:0.23639\tval-logloss:0.245228\n",
      "[149]\ttrain-logloss:0.23632\tval-logloss:0.245231\n"
     ]
    }
   ],
   "source": [
    "for nb in range(10):\n",
    "    print(\"Doing Cross %d Validation\"% nb)\n",
    "    val_start = nb*val_nb_user\n",
    "    val_end = (nb+1)*val_nb_user\n",
    "    if nb==9:\n",
    "        val_end = nb_user\n",
    "    print(\"validation start: %d, end: %d\" % (val_start, val_end))\n",
    "    train_user_ids = np.concatenate((user_id_list[:val_start],\\\n",
    "                                    user_id_list[val_end:]))\n",
    "    val_user_ids = user_id_list[val_start:val_end]\n",
    "    print(\"Split train and valid data/label by user_id\")\n",
    "    sub_df_val = df_train[df_train.user_id.isin(val_user_ids)]\n",
    "    sub_df_train = df_train[df_train.user_id.isin(train_user_ids)]\n",
    "    sub_train_label = np.array(sub_df_train['label'])\n",
    "    sub_val_label = np.array(sub_df_val['label'])\n",
    "    sub_df_train.drop('label', axis=1, inplace=True)\n",
    "    sub_df_val.drop('label', axis=1, inplace=True)\n",
    "    params={\n",
    "    'booster':'gbtree',\n",
    "    'objective': 'binary:logistic', \n",
    "    'eval_metric': 'logloss',\n",
    "    'gamma':0.7,  # 用于控制是否后剪枝的参数,越大越保守，一般0.1、0.2这样子。\n",
    "    'max_depth':10, # 构建树的深度，越大越容易过拟合\n",
    "    'lambda':10,  # 控制模型复杂度的权重值的L2正则化项参数，参数越大，模型越不容易过拟合。\n",
    "    'subsample':0.76, # 随机采样训练样本\n",
    "    'colsample_bytree':0.95, # 生成树时进行的列采样\n",
    "    'min_child_weight':10,  \n",
    "    'silent':0 ,#设置成1则没有运行信息输出，最好是设置为0.\n",
    "    'eta': 0.1, # 如同学习率\n",
    "    'seed':77,\n",
    "    'nthread':8,# cpu 线程数\n",
    "    }\n",
    "    train = np.array(sub_df_train)\n",
    "    valid = np.array(sub_df_val)\n",
    "    n = 150\n",
    "    plst = list(params.items())\n",
    "    xgtrain = xgb.DMatrix(train, label=sub_train_label)\n",
    "    xgval = xgb.DMatrix(valid, label=sub_val_label)\n",
    "    watchlist = [(xgtrain, 'train'), (xgval, 'val')]\n",
    "    model = xgb.train(plst, xgtrain, n, watchlist, early_stopping_rounds=100)\n",
    "    model.save_model('CV_0724_'+str(nb)+'.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost predict from model 0\n",
      "xgboost predict from model 1\n",
      "xgboost predict from model 2\n",
      "xgboost predict from model 3\n",
      "xgboost predict from model 4\n",
      "xgboost predict from model 5\n",
      "xgboost predict from model 6\n",
      "xgboost predict from model 7\n",
      "xgboost predict from model 8\n",
      "xgboost predict from model 9\n"
     ]
    }
   ],
   "source": [
    "df_test_array = np.array(df_test)\n",
    "xgtest = xgb.DMatrix(df_test_array)\n",
    "xgbst = xgb.Booster()\n",
    "for i in range(10):\n",
    "    print('xgboost predict from model',str(i))\n",
    "    xgbst.load_model('./CV_0724_'+str(i)+'.model')\n",
    "    if i == 0:\n",
    "        preds = xgbst.predict(xgtest)\n",
    "    else:\n",
    "        preds += xgbst.predict(xgtest)\n",
    "preds = preds / 10.\n",
    "df_test['pred'] = preds\n",
    "THRESHOLD=0.2\n",
    "d = dict()\n",
    "for row in df_test.itertuples():\n",
    "    if row.pred > THRESHOLD:\n",
    "        try:\n",
    "            d[row.order_id] += ' ' + str(row.product_id)\n",
    "        except:\n",
    "            d[row.order_id] = str(row.product_id)\n",
    "for order in test_orders.order_id:\n",
    "    if order not in d:\n",
    "        d[order] = 'None'\n",
    "\n",
    "tst = pd.DataFrame.from_dict(d, orient='index')\n",
    "tst.reset_index(inplace=True)\n",
    "tst.columns = ['order_id', 'products']\n",
    "tst.to_csv('submission_60_features_THRESHOLD_0.2_10_fold_CV_0724.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
