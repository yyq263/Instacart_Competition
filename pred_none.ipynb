{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from IPython.display import display\n",
    "import xgboost as xgb\n",
    "\n",
    "print('loading aisles...')\n",
    "aisles = pd.read_csv('aisles.csv', dtype={\n",
    "        'aisle_id': np.uint16,\n",
    "        'aisle': 'category'})\n",
    "\n",
    "print('loading department...')\n",
    "department = pd.read_csv('departments.csv', dtype={\n",
    "            'department_id': np.uint8,\n",
    "            'department': 'category'})\n",
    "\n",
    "print('loading products...')\n",
    "products = pd.read_csv('products.csv', dtype={\n",
    "        'product_id': np.uint16,\n",
    "        'order_id': np.uint32,\n",
    "        'aisle_id': np.uint8,\n",
    "        'department_id': np.uint8})\n",
    "\n",
    "print('loading prior orders...')\n",
    "prior = pd.read_csv('order_products__prior.csv', dtype={\n",
    "        'order_id': np.uint32,\n",
    "        'product_id': np.uint16,\n",
    "        'add_to_cart_order': np.uint16,\n",
    "        'reordered': np.uint16})\n",
    "\n",
    "print('loading train orders...')\n",
    "train = pd.read_csv('order_products__train.csv', dtype={\n",
    "        'order_id': np.uint32,\n",
    "        'product_id': np.uint16,\n",
    "        'add_to_cart_order': np.uint16,\n",
    "        'reordered': np.uint8})\n",
    "\n",
    "print('loading orders...')\n",
    "order = pd.read_csv('orders_with_NaN_estimate.csv' , dtype={\n",
    "        'order_id': np.uint32,\n",
    "        'user_id': np.uint32,\n",
    "        'eval_set': 'category',\n",
    "        'order_number': np.uint16,\n",
    "        'order_dow': np.uint16,\n",
    "        'order_hour_of_day': np.uint16,\n",
    "        'days_since_prior_order': np.float32})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mean_days_since_prior_order = np.array(order['days_since_prior_order'].groupby(order.user_id).mean().astype(np.float32))\n",
    "# j=0\n",
    "# print('size of mean_days_since_prior_order: ', len(mean_days_since_prior_order))\n",
    "# for i, item in enumerate(order['days_since_prior_order']):\n",
    "#     if np.isnan(item):\n",
    "#         order.loc[i, 'days_since_prior_order'] = mean_days_since_prior_order[j]\n",
    "#         j+=1\n",
    "#         if not j%10000:\n",
    "#             print('j=',j)\n",
    "# order.to_csv('orders_with_NaN_estimate.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_orders = order[order.eval_set == 'train']\n",
    "test_orders = order[order.eval_set == 'test']\n",
    "prior_orders = order[order.eval_set == 'prior']\n",
    "train_prior_orders = pd.concat([train_orders, prior_orders], ignore_index=True)\n",
    "\n",
    "train_prior = pd.concat([train, prior],ignore_index=True)\n",
    "order.set_index('order_id', inplace=True, drop=False)\n",
    "train_prior = train_prior.join(order, on='order_id', rsuffix='_')\n",
    "train_prior.drop('order_id_', inplace=True, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users = pd.DataFrame()\n",
    "users['user_id'] = train_prior_orders.groupby('user_id')['user_id'].apply(lambda x: x.iloc[0])\n",
    "users['nb_order'] = train_prior_orders.groupby('user_id').size().astype(np.uint16)\n",
    "users['avg_days_between_order'] = train_prior.groupby('user_id')['days_since_prior_order'].mean().astype(np.float32)\n",
    "users['avg_hour_of_day'] = train_prior.groupby('user_id')['order_hour_of_day'].mean().astype(np.float32)\n",
    "users['nb_total_items'] = train_prior.groupby('user_id').size().astype(np.uint16)\n",
    "users['all_products'] = train_prior.groupby('user_id')['product_id'].apply(set) # apply 对每个行或者列调用一次函数\n",
    "users['nb_distinct_items'] = (users['all_products'].map(len)).astype(np.uint16) #map 对每个元素(element-wise)调用一次函数\n",
    "users['average_basket'] = (users.nb_total_items / users.nb_order).astype(np.float32)\n",
    "users['min_days_of_week'] = train_prior.groupby('user_id')['order_dow'].apply(min).astype(np.uint8)\n",
    "users['max_days_of_week'] = train_prior.groupby('user_id')['order_dow'].apply(max).astype(np.uint8)\n",
    "users.set_index('user_id', inplace=True, drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# order_id X user_id related features\n",
    "features = pd.DataFrame()\n",
    "features['order_id'] = train_prior_orders['order_id']\n",
    "features['user_id'] = train_prior_orders['user_id']\n",
    "features['order_number'] = train_prior_orders['order_number']\n",
    "features['order_dow'] = train_prior_orders['order_dow']\n",
    "features['order_hour_of_day'] = train_prior_orders['order_hour_of_day']\n",
    "features['order_days_since_prior'] = train_prior_orders['days_since_prior_order']\n",
    "features.set_index('order_id', inplace=True, drop=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_features(orders, info):\n",
    "    g_features = pd.DataFrame()\n",
    "    g_features['order_id'] = orders.order_id\n",
    "    g_features['user_id'] = g_features.order_id.map(features.user_id)\n",
    "    g_features['order_number'] = g_features.order_id.map(features.order_number)\n",
    "    g_features['order_dow'] = g_features.order_id.map(features.order_dow)\n",
    "    g_features['order_hour_of_day'] = g_features.order_id.map(features.order_hour_of_day)\n",
    "    g_features['order_days_since_prior'] = g_features.order_id.map(features.order_days_since_prior)\n",
    "    g_features['user_nb_order'] = g_features.user_id.map(users.nb_order)\n",
    "    g_features['user_avg_days_between_order'] = g_features.user_id.map(users.avg_days_between_order)\n",
    "    g_features['user_avg_hour_of_day'] = g_features.user_id.map(users.avg_hour_of_day)\n",
    "    g_features['user_nb_total_items'] = g_features.user_id.map(users.nb_total_items)\n",
    "    g_features['user_nb_distinct_items'] = g_features.user_id.map(users.nb_distinct_items)\n",
    "    g_features['user_average_basket'] = g_features.user_id.map(users.average_basket)\n",
    "    g_features['user_min_days_of_week'] = g_features.user_id.map(users.min_days_of_week)\n",
    "    g_features['user_max_days_of_week'] = g_features.user_id.map(users.max_days_of_week)\n",
    "    # calculate label\n",
    "    df_order = pd.DataFrame()\n",
    "    df_order['order_id'] = info.groupby('order_id')['order_id'].apply(lambda x: x.iloc[0])\n",
    "    df_order['nb_reorder'] = info.groupby('order_id')['reordered'].sum().apply(np.uint16)\n",
    "    df_order['reorder_label'] = (df_order['nb_reorder'] > 0).astype(np.int8)\n",
    "    df_order.set_index('order_id', inplace=True, drop=False)\n",
    "    g_features['label'] = g_features.order_id.map(df_order.reorder_label)\n",
    "    g_features.drop('order_id', inplace=True)\n",
    "    return g_features\n",
    "train_set = gen_features(prior_orders, prior)\n",
    "valid_set = gen_features(train_orders, train)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_label = np.array(train_set['label'])\n",
    "train_set.drop('label', axis=1, inplace=True)\n",
    "train_data = np.array(train_set)\n",
    "\n",
    "valid_label = np.array(valid_set['label'])\n",
    "valid_set.drop('label',axis=1, inplace=True)\n",
    "valid_data = np.array(valid_set)\n",
    "del train_set\n",
    "del valid_set\n",
    "del users\n",
    "del features\n",
    "del order\n",
    "del prior\n",
    "del train\n",
    "del products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params={\n",
    "    'booster':'gbtree',\n",
    "    'objective': 'binary:logistic', \n",
    "    'eval_metric': 'logloss',\n",
    "    'gamma':0.7,  # 用于控制是否后剪枝的参数,越大越保守，一般0.1、0.2这样子。\n",
    "    'max_depth':10, # 构建树的深度，越大越容易过拟合\n",
    "    'lambda':10,  # 控制模型复杂度的权重值的L2正则化项参数，参数越大，模型越不容易过拟合。\n",
    "    'subsample':0.76, # 随机采样训练样本\n",
    "    'colsample_bytree':0.95, # 生成树时进行的列采样\n",
    "    'min_child_weight':10,  \n",
    "    'silent':0 ,#设置成1则没有运行信息输出，最好是设置为0.\n",
    "    'eta': 0.07, # 如同学习率\n",
    "    'seed':15,\n",
    "    'nthread':8,# cpu 线程数\n",
    "    }\n",
    "n = 150\n",
    "plst = list(params.items())\n",
    "xgtrain = xgb.DMatrix(train_data, label=train_label)\n",
    "xgval = xgb.DMatrix(valid_data, label=valid_label)\n",
    "watchlist = [(xgtrain, 'train'), (xgval, 'val')]\n",
    "model = xgb.train(plst, xgtrain, n, watchlist, early_stopping_rounds=100)\n",
    "#     model.save_model('CV_0724_'+str(nb)+'.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgtest = xgb.DMatrix(valid_data)\n",
    "preds = model.predict(xgtest)\n",
    "preds = np.uint8(preds>0.9)\n",
    "acc = np.sum(preds==valid_label) / np.float32(len(preds))\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "xgb.plot_importance(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
